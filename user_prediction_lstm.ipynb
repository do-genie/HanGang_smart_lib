{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0G7iLoKgDgF",
        "outputId": "365a96e0-3438-48de-e3db-3b76fcf495af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import openpyxl"
      ],
      "metadata": {
        "id": "0wT0vB9fgosd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1Yd8_QMgHYt",
        "outputId": "54124f8c-03e3-4a7e-fa72-b381289a711f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8lmiF-xgI3B",
        "outputId": "c94d114e-877a-4ebb-d558-abca73ff772f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'컨텐츠 기반 필터링 사용한 반려식물 추천 서비스'\n",
            "'딥러닝 기법을 활용한 한정판 스니커즈 리셀 가능여부 및 가격 예측 프로젝트'\n",
            " 행운의편지\n",
            "'2017,18,20 여의도 한강공원 방문자수.xlsx'\n",
            "'2017-2019 이촌 한강공원 방문자수.xlsx'\n",
            "'2017-2019 난지 한강공원 방문자수.xlsx'\n",
            "'2019100889 산업경영공학과 이수진 (인공지능론 텀프로젝트).pptx'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'ffh-bikk-mnd - 2022년 10월 17일 (1).gjam'\n",
            "'ffh-bikk-mnd - 2022년 10월 17일.gjam'\n",
            "'서울특별시 빅데이터 캠퍼스.gdoc'\n",
            "'할 일 목록.gsheet'\n",
            " kfood_final\n",
            " model\n",
            " nlp_liflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 알아둬야 하는 사실\n",
        "\n",
        "```\n",
        "#데이터는 총\n",
        "'2017,18,20 여의도 한강공원 방문자수.xlsx'\n",
        "\n",
        "'2017-2019 이촌 한강공원 방문자수.xlsx'\n",
        "\n",
        "'2017-2019 난지 한강공원 방문자수.xlsx'\n",
        "\n",
        "로 3가지임! \n",
        "\n",
        "각자 맡은 공원을 read_excel('____________')에 적으면 됨\n",
        "\n",
        "나머지는 이거 바로 밑 블럭에 있는 파라미터 값 범위만 변경해주면 된다.\n",
        "\n",
        "결과는 캡쳐해서 노션에 올려주면 됨\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "QtuVOpwpKx88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import median_absolute_error\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(test_label, pred))\n",
        "activation1 = ['relu', 'sigmoid']\n",
        "activation2 = ['relu', 'sigmoid']\n",
        "output_dim_lstm = [16, 32, 64, 128, 256]\n",
        "output_dim_dense = [4, 8, 16]\n",
        "learning_rate = [0.0005, 0.001, 0.01, 0.1]\n",
        "epochs = [50, 100, 200, 300]\n",
        "batch_size = [5, 10, 20, 30, 40] "
      ],
      "metadata": {
        "id": "5JBChwcWKwqo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b9dV4aifsfEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('2017,18,20 여의도 한강공원 방문자수.xlsx', engine='openpyxl') ##파일 이름 바꾸기\n",
        "df = df[['일반이용자(아침)',\t'일반이용자(낮)',\t'일반이용자(저녁)','합계']]\n",
        "df['일반이용자(아침)'] = df['일반이용자(아침)'].interpolate()\n",
        "df['일반이용자(낮)'] = df['일반이용자(낮)'].interpolate()\n",
        "df['일반이용자(저녁)'] = df['일반이용자(저녁)'].interpolate()\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ti9l3yf6gMVs",
        "outputId": "2d629f82-aa5d-4c80-9a80-88f64fc83864"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      일반이용자(아침)  일반이용자(낮)  일반이용자(저녁)    합계\n",
              "0           550      2410     2310.0  5270\n",
              "1           237      3550     2443.0  6230\n",
              "2           503      3640     3354.0  7497\n",
              "3          2310      1697     3420.0  7427\n",
              "4           510      2484     2320.0  5314\n",
              "...         ...       ...        ...   ...\n",
              "1091        110      2000     2200.0  4310\n",
              "1092        230      2530     1580.0  4340\n",
              "1093        450       700     1270.0  2420\n",
              "1094         60       920      430.0  1410\n",
              "1095        110      1230     1330.0  2670\n",
              "\n",
              "[1096 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7e4fa52-fa16-404b-92a1-856cff794cee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일반이용자(아침)</th>\n",
              "      <th>일반이용자(낮)</th>\n",
              "      <th>일반이용자(저녁)</th>\n",
              "      <th>합계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>550</td>\n",
              "      <td>2410</td>\n",
              "      <td>2310.0</td>\n",
              "      <td>5270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>237</td>\n",
              "      <td>3550</td>\n",
              "      <td>2443.0</td>\n",
              "      <td>6230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>503</td>\n",
              "      <td>3640</td>\n",
              "      <td>3354.0</td>\n",
              "      <td>7497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2310</td>\n",
              "      <td>1697</td>\n",
              "      <td>3420.0</td>\n",
              "      <td>7427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510</td>\n",
              "      <td>2484</td>\n",
              "      <td>2320.0</td>\n",
              "      <td>5314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>110</td>\n",
              "      <td>2000</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>4310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>230</td>\n",
              "      <td>2530</td>\n",
              "      <td>1580.0</td>\n",
              "      <td>4340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>450</td>\n",
              "      <td>700</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>2420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>60</td>\n",
              "      <td>920</td>\n",
              "      <td>430.0</td>\n",
              "      <td>1410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>110</td>\n",
              "      <td>1230</td>\n",
              "      <td>1330.0</td>\n",
              "      <td>2670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1096 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7e4fa52-fa16-404b-92a1-856cff794cee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7e4fa52-fa16-404b-92a1-856cff794cee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7e4fa52-fa16-404b-92a1-856cff794cee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_check=df.isna()\n",
        "\n",
        "check_for_any_nan= df.isna().values.any()\n",
        "# Or\n",
        "check_for_any_nan= df.isna().any().any()\n",
        "total_nan_values = df.isna().sum().sum()\n",
        "print(df_check)\n",
        "print(\"NaN Presence:\"+str(check_for_any_nan))\n",
        "print (\"Total Number of NaN values:\"+str(total_nan_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "secxNq97HAwT",
        "outputId": "b1e7fd49-293e-435e-a035-4ab4d4a7e2a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      일반이용자(아침)  일반이용자(낮)  일반이용자(저녁)     합계\n",
            "0         False     False      False  False\n",
            "1         False     False      False  False\n",
            "2         False     False      False  False\n",
            "3         False     False      False  False\n",
            "4         False     False      False  False\n",
            "...         ...       ...        ...    ...\n",
            "1091      False     False      False  False\n",
            "1092      False     False      False  False\n",
            "1093      False     False      False  False\n",
            "1094      False     False      False  False\n",
            "1095      False     False      False  False\n",
            "\n",
            "[1096 rows x 4 columns]\n",
            "NaN Presence:False\n",
            "Total Number of NaN values:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#df.sort_index(ascending=False).reset_index(drop=True)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scale_cols = ['일반이용자(아침)',\t'일반이용자(낮)',\t'일반이용자(저녁)','합계']\n",
        "\n",
        "stocks_scaled = scaler.fit_transform(df[scale_cols])\n",
        "stocks_scaled = pd.DataFrame(stocks_scaled)\n",
        "stocks_scaled.columns = scale_cols\n",
        "stocks_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O2t6-rW8hHYV",
        "outputId": "787ffe62-9043-4c5a-ccb5-57458bdd99fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      일반이용자(아침)  일반이용자(낮)  일반이용자(저녁)        합계\n",
              "0      0.072700  0.006025   0.006230  0.006495\n",
              "1      0.026261  0.008973   0.006602  0.007780\n",
              "2      0.065727  0.009206   0.009147  0.009475\n",
              "3      0.333828  0.004181   0.009332  0.009382\n",
              "4      0.066766  0.006216   0.006258  0.006554\n",
              "...         ...       ...        ...       ...\n",
              "1091   0.007418  0.004965   0.005923  0.005210\n",
              "1092   0.025223  0.006335   0.004191  0.005250\n",
              "1093   0.057864  0.001603   0.003325  0.002681\n",
              "1094   0.000000  0.002172   0.000978  0.001329\n",
              "1095   0.007418  0.002974   0.003492  0.003015\n",
              "\n",
              "[1096 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d55d137d-4328-4e6a-a3da-96f50184a63c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일반이용자(아침)</th>\n",
              "      <th>일반이용자(낮)</th>\n",
              "      <th>일반이용자(저녁)</th>\n",
              "      <th>합계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.072700</td>\n",
              "      <td>0.006025</td>\n",
              "      <td>0.006230</td>\n",
              "      <td>0.006495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.026261</td>\n",
              "      <td>0.008973</td>\n",
              "      <td>0.006602</td>\n",
              "      <td>0.007780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.065727</td>\n",
              "      <td>0.009206</td>\n",
              "      <td>0.009147</td>\n",
              "      <td>0.009475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.333828</td>\n",
              "      <td>0.004181</td>\n",
              "      <td>0.009332</td>\n",
              "      <td>0.009382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.066766</td>\n",
              "      <td>0.006216</td>\n",
              "      <td>0.006258</td>\n",
              "      <td>0.006554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>0.007418</td>\n",
              "      <td>0.004965</td>\n",
              "      <td>0.005923</td>\n",
              "      <td>0.005210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>0.025223</td>\n",
              "      <td>0.006335</td>\n",
              "      <td>0.004191</td>\n",
              "      <td>0.005250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>0.057864</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.003325</td>\n",
              "      <td>0.002681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002172</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>0.001329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>0.007418</td>\n",
              "      <td>0.002974</td>\n",
              "      <td>0.003492</td>\n",
              "      <td>0.003015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1096 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d55d137d-4328-4e6a-a3da-96f50184a63c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d55d137d-4328-4e6a-a3da-96f50184a63c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d55d137d-4328-4e6a-a3da-96f50184a63c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE = int(len(stocks_scaled)*0.2)\n",
        "print(TEST_SIZE)\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "train = stocks_scaled[:-TEST_SIZE]\n",
        "test = stocks_scaled[-TEST_SIZE:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzcK0l37hq8_",
        "outputId": "a7291b0e-54b6-4e4d-bbfa-d6bb8c9de8f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(data, label, window_size=7):\n",
        "    feature_list = []\n",
        "    label_list = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
        "        label_list.append(np.array(label.iloc[i+window_size]))\n",
        "    return np.array(feature_list), np.array(label_list)"
      ],
      "metadata": {
        "id": "5EZSEBoCh0U9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "feature_cols = ['일반이용자(아침)',\t'일반이용자(낮)',\t'일반이용자(저녁)','합계']\n",
        "label_cols = ['합계']\n",
        "\n",
        "train_feature = train[feature_cols]\n",
        "train_label = train[label_cols]\n",
        "\n",
        "train_feature, train_label = make_dataset(train_feature, train_label, 7)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)\n",
        "x_train.shape, x_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpiFpob3h2cH",
        "outputId": "5256e4b4-b44e-4e40-bc0a-8f37140500a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((696, 7, 4), (174, 7, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_feature = test[feature_cols]\n",
        "test_label = test[label_cols]\n",
        "\n",
        "test_feature.shape, test_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0LZ70j6h-rP",
        "outputId": "c388dede-82a6-4019-ab28-d5deffabbd3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((219, 4), (219, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_feature, test_label = make_dataset(test_feature, test_label, 7)\n",
        "test_feature.shape, test_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBTkkoceiAGw",
        "outputId": "beb01834-ec0e-42c0-9ea7-0a0eeadb123f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((212, 7, 4), (212, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
        "import os\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import median_absolute_error"
      ],
      "metadata": {
        "id": "TcTigqcQiC7B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q=0\n",
        "max_r2 = 0\n",
        "min_idx= 0\n",
        "grid_search = []\n",
        "for acti1 in activation1:\n",
        "  for out_lstm in output_dim_lstm :\n",
        "    for out_dense in output_dim_dense:\n",
        "      for lr in learning_rate:\n",
        "        for batch in batch_size:\n",
        "          for acti2 in activation2:\n",
        "            set = {}\n",
        "            model = tf.keras.Sequential()\n",
        "            model.add(LSTM(out_lstm, \n",
        "                input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
        "                activation=acti1, \n",
        "                return_sequences=False)\n",
        "            )\n",
        "            model.add(Dense(out_dense, activation=acti2))\n",
        "\n",
        "            model.add(Dense(1))\n",
        "\n",
        "            loss = Huber()\n",
        "            optimizer = Adam(lr)\n",
        "            model.compile(loss=Huber(), optimizer=optimizer, metrics=['mse'])\n",
        "            early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "            model_path = 'model'\n",
        "            filename = os.path.join(model_path, 'tmp_checkpoint.h5')\n",
        "            checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "            history = model.fit(x_train, y_train, \n",
        "                                                epochs=10,  ###이거 본인이 설정\n",
        "                                                batch_size=batch,\n",
        "                                                validation_data=(x_valid, y_valid), \n",
        "                                                callbacks=[early_stop, checkpoint])\n",
        "            model.load_weights(filename)\n",
        "            pred = model.predict(test_feature)\n",
        "\n",
        "            pred.shape\n",
        "\n",
        "                      \n",
        "            mse = model.evaluate(test_feature , test_label, batch_size=batch)\n",
        "\n",
        "            rmse = RMSE(test_label, pred)\n",
        "\n",
        "            r2_y_predict = r2_score(test_label, pred)\n",
        "\n",
        "            set[\"activation1\"] = acti1\n",
        "            set[\"activation2\"] = acti2\n",
        "            set[\"output_dim_lstm\"] = out_lstm\n",
        "            set[\"output_dim_dense\"] = out_dense\n",
        "            set[\"learning_rate\"] = lr\n",
        "            set[\"batch_size\"] = batch\n",
        "            set[\"MSE\"] = mse\n",
        "            set[\"R2\"] = r2_y_predict\n",
        "            set[\"RMSE\"] = rmse\n",
        "            \n",
        "          \n",
        "\n",
        "            grid_search.append(set)\n",
        "                        \n",
        "            if r2_y_predict > max_r2:\n",
        "              max_r2 = r2_y_predict\n",
        "              print(max_r2)\n",
        "              max_idx = q\n",
        "              print(set)\n",
        "                    \n",
        "            q+=1\n",
        "\n",
        "grid_df = pd.DataFrame(grid_search)\n",
        "grid_df = grid_df.sort_values(by='co_val', ascending=False)\n",
        "\n",
        "grid_df.to_csv(\"여의도.csv\", mode='w')  #파일 이름 한강공원 이름으로 설정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3tygmK_0OxIe",
        "outputId": "3e19954a-c13e-4321-9de4-730c2626769c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 1: val_loss improved from inf to 0.00127, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 2s 8ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 2/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022    \n",
            "Epoch 2: val_loss improved from 0.00127 to 0.00121, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 3/10\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 3: val_loss improved from 0.00121 to 0.00117, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 4/10\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 4: val_loss improved from 0.00117 to 0.00114, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 5/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 5: val_loss improved from 0.00114 to 0.00112, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 6/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 6: val_loss improved from 0.00112 to 0.00110, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 7/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 7: val_loss improved from 0.00110 to 0.00108, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 8/10\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 8: val_loss improved from 0.00108 to 0.00107, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 9/10\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 9: val_loss improved from 0.00107 to 0.00106, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 10/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 10: val_loss improved from 0.00106 to 0.00104, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.3532e-05 - mse: 2.7064e-05\n",
            "0.005202315642479316\n",
            "{'activation': 'relu', 'output_dim_lstm': 16, 'output_dim_dense': 4, 'learning_rate': 0.0005, 'batch_size': 5, 'MSE': [1.3532046068576165e-05, 2.706409213715233e-05], 'R2': 0.6095700954693082, 'RMSE': 0.005202315642479316}\n",
            "Epoch 1/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0027    \n",
            "Epoch 1: val_loss improved from inf to 0.00138, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 10ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 2/10\n",
            "59/70 [========================>.....] - ETA: 0s - loss: 9.7644e-04 - mse: 0.0020\n",
            "Epoch 2: val_loss improved from 0.00138 to 0.00129, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 3/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 3: val_loss improved from 0.00129 to 0.00125, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 4/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 4: val_loss improved from 0.00125 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 5/10\n",
            "59/70 [========================>.....] - ETA: 0s - loss: 4.4434e-04 - mse: 8.8867e-04\n",
            "Epoch 5: val_loss improved from 0.00120 to 0.00118, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 6/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 8.4737e-04 - mse: 0.0017\n",
            "Epoch 6: val_loss improved from 0.00118 to 0.00117, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021    \n",
            "Epoch 7: val_loss improved from 0.00117 to 0.00115, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 8/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 8: val_loss improved from 0.00115 to 0.00113, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 9/10\n",
            "62/70 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 9: val_loss improved from 0.00113 to 0.00113, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 10/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 10: val_loss improved from 0.00113 to 0.00111, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1.7757e-05 - mse: 3.5514e-05\n",
            "Epoch 1/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 1: val_loss improved from inf to 0.00200, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 15ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 2: val_loss improved from 0.00200 to 0.00187, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 0.0019 - val_mse: 0.0037\n",
            "Epoch 3/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 3: val_loss improved from 0.00187 to 0.00177, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 4/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 4: val_loss improved from 0.00177 to 0.00168, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 5/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 5: val_loss improved from 0.00168 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0013 - mse: 0.0026    \n",
            "Epoch 6: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0028    \n",
            "Epoch 7: val_loss improved from 0.00158 to 0.00157, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 8/10\n",
            "24/35 [===================>..........] - ETA: 0s - loss: 3.0102e-04 - mse: 6.0205e-04\n",
            "Epoch 8: val_loss improved from 0.00157 to 0.00155, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 9/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0027        \n",
            "Epoch 9: val_loss improved from 0.00155 to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 10/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0027    \n",
            "Epoch 10: val_loss improved from 0.00154 to 0.00152, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 4.8073e-05 - mse: 9.6146e-05\n",
            "Epoch 1/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 9.2663e-04 - mse: 0.0019\n",
            "Epoch 1: val_loss improved from inf to 0.00166, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 3s 65ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 2/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0017 - mse: 0.0034    \n",
            "Epoch 2: val_loss improved from 0.00166 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 3: val_loss improved from 0.00159 to 0.00157, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 4/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026        \n",
            "Epoch 4: val_loss improved from 0.00157 to 0.00156, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 5/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 5: val_loss improved from 0.00156 to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 6/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 6: val_loss improved from 0.00154 to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 7/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 6.2265e-04 - mse: 0.0012    \n",
            "Epoch 7: val_loss improved from 0.00154 to 0.00153, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 8/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 6.1190e-04 - mse: 0.0012\n",
            "Epoch 8: val_loss improved from 0.00153 to 0.00152, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 9/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 9: val_loss improved from 0.00152 to 0.00150, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 10/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 10: val_loss improved from 0.00150 to 0.00149, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5447e-05 - mse: 9.0895e-05\n",
            "Epoch 1/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 4.1557e-04 - mse: 8.3114e-04 \n",
            "Epoch 1: val_loss improved from inf to 0.00136, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 24ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 2/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 2: val_loss improved from 0.00136 to 0.00134, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 3/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 2.2562e-04 - mse: 4.5123e-04\n",
            "Epoch 3: val_loss improved from 0.00134 to 0.00132, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 4/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 0.0015 - mse: 0.0031        \n",
            "Epoch 4: val_loss improved from 0.00132 to 0.00128, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 5/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 4.3335e-04 - mse: 8.6669e-04\n",
            "Epoch 5: val_loss improved from 0.00128 to 0.00126, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 6/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 5.1546e-04 - mse: 0.0010    \n",
            "Epoch 6: val_loss improved from 0.00126 to 0.00123, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 7/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 7: val_loss improved from 0.00123 to 0.00122, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 8/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 1.6214e-04 - mse: 3.2428e-04\n",
            "Epoch 8: val_loss improved from 0.00122 to 0.00121, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 9/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0017 - mse: 0.0035        \n",
            "Epoch 9: val_loss improved from 0.00121 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 10/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 0.0015 - mse: 0.0030        \n",
            "Epoch 10: val_loss improved from 0.00120 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 3.6594e-05 - mse: 7.3188e-05\n",
            "Epoch 1/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 1: val_loss improved from inf to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 2s 7ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 2: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 3: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 4: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.0138e-04 - mse: 2.0276e-04\n",
            "Epoch 1/10\n",
            "60/70 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 1: val_loss improved from inf to 0.00139, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 10ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 2: val_loss improved from 0.00139 to 0.00130, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 3/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 3: val_loss improved from 0.00130 to 0.00127, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 4/10\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 4: val_loss improved from 0.00127 to 0.00124, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 5/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 5: val_loss improved from 0.00124 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 6/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0010 - mse: 0.0021    \n",
            "Epoch 6: val_loss improved from 0.00120 to 0.00118, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 7/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 7: val_loss improved from 0.00118 to 0.00113, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 8/10\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 8: val_loss improved from 0.00113 to 0.00111, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 9/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 9: val_loss improved from 0.00111 to 0.00109, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 10/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0010 - mse: 0.0021        \n",
            "Epoch 10: val_loss did not improve from 0.00109\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1.2601e-05 - mse: 2.5202e-05\n",
            "0.005020150135021941\n",
            "{'activation': 'relu', 'output_dim_lstm': 16, 'output_dim_dense': 4, 'learning_rate': 0.001, 'batch_size': 10, 'MSE': [1.2600954505614936e-05, 2.5201909011229873e-05], 'R2': 0.6364341456599156, 'RMSE': 0.005020150135021941}\n",
            "Epoch 1/10\n",
            "24/35 [===================>..........] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 1: val_loss improved from inf to 0.00126, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 15ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 2/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 2: val_loss improved from 0.00126 to 0.00122, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 3/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0011 - mse: 0.0023        \n",
            "Epoch 3: val_loss improved from 0.00122 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 4: val_loss improved from 0.00120 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 5/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 5: val_loss improved from 0.00120 to 0.00118, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 6/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 6: val_loss did not improve from 0.00118\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 7/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 7: val_loss improved from 0.00118 to 0.00112, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 8/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 3.6360e-04 - mse: 7.2720e-04\n",
            "Epoch 8: val_loss improved from 0.00112 to 0.00111, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 9/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 9: val_loss improved from 0.00111 to 0.00109, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 10/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0022        \n",
            "Epoch 10: val_loss improved from 0.00109 to 0.00107, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.1577e-05 - mse: 4.3153e-05\n",
            "Epoch 1/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0015 - mse: 0.0030        \n",
            "Epoch 1: val_loss improved from inf to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 20ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 4.0393e-04 - mse: 8.0785e-04\n",
            "Epoch 2: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 3: val_loss improved from 0.00158 to 0.00156, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 4/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026    \n",
            "Epoch 4: val_loss improved from 0.00156 to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 5/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 5: val_loss improved from 0.00154 to 0.00150, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 6/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0025\n",
            "Epoch 6: val_loss improved from 0.00150 to 0.00150, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 7/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 7: val_loss improved from 0.00150 to 0.00146, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 8/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0026    \n",
            "Epoch 8: val_loss improved from 0.00146 to 0.00143, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 9/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0025    \n",
            "Epoch 9: val_loss improved from 0.00143 to 0.00141, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 10/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 10: val_loss improved from 0.00141 to 0.00138, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4719e-05 - mse: 2.9437e-05\n",
            "Epoch 1/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0013 - mse: 0.0027 \n",
            "Epoch 1: val_loss improved from inf to 0.00160, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 25ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 8.6049e-04 - mse: 0.0017\n",
            "Epoch 2: val_loss improved from 0.00160 to 0.00157, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 3/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 3: val_loss improved from 0.00157 to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 4/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 4: val_loss improved from 0.00154 to 0.00152, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 5/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 6.0520e-04 - mse: 0.0012\n",
            "Epoch 5: val_loss improved from 0.00152 to 0.00148, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 6/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 0.0014 - mse: 0.0028        \n",
            "Epoch 6: val_loss improved from 0.00148 to 0.00144, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 7/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0018 - mse: 0.0035        \n",
            "Epoch 7: val_loss improved from 0.00144 to 0.00141, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 8/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0015 - mse: 0.0031        \n",
            "Epoch 8: val_loss improved from 0.00141 to 0.00137, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 9/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 6.2910e-04 - mse: 0.0013    \n",
            "Epoch 9: val_loss improved from 0.00137 to 0.00134, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 10/10\n",
            "12/18 [===================>..........] - ETA: 0s - loss: 0.0016 - mse: 0.0031        \n",
            "Epoch 10: val_loss improved from 0.00134 to 0.00132, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 2.3686e-05 - mse: 4.7372e-05\n",
            "Epoch 1/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00109, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 8ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 2/10\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 2: val_loss did not improve from 0.00109\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 3/10\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 3: val_loss improved from 0.00109 to 0.00103, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 4/10\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 4: val_loss did not improve from 0.00103\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 5/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 8.5833e-04 - mse: 0.0017\n",
            "Epoch 5: val_loss did not improve from 0.00103\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 6: val_loss did not improve from 0.00103\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 7: val_loss did not improve from 0.00103\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 8: val_loss did not improve from 0.00103\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 8.0234e-05 - mse: 1.6047e-04\n",
            "Epoch 1/10\n",
            "62/70 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 1: val_loss improved from inf to 0.00126, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 11ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 2/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0025\n",
            "Epoch 2: val_loss improved from 0.00126 to 0.00104, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 3/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0025\n",
            "Epoch 3: val_loss did not improve from 0.00104\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 4/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 4.2409e-04 - mse: 8.4818e-04\n",
            "Epoch 4: val_loss did not improve from 0.00104\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 5/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 5: val_loss did not improve from 0.00104\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 6/10\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 6: val_loss improved from 0.00104 to 0.00100, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 7/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 7: val_loss did not improve from 0.00100\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 8/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0024    \n",
            "Epoch 8: val_loss did not improve from 0.00100\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 9/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 9: val_loss improved from 0.00100 to 0.00081, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 8.0997e-04 - val_mse: 0.0016\n",
            "Epoch 10/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 10: val_loss did not improve from 0.00081\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 8.9680e-04 - val_mse: 0.0018\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 2.5577e-05 - mse: 5.1155e-05\n",
            "Epoch 1/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00109, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 15ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 2/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 2: val_loss improved from 0.00109 to 0.00108, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 3/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 3: val_loss did not improve from 0.00108\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 4/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 2.2774e-04 - mse: 4.5548e-04\n",
            "Epoch 4: val_loss improved from 0.00108 to 0.00098, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.8347e-04 - val_mse: 0.0020\n",
            "Epoch 5/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0026        \n",
            "Epoch 5: val_loss did not improve from 0.00098\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 6/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 6: val_loss improved from 0.00098 to 0.00093, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 9.2517e-04 - val_mse: 0.0019\n",
            "Epoch 7/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0025\n",
            "Epoch 7: val_loss did not improve from 0.00093\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.9768e-04 - val_mse: 0.0020\n",
            "Epoch 8/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 1.8318e-04 - mse: 3.6637e-04\n",
            "Epoch 8: val_loss did not improve from 0.00093\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.8723e-04 - val_mse: 0.0020\n",
            "Epoch 9/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0011 - mse: 0.0023        \n",
            "Epoch 9: val_loss improved from 0.00093 to 0.00089, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 8.9206e-04 - val_mse: 0.0018\n",
            "Epoch 10/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 10: val_loss improved from 0.00089 to 0.00085, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 8.5479e-04 - val_mse: 0.0017\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.2745e-05 - mse: 1.8549e-04\n",
            "Epoch 1/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0031    \n",
            "Epoch 1: val_loss improved from inf to 0.00162, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 20ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 2: val_loss improved from 0.00162 to 0.00155, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 3/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 7.0246e-04 - mse: 0.0014    \n",
            "Epoch 3: val_loss improved from 0.00155 to 0.00152, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 4/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 4: val_loss improved from 0.00152 to 0.00144, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 5/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 5: val_loss improved from 0.00144 to 0.00142, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 6/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0029    \n",
            "Epoch 6: val_loss improved from 0.00142 to 0.00136, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 7/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 7: val_loss did not improve from 0.00136\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 8/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 5.3527e-04 - mse: 0.0011\n",
            "Epoch 8: val_loss did not improve from 0.00136\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 9/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 9: val_loss improved from 0.00136 to 0.00136, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 10/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0011 - mse: 0.0021        \n",
            "Epoch 10: val_loss improved from 0.00136 to 0.00125, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4464e-05 - mse: 4.8929e-05\n",
            "Epoch 1/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0018 - mse: 0.0036         \n",
            "Epoch 1: val_loss improved from inf to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 27ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 2/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 4.5576e-04 - mse: 9.1152e-04\n",
            "Epoch 2: val_loss improved from 0.00120 to 0.00111, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 3/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 8.7696e-04 - mse: 0.0018\n",
            "Epoch 3: val_loss improved from 0.00111 to 0.00106, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 4/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0016 - mse: 0.0032        \n",
            "Epoch 4: val_loss improved from 0.00106 to 0.00103, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 5/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0017 - mse: 0.0033        \n",
            "Epoch 5: val_loss improved from 0.00103 to 0.00099, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.8915e-04 - val_mse: 0.0020\n",
            "Epoch 6/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0016 - mse: 0.0033        \n",
            "Epoch 6: val_loss did not improve from 0.00099\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0022        \n",
            "Epoch 7: val_loss improved from 0.00099 to 0.00091, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.1383e-04 - val_mse: 0.0018\n",
            "Epoch 8/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 5.6736e-04 - mse: 0.0011    \n",
            "Epoch 8: val_loss did not improve from 0.00091\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.9530e-04 - val_mse: 0.0020\n",
            "Epoch 9/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0016 - mse: 0.0032        \n",
            "Epoch 9: val_loss improved from 0.00091 to 0.00091, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.1271e-04 - val_mse: 0.0018\n",
            "Epoch 10/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0016 - mse: 0.0032        \n",
            "Epoch 10: val_loss did not improve from 0.00091\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 9.4573e-04 - val_mse: 0.0019\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 2.5414e-05 - mse: 5.0829e-05\n",
            "Epoch 1/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 1: val_loss improved from inf to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 2s 8ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 2: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 3/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 3: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 4/10\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0035    \n",
            "Epoch 4: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0032 - val_mse: 0.0063\n",
            "Epoch 5/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 5: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0017 - val_mse: 0.0035\n",
            "Epoch 6/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0019 - val_mse: 0.0037\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 5.6647e-05 - mse: 1.1329e-04\n",
            "Epoch 1/10\n",
            "62/70 [=========================>....] - ETA: 0s - loss: 0.0025 - mse: 0.0049\n",
            "Epoch 1: val_loss improved from inf to 0.00128, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 3s 13ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 2: val_loss improved from 0.00128 to 0.00114, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0024 - mse: 0.0048\n",
            "Epoch 3: val_loss did not improve from 0.00114\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0048 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 4: val_loss did not improve from 0.00114\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 5: val_loss did not improve from 0.00114\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 6/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0015 - mse: 0.0031    \n",
            "Epoch 6: val_loss did not improve from 0.00114\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0028 - val_mse: 0.0056\n",
            "Epoch 7/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 7: val_loss did not improve from 0.00114\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 5.7843e-05 - mse: 1.1569e-04\n",
            "Epoch 1/10\n",
            "26/35 [=====================>........] - ETA: 0s - loss: 0.0020 - mse: 0.0039\n",
            "Epoch 1: val_loss improved from inf to 0.00164, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 17ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 2/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 2: val_loss improved from 0.00164 to 0.00164, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 3/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 3: val_loss did not improve from 0.00164\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 4/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 4: val_loss did not improve from 0.00164\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 5/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 5: val_loss did not improve from 0.00164\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 6/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0032    \n",
            "Epoch 6: val_loss improved from 0.00164 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0025\n",
            "Epoch 7: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 10/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.1385e-04 - mse: 2.2769e-04\n",
            "Epoch 1/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0061 - mse: 0.0123\n",
            "Epoch 1: val_loss improved from inf to 0.00228, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 22ms/step - loss: 0.0056 - mse: 0.0114 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 2/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 2: val_loss improved from 0.00228 to 0.00168, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 3/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 4.9249e-04 - mse: 9.8498e-04\n",
            "Epoch 3: val_loss did not improve from 0.00168\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 4/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 4: val_loss improved from 0.00168 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 5: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 7.4953e-04 - mse: 0.0015    \n",
            "Epoch 6: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0016 - mse: 0.0032    \n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 9/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0015 - mse: 0.0030        \n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0012 - mse: 0.0025        \n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3121e-04 - mse: 2.6242e-04\n",
            "Epoch 1/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0041 - mse: 0.0081         \n",
            "Epoch 1: val_loss improved from inf to 0.00263, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 25ms/step - loss: 0.0038 - mse: 0.0076 - val_loss: 0.0026 - val_mse: 0.0053\n",
            "Epoch 2/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0267 - mse: 0.2605\n",
            "Epoch 2: val_loss improved from 0.00263 to 0.00170, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0154 - mse: 0.1499 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 3/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 0.0016 - mse: 0.0033        \n",
            "Epoch 3: val_loss improved from 0.00170 to 0.00161, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 4: val_loss did not improve from 0.00161\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0016 - mse: 0.0032        \n",
            "Epoch 5: val_loss did not improve from 0.00161\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 6/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 3.9554e-04 - mse: 7.9107e-04\n",
            "Epoch 6: val_loss did not improve from 0.00161\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0027    \n",
            "Epoch 7: val_loss improved from 0.00161 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0014 - mse: 0.0027        \n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 7.0178e-04 - mse: 0.0014\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 8.8802e-05 - mse: 1.7760e-04\n",
            "Epoch 1/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0475 - mse: 0.2930\n",
            "Epoch 1: val_loss improved from inf to 0.00189, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 8ms/step - loss: 0.0454 - mse: 0.2800 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 2/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 2: val_loss did not improve from 0.00189\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0048 - val_mse: 0.0097\n",
            "Epoch 3/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 3: val_loss did not improve from 0.00189\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 0.0032 - val_mse: 0.0065\n",
            "Epoch 4/10\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 4: val_loss improved from 0.00189 to 0.00166, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0032    \n",
            "Epoch 5: val_loss did not improve from 0.00166\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0030 - val_mse: 0.0059\n",
            "Epoch 6/10\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 6: val_loss improved from 0.00166 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.0018 - mse: 0.0037\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0024 - val_mse: 0.0048\n",
            "Epoch 8/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 9/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0040\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 10/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0019 - mse: 0.0039\n",
            "Epoch 10: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.3909e-04 - mse: 2.7818e-04\n",
            "Epoch 1/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0031 - mse: 0.0063\n",
            "Epoch 1: val_loss improved from inf to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 10ms/step - loss: 0.0028 - mse: 0.0057 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 2: val_loss did not improve from 0.00159\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 3: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 4: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0018 - val_mse: 0.0037\n",
            "Epoch 6/10\n",
            "62/70 [=========================>....] - ETA: 0s - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0041 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 7/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0018 - val_mse: 0.0037\n",
            "Epoch 8/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0031 - val_mse: 0.0062\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 1.2509e-04 - mse: 2.5017e-04\n",
            "Epoch 1/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0255 - mse: 0.0525\n",
            "Epoch 1: val_loss improved from inf to 0.00230, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 3s 15ms/step - loss: 0.0231 - mse: 0.0474 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 2/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0023 - mse: 0.0046\n",
            "Epoch 2: val_loss improved from 0.00230 to 0.00227, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0023 - val_mse: 0.0045\n",
            "Epoch 3/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0047\n",
            "Epoch 3: val_loss improved from 0.00227 to 0.00203, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0020 - val_mse: 0.0041\n",
            "Epoch 4/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 4: val_loss improved from 0.00203 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0021 - mse: 0.0043\n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 6/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0021 - mse: 0.0043    \n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0018 - val_mse: 0.0037\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.6800e-05 - mse: 1.9360e-04\n",
            "Epoch 1/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0458 - mse: 0.0927\n",
            "Epoch 1: val_loss improved from inf to 0.00199, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 21ms/step - loss: 0.0384 - mse: 0.0777 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 2/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0023 - mse: 0.0046\n",
            "Epoch 2: val_loss did not improve from 0.00199\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0019 - mse: 0.0039 - val_loss: 0.0022 - val_mse: 0.0043\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 3: val_loss improved from 0.00199 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 8.1700e-04 - mse: 0.0016\n",
            "Epoch 4: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0015 - mse: 0.0029    \n",
            "Epoch 5: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 5.3024e-04 - mse: 0.0011    \n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0016 - mse: 0.0032    \n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 8/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0017 - mse: 0.0034        \n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 9/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0018 - mse: 0.0036    \n",
            "Epoch 9: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0027    \n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.3358e-05 - mse: 1.8672e-04\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1482 - mse: 0.4593\n",
            "Epoch 1: val_loss improved from inf to 0.01388, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 26ms/step - loss: 0.1482 - mse: 0.4593 - val_loss: 0.0139 - val_mse: 0.0278\n",
            "Epoch 2/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0044 - mse: 0.0087\n",
            "Epoch 2: val_loss improved from 0.01388 to 0.00193, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mse: 0.0085 - val_loss: 0.0019 - val_mse: 0.0039\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0018 - mse: 0.0036    \n",
            "Epoch 3: val_loss improved from 0.00193 to 0.00168, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 4: val_loss improved from 0.00168 to 0.00165, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0022 - mse: 0.0043        \n",
            "Epoch 5: val_loss improved from 0.00165 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 7/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0018 - mse: 0.0037        \n",
            "Epoch 7: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0022 - mse: 0.0043        \n",
            "Epoch 8: val_loss improved from 0.00159 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 8.0903e-04 - mse: 0.0016    \n",
            "Epoch 9: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0017 - mse: 0.0034        \n",
            "Epoch 10: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 8.6017e-05 - mse: 1.7203e-04\n",
            "Epoch 1/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0404 - mse: 0.2249\n",
            "Epoch 1: val_loss improved from inf to 0.00783, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 4s 13ms/step - loss: 0.0403 - mse: 0.2246 - val_loss: 0.0078 - val_mse: 0.0157\n",
            "Epoch 2/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 2: val_loss improved from 0.00783 to 0.00196, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0020 - val_mse: 0.0039\n",
            "Epoch 3/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 3: val_loss improved from 0.00196 to 0.00160, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 4: val_loss improved from 0.00160 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0026 - mse: 0.0052\n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0026 - mse: 0.0052 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.0022 - mse: 0.0043\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0023 - val_mse: 0.0045\n",
            "Epoch 7/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0023 - mse: 0.0047\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0022 - mse: 0.0045 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0022 - mse: 0.0044\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 9/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0022 - mse: 0.0044\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0023 - mse: 0.0046 - val_loss: 0.0019 - val_mse: 0.0037\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 9.3978e-05 - mse: 1.8796e-04\n",
            "Epoch 1/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0052 - mse: 0.0104\n",
            "Epoch 1: val_loss improved from inf to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 11ms/step - loss: 0.0047 - mse: 0.0095 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0032    \n",
            "Epoch 2: val_loss did not improve from 0.00159\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 3/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 3: val_loss did not improve from 0.00159\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 4/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 4: val_loss did not improve from 0.00159\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "Epoch 5/10\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 5: val_loss did not improve from 0.00159\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 6/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0034    \n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0024 - val_mse: 0.0049\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 6.7155e-05 - mse: 1.3431e-04\n",
            "Epoch 1/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2295 - mse: 1.0681\n",
            "Epoch 1: val_loss improved from inf to 0.00186, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 16ms/step - loss: 0.1990 - mse: 0.9231 - val_loss: 0.0019 - val_mse: 0.0037\n",
            "Epoch 2/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0028 - mse: 0.0057\n",
            "Epoch 2: val_loss did not improve from 0.00186\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0019 - val_mse: 0.0039\n",
            "Epoch 3/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.0015 - mse: 0.0031    \n",
            "Epoch 3: val_loss improved from 0.00186 to 0.00163, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 4/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 4: val_loss did not improve from 0.00163\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 5/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 5: val_loss did not improve from 0.00163\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 6/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 6.7804e-04 - mse: 0.0014\n",
            "Epoch 6: val_loss improved from 0.00163 to 0.00161, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 7: val_loss did not improve from 0.00161\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 8/10\n",
            "26/35 [=====================>........] - ETA: 0s - loss: 5.5635e-04 - mse: 0.0011\n",
            "Epoch 8: val_loss did not improve from 0.00161\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 9/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 9: val_loss did not improve from 0.00161\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0022 - val_mse: 0.0043\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 10: val_loss did not improve from 0.00161\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.3781e-05 - mse: 8.7562e-05\n",
            "Epoch 1/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.1630 - mse: 0.6235\n",
            "Epoch 1: val_loss improved from inf to 0.01272, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 20ms/step - loss: 0.1478 - mse: 0.5650 - val_loss: 0.0127 - val_mse: 0.0254\n",
            "Epoch 2/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0035 - mse: 0.0070\n",
            "Epoch 2: val_loss improved from 0.01272 to 0.00246, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0039 - mse: 0.0077 - val_loss: 0.0025 - val_mse: 0.0049\n",
            "Epoch 3/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 3: val_loss improved from 0.00246 to 0.00200, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 4/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 4: val_loss improved from 0.00200 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 7.7390e-04 - mse: 0.0015\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 7/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 6.2508e-04 - mse: 0.0013    \n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0019 - val_mse: 0.0039\n",
            "Epoch 8/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0017 - mse: 0.0033        \n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0217e-04 - mse: 2.0434e-04\n",
            "Epoch 1/10\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 8.2423 - mse: 1053.8601 \n",
            "Epoch 1: val_loss improved from inf to 0.01205, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 27ms/step - loss: 6.6371 - mse: 847.9443 - val_loss: 0.0121 - val_mse: 0.0241\n",
            "Epoch 2/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0088 - mse: 0.0176\n",
            "Epoch 2: val_loss improved from 0.01205 to 0.00351, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0061 - mse: 0.0122 - val_loss: 0.0035 - val_mse: 0.0070\n",
            "Epoch 3/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0034 - mse: 0.0068\n",
            "Epoch 3: val_loss improved from 0.00351 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028    \n",
            "Epoch 4: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0035\n",
            "Epoch 5/10\n",
            "11/18 [=================>............] - ETA: 0s - loss: 9.9805e-04 - mse: 0.0020    \n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0026    \n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0018 - mse: 0.0037        \n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0025 - mse: 0.0049\n",
            "Epoch 8: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0029        \n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0035\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 9.5180e-05 - mse: 1.9036e-04\n",
            "Epoch 1/10\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 1: val_loss improved from inf to 0.00116, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 2/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021        \n",
            "Epoch 2: val_loss did not improve from 0.00116\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 3/10\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021    \n",
            "Epoch 3: val_loss improved from 0.00116 to 0.00113, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 4/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 4: val_loss did not improve from 0.00113\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 5/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022        \n",
            "Epoch 5: val_loss did not improve from 0.00113\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 6/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 6: val_loss improved from 0.00113 to 0.00110, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 7/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 7: val_loss improved from 0.00110 to 0.00108, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 8/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 8.4100e-04 - mse: 0.0017\n",
            "Epoch 8: val_loss did not improve from 0.00108\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 9/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 9: val_loss improved from 0.00108 to 0.00106, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 10/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 10: val_loss improved from 0.00106 to 0.00105, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.2160e-05 - mse: 2.4319e-05\n",
            "0.004931442198260454\n",
            "{'activation': 'relu', 'output_dim_lstm': 16, 'output_dim_dense': 8, 'learning_rate': 0.0005, 'batch_size': 5, 'MSE': [1.21595594464452e-05, 2.4319122530869208e-05], 'R2': 0.6491693152294201, 'RMSE': 0.004931442198260454}\n",
            "Epoch 1/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00150, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 11ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 2/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0020\n",
            "Epoch 2: val_loss improved from 0.00150 to 0.00142, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 3/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 3: val_loss improved from 0.00142 to 0.00140, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 4/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 4: val_loss improved from 0.00140 to 0.00136, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 5: val_loss improved from 0.00136 to 0.00135, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 6/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 6: val_loss improved from 0.00135 to 0.00134, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 7/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 7: val_loss improved from 0.00134 to 0.00132, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 8/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 8: val_loss improved from 0.00132 to 0.00131, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 9/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 9: val_loss improved from 0.00131 to 0.00130, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 10/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 10: val_loss improved from 0.00130 to 0.00129, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 1.2292e-05 - mse: 2.4585e-05\n",
            "Epoch 1/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 1: val_loss improved from inf to 0.00152, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 15ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 2/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0023        \n",
            "Epoch 2: val_loss improved from 0.00152 to 0.00146, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 3/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0025\n",
            "Epoch 3: val_loss improved from 0.00146 to 0.00142, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 4/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 4: val_loss improved from 0.00142 to 0.00139, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 5/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 5: val_loss improved from 0.00139 to 0.00134, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 6/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0023        \n",
            "Epoch 6: val_loss improved from 0.00134 to 0.00131, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 7/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 7: val_loss improved from 0.00131 to 0.00129, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 8/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 8: val_loss improved from 0.00129 to 0.00126, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 9/10\n",
            "26/35 [=====================>........] - ETA: 0s - loss: 0.0014 - mse: 0.0027    \n",
            "Epoch 9: val_loss improved from 0.00126 to 0.00125, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 10: val_loss improved from 0.00125 to 0.00123, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.2756e-05 - mse: 4.5513e-05\n",
            "Epoch 1/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 1: val_loss improved from inf to 0.00173, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 20ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0017 - val_mse: 0.0035\n",
            "Epoch 2/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 6.8159e-04 - mse: 0.0014\n",
            "Epoch 2: val_loss improved from 0.00173 to 0.00166, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 3/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 4.3869e-04 - mse: 8.7737e-04\n",
            "Epoch 3: val_loss improved from 0.00166 to 0.00160, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0013 - mse: 0.0026        \n",
            "Epoch 4: val_loss improved from 0.00160 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0016 - mse: 0.0032        \n",
            "Epoch 5: val_loss improved from 0.00158 to 0.00156, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 6/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 6: val_loss improved from 0.00156 to 0.00155, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 7/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0015 - mse: 0.0029    \n",
            "Epoch 7: val_loss improved from 0.00155 to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 8/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 4.1014e-04 - mse: 8.2027e-04\n",
            "Epoch 8: val_loss improved from 0.00154 to 0.00153, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 9/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 9: val_loss improved from 0.00153 to 0.00153, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 10/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0017 - mse: 0.0034    \n",
            "Epoch 10: val_loss improved from 0.00153 to 0.00151, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9989e-05 - mse: 5.9978e-05\n",
            "Epoch 1/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 0.0019 - mse: 0.0038         \n",
            "Epoch 1: val_loss improved from inf to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 25ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 2/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 2: val_loss improved from 0.00154 to 0.00150, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 3/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0013 - mse: 0.0026    \n",
            "Epoch 3: val_loss improved from 0.00150 to 0.00147, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 4/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 4: val_loss improved from 0.00147 to 0.00141, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 5/10\n",
            " 9/18 [==============>...............] - ETA: 0s - loss: 0.0019 - mse: 0.0039        \n",
            "Epoch 5: val_loss improved from 0.00141 to 0.00137, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 6: val_loss improved from 0.00137 to 0.00134, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 7/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 9.5171e-04 - mse: 0.0019    \n",
            "Epoch 7: val_loss improved from 0.00134 to 0.00130, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 8/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 4.9121e-04 - mse: 9.8241e-04\n",
            "Epoch 8: val_loss improved from 0.00130 to 0.00127, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 9/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 9: val_loss improved from 0.00127 to 0.00125, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 10/10\n",
            "10/18 [===============>..............] - ETA: 0s - loss: 1.6686e-04 - mse: 3.3372e-04\n",
            "Epoch 10: val_loss improved from 0.00125 to 0.00121, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 3.3335e-05 - mse: 6.6670e-05\n",
            "Epoch 1/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00139, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 9ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 2/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 2: val_loss improved from 0.00139 to 0.00130, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 3/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 3: val_loss improved from 0.00130 to 0.00128, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 4/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 4: val_loss improved from 0.00128 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 5/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 5: val_loss improved from 0.00120 to 0.00117, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 6/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 6: val_loss did not improve from 0.00117\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 7/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021    \n",
            "Epoch 7: val_loss improved from 0.00117 to 0.00113, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 8/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 8: val_loss improved from 0.00113 to 0.00110, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 9/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 9: val_loss improved from 0.00110 to 0.00109, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 10/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 10: val_loss did not improve from 0.00109\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.6163e-05 - mse: 3.2325e-05\n",
            "Epoch 1/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 1: val_loss improved from inf to 0.00145, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 11ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 2: val_loss improved from 0.00145 to 0.00135, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 3/10\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 3: val_loss improved from 0.00135 to 0.00123, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 4/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 4: val_loss improved from 0.00123 to 0.00117, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 5: val_loss improved from 0.00117 to 0.00115, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 6/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 6: val_loss improved from 0.00115 to 0.00112, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 7/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 7: val_loss improved from 0.00112 to 0.00111, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 8/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 8: val_loss improved from 0.00111 to 0.00110, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 9/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 9: val_loss improved from 0.00110 to 0.00107, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 10/10\n",
            "62/70 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 10: val_loss improved from 0.00107 to 0.00106, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 1.3305e-05 - mse: 2.6611e-05\n",
            "Epoch 1/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0025\n",
            "Epoch 1: val_loss improved from inf to 0.00142, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 21ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 2/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 2: val_loss improved from 0.00142 to 0.00138, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 3/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0011 - mse: 0.0021        \n",
            "Epoch 3: val_loss improved from 0.00138 to 0.00133, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021        \n",
            "Epoch 4: val_loss improved from 0.00133 to 0.00129, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 5/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 3.9051e-04 - mse: 7.8101e-04\n",
            "Epoch 5: val_loss improved from 0.00129 to 0.00124, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 6/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021        \n",
            "Epoch 6: val_loss improved from 0.00124 to 0.00123, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 7/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 7: val_loss improved from 0.00123 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 8/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.0013 - mse: 0.0025    \n",
            "Epoch 8: val_loss improved from 0.00120 to 0.00118, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 9/10\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 9.5683e-04 - mse: 0.0019    \n",
            "Epoch 9: val_loss improved from 0.00118 to 0.00118, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 10/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 1.0177e-04 - mse: 2.0354e-04\n",
            "Epoch 10: val_loss did not improve from 0.00118\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.4005e-05 - mse: 4.8011e-05\n",
            "Epoch 1/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 3.3352e-04 - mse: 6.6703e-04\n",
            "Epoch 1: val_loss improved from inf to 0.00144, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 20ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0024    \n",
            "Epoch 2: val_loss improved from 0.00144 to 0.00130, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 3/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 3: val_loss improved from 0.00130 to 0.00124, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 4/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0027        \n",
            "Epoch 4: val_loss improved from 0.00124 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 5/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 3.9606e-04 - mse: 7.9212e-04\n",
            "Epoch 5: val_loss improved from 0.00120 to 0.00119, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 6/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 6: val_loss improved from 0.00119 to 0.00112, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 7/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0021    \n",
            "Epoch 7: val_loss improved from 0.00112 to 0.00110, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 8/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0011 - mse: 0.0022        \n",
            "Epoch 8: val_loss improved from 0.00110 to 0.00108, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 9/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 1.2677e-04 - mse: 2.5354e-04\n",
            "Epoch 9: val_loss improved from 0.00108 to 0.00107, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 10/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 10: val_loss did not improve from 0.00107\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6983e-05 - mse: 5.3967e-05\n",
            "Epoch 1/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00137, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 27ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 2: val_loss improved from 0.00137 to 0.00132, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 3/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 3: val_loss improved from 0.00132 to 0.00127, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 4/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 4: val_loss improved from 0.00127 to 0.00125, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 5: val_loss improved from 0.00125 to 0.00123, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 6/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 1.4132e-04 - mse: 2.8264e-04\n",
            "Epoch 6: val_loss improved from 0.00123 to 0.00122, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 7/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 7: val_loss improved from 0.00122 to 0.00121, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 8/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 8: val_loss improved from 0.00121 to 0.00118, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 9/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 9: val_loss improved from 0.00118 to 0.00117, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021    \n",
            "Epoch 10: val_loss improved from 0.00117 to 0.00115, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 3.2649e-05 - mse: 6.5299e-05\n",
            "Epoch 1/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00133, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 9ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 2/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 2: val_loss improved from 0.00133 to 0.00087, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 8.6502e-04 - val_mse: 0.0017\n",
            "Epoch 3/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 3: val_loss did not improve from 0.00087\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.3181e-04 - val_mse: 0.0019\n",
            "Epoch 4/10\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0025\n",
            "Epoch 4: val_loss improved from 0.00087 to 0.00082, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 8.2185e-04 - val_mse: 0.0016\n",
            "Epoch 5/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 5: val_loss did not improve from 0.00082\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 8.8947e-04 - val_mse: 0.0018\n",
            "Epoch 6/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 6: val_loss did not improve from 0.00082\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 8.7393e-04 - val_mse: 0.0017\n",
            "Epoch 7/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 7: val_loss did not improve from 0.00082\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 8: val_loss did not improve from 0.00082\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 9: val_loss did not improve from 0.00082\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 8.4014e-05 - mse: 1.6803e-04\n",
            "Epoch 1/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00127, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 3s 12ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 2/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 2: val_loss improved from 0.00127 to 0.00103, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 3/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 3: val_loss improved from 0.00103 to 0.00096, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.5768e-04 - val_mse: 0.0019\n",
            "Epoch 4/10\n",
            "61/70 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 4: val_loss improved from 0.00096 to 0.00095, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 9.4992e-04 - val_mse: 0.0019\n",
            "Epoch 5/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0025\n",
            "Epoch 5: val_loss did not improve from 0.00095\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 9.7739e-04 - val_mse: 0.0020\n",
            "Epoch 6/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 6: val_loss improved from 0.00095 to 0.00082, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 8.2065e-04 - val_mse: 0.0016\n",
            "Epoch 7/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 7: val_loss did not improve from 0.00082\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 8: val_loss did not improve from 0.00082\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 9: val_loss did not improve from 0.00082\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 10: val_loss did not improve from 0.00082\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 8.3109e-04 - val_mse: 0.0017\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 3.4699e-05 - mse: 6.9397e-05\n",
            "Epoch 1/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 1: val_loss improved from inf to 0.00115, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 21ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0023    \n",
            "Epoch 2: val_loss did not improve from 0.00115\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "Epoch 3/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0025\n",
            "Epoch 3: val_loss improved from 0.00115 to 0.00103, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 4/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 4: val_loss improved from 0.00103 to 0.00101, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 5/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022        \n",
            "Epoch 5: val_loss improved from 0.00101 to 0.00098, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 9.7880e-04 - val_mse: 0.0020\n",
            "Epoch 6/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 6: val_loss did not improve from 0.00098\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 7/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 7: val_loss did not improve from 0.00098\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 8/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 8: val_loss did not improve from 0.00098\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 9: val_loss did not improve from 0.00098\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.8997e-04 - val_mse: 0.0020\n",
            "Epoch 10/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022        \n",
            "Epoch 10: val_loss did not improve from 0.00098\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.9526e-05 - mse: 3.9053e-05\n",
            "Epoch 1/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00108, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 20ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 2/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 2: val_loss improved from 0.00108 to 0.00102, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 3: val_loss did not improve from 0.00102\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 4/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 5.4595e-04 - mse: 0.0011\n",
            "Epoch 4: val_loss did not improve from 0.00102\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 5: val_loss improved from 0.00102 to 0.00094, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 9.4077e-04 - val_mse: 0.0019\n",
            "Epoch 6/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 6: val_loss improved from 0.00094 to 0.00091, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 9.1094e-04 - val_mse: 0.0018\n",
            "Epoch 7/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 7: val_loss did not improve from 0.00091\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 9.1881e-04 - val_mse: 0.0018\n",
            "Epoch 8/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0015 - mse: 0.0030        \n",
            "Epoch 8: val_loss did not improve from 0.00091\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 9.9919e-04 - val_mse: 0.0020\n",
            "Epoch 9/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 9: val_loss improved from 0.00091 to 0.00089, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 8.8956e-04 - val_mse: 0.0018\n",
            "Epoch 10/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 10: val_loss improved from 0.00089 to 0.00079, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 7.9238e-04 - val_mse: 0.0016\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1550e-05 - mse: 4.3100e-05\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 1: val_loss improved from inf to 0.00117, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 26ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 2/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 2: val_loss improved from 0.00117 to 0.00112, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 3/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 8.9254e-04 - mse: 0.0018    \n",
            "Epoch 3: val_loss improved from 0.00112 to 0.00101, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 4/10\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0012 - mse: 0.0025        \n",
            "Epoch 4: val_loss did not improve from 0.00101\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 5/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0024    \n",
            "Epoch 5: val_loss improved from 0.00101 to 0.00100, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.9807e-04 - val_mse: 0.0020\n",
            "Epoch 6/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 6: val_loss improved from 0.00100 to 0.00096, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 9.5586e-04 - val_mse: 0.0019\n",
            "Epoch 7/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 7: val_loss did not improve from 0.00096\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 9.7143e-04 - val_mse: 0.0019\n",
            "Epoch 8/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 8: val_loss did not improve from 0.00096\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 9.5669e-04 - val_mse: 0.0019\n",
            "Epoch 9/10\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0012 - mse: 0.0025    \n",
            "Epoch 9: val_loss improved from 0.00096 to 0.00092, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 9.2064e-04 - val_mse: 0.0018\n",
            "Epoch 10/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 10: val_loss did not improve from 0.00092\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 9.4522e-04 - val_mse: 0.0019\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 2.2288e-05 - mse: 4.4576e-05\n",
            "Epoch 1/10\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.0035 - mse: 0.0070\n",
            "Epoch 1: val_loss improved from inf to 0.00162, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 9ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 2: val_loss did not improve from 0.00162\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 3/10\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 3: val_loss did not improve from 0.00162\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 4/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 4: val_loss did not improve from 0.00162\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 5/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 5: val_loss improved from 0.00162 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 6: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.0019 - mse: 0.0039\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0037 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 9ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.2140e-04 - mse: 2.4280e-04\n",
            "Epoch 1/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0682 - mse: 0.3808\n",
            "Epoch 1: val_loss improved from inf to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 11ms/step - loss: 0.0618 - mse: 0.3448 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "62/70 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 2: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 3/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 3: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 4: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 6/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 7.8140e-05 - mse: 1.5628e-04\n",
            "Epoch 1/10\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 1: val_loss improved from inf to 0.00191, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 16ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 2/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 2: val_loss improved from 0.00191 to 0.00172, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 3/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 6.9420e-04 - mse: 0.0014\n",
            "Epoch 3: val_loss improved from 0.00172 to 0.00161, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 4: val_loss improved from 0.00161 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 5: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0029        \n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 7/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 8/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 8.8129e-04 - mse: 0.0018\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0025 - val_mse: 0.0050\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0025        \n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.3256e-04 - mse: 2.6513e-04\n",
            "Epoch 1/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0036 - mse: 0.0073\n",
            "Epoch 1: val_loss improved from inf to 0.01972, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 23ms/step - loss: 0.0036 - mse: 0.0073 - val_loss: 0.0197 - val_mse: 0.0792\n",
            "Epoch 2/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0022 - mse: 0.0044\n",
            "Epoch 2: val_loss improved from 0.01972 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.0015 - mse: 0.0031        \n",
            "Epoch 3: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 4: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 5: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 7/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 7: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0018 - val_mse: 0.0037\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6939e-04 - mse: 3.3879e-04\n",
            "Epoch 1/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0024 - mse: 0.0049\n",
            "Epoch 1: val_loss improved from inf to 0.00198, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 26ms/step - loss: 0.0024 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 2/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 2: val_loss improved from 0.00198 to 0.00165, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 3/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 3: val_loss improved from 0.00165 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 4: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 7.7910e-04 - mse: 0.0016    \n",
            "Epoch 5: val_loss improved from 0.00159 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0019 - val_mse: 0.0038\n",
            "Epoch 7/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 7: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 8/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 8: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0019 - val_mse: 0.0037\n",
            "Epoch 9/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 9: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 9.5057e-05 - mse: 1.9011e-04\n",
            "Epoch 1/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0168 - mse: 0.0473\n",
            "Epoch 1: val_loss improved from inf to 0.00176, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 12ms/step - loss: 0.0161 - mse: 0.0452 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 2/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 2: val_loss improved from 0.00176 to 0.00168, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 3/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 3: val_loss did not improve from 0.00168\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0017 - val_mse: 0.0035\n",
            "Epoch 4/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 4: val_loss improved from 0.00168 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0020 - mse: 0.0039\n",
            "Epoch 5: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 6/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 7/10\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 7: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0033 - val_mse: 0.0066\n",
            "Epoch 8/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0020 - mse: 0.0040\n",
            "Epoch 8: val_loss did not improve from 0.00159\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0020 - mse: 0.0039 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 9/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0019 - mse: 0.0037\n",
            "Epoch 9: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0025 - val_mse: 0.0051\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0746e-04 - mse: 2.1493e-04\n",
            "Epoch 1/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0080 - mse: 0.0159\n",
            "Epoch 1: val_loss improved from inf to 0.00161, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 12ms/step - loss: 0.0075 - mse: 0.0151 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 2: val_loss improved from 0.00161 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 3: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 4: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0018 - val_mse: 0.0037\n",
            "Epoch 6/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0016 - mse: 0.0033\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 7/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0026 - val_mse: 0.0051\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.2882e-04 - mse: 2.5764e-04\n",
            "Epoch 1/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0513 - mse: 0.1147\n",
            "Epoch 1: val_loss improved from inf to 0.00163, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 3s 17ms/step - loss: 0.0495 - mse: 0.1103 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 2/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0020 - mse: 0.0039\n",
            "Epoch 2: val_loss did not improve from 0.00163\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 3/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 3: val_loss improved from 0.00163 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 4: val_loss did not improve from 0.00159\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 5/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 5: val_loss improved from 0.00159 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 8: val_loss improved from 0.00158 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 10/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.9190e-05 - mse: 1.9838e-04\n",
            "Epoch 1/10\n",
            "18/24 [=====================>........] - ETA: 0s - loss: 0.1308 - mse: 0.3981\n",
            "Epoch 1: val_loss improved from inf to 0.00408, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 21ms/step - loss: 0.1020 - mse: 0.3099 - val_loss: 0.0041 - val_mse: 0.0082\n",
            "Epoch 2/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0022 - mse: 0.0044\n",
            "Epoch 2: val_loss improved from 0.00408 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0041 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 3: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 6.6363e-04 - mse: 0.0013\n",
            "Epoch 4: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 5: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0021 - val_mse: 0.0041\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0029    \n",
            "Epoch 6: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0027    \n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.5489e-05 - mse: 1.9098e-04\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 1.8359 - mse: 123.9581\n",
            "Epoch 1: val_loss improved from inf to 0.00937, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 27ms/step - loss: 1.8359 - mse: 123.9581 - val_loss: 0.0094 - val_mse: 0.0187\n",
            "Epoch 2/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0067 - mse: 0.0134\n",
            "Epoch 2: val_loss improved from 0.00937 to 0.00311, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0116 - val_loss: 0.0031 - val_mse: 0.0062\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 3: val_loss improved from 0.00311 to 0.00227, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0023 - val_mse: 0.0045\n",
            "Epoch 4/10\n",
            "13/18 [====================>.........] - ETA: 0s - loss: 5.1259e-04 - mse: 0.0010    \n",
            "Epoch 4: val_loss improved from 0.00227 to 0.00225, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0023 - val_mse: 0.0045\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 5: val_loss improved from 0.00225 to 0.00200, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 6: val_loss did not improve from 0.00200\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0021 - val_mse: 0.0042\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0027\n",
            "Epoch 7: val_loss did not improve from 0.00200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 8/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 8: val_loss did not improve from 0.00200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0021 - val_mse: 0.0042\n",
            "Epoch 9/10\n",
            "13/18 [====================>.........] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 9: val_loss did not improve from 0.00200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0021 - val_mse: 0.0042\n",
            "Epoch 10/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 6.2202e-04 - mse: 0.0012    \n",
            "Epoch 10: val_loss did not improve from 0.00200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0021 - val_mse: 0.0041\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 6.2376e-05 - mse: 1.2475e-04\n",
            "Epoch 1/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.3365 - mse: 15.0011\n",
            "Epoch 1: val_loss improved from inf to 0.00203, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 10ms/step - loss: 0.3215 - mse: 14.3329 - val_loss: 0.0020 - val_mse: 0.0041\n",
            "Epoch 2/10\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 2: val_loss improved from 0.00203 to 0.00169, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 3/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 3: val_loss did not improve from 0.00169\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 4/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 4: val_loss did not improve from 0.00169\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0037 - val_mse: 0.0075\n",
            "Epoch 5/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0021 - mse: 0.0041\n",
            "Epoch 5: val_loss did not improve from 0.00169\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0022 - mse: 0.0043 - val_loss: 0.0036 - val_mse: 0.0071\n",
            "Epoch 6/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0020 - mse: 0.0039\n",
            "Epoch 6: val_loss did not improve from 0.00169\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0020 - mse: 0.0040 - val_loss: 0.0028 - val_mse: 0.0057\n",
            "Epoch 7/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0023 - mse: 0.0046\n",
            "Epoch 7: val_loss improved from 0.00169 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0022 - mse: 0.0044 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 8/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0022 - mse: 0.0044\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 10/10\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.0024 - mse: 0.0048\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0023 - mse: 0.0047 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 9.4439e-05 - mse: 1.8888e-04\n",
            "Epoch 1/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.1304 - mse: 1.1438\n",
            "Epoch 1: val_loss improved from inf to 0.00160, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 3s 20ms/step - loss: 0.1199 - mse: 1.0518 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 2/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 2: val_loss did not improve from 0.00160\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 3/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0029    \n",
            "Epoch 3: val_loss did not improve from 0.00160\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 4/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 4: val_loss did not improve from 0.00160\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0018 - mse: 0.0037\n",
            "Epoch 5: val_loss did not improve from 0.00160\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 6/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 6: val_loss improved from 0.00160 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 7: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0030 - val_mse: 0.0060\n",
            "Epoch 8/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 8: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 9/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 9: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 10/10\n",
            "64/70 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.0016 - mse: 0.0031 - val_loss: 0.0023 - val_mse: 0.0046\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.0652e-04 - mse: 2.1304e-04\n",
            "Epoch 1/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1223 - mse: 0.3195\n",
            "Epoch 1: val_loss improved from inf to 0.00416, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 2s 17ms/step - loss: 0.1223 - mse: 0.3195 - val_loss: 0.0042 - val_mse: 0.0083\n",
            "Epoch 2/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0019 - mse: 0.0037\n",
            "Epoch 2: val_loss improved from 0.00416 to 0.00166, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0035 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 3/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 3.4782e-04 - mse: 6.9564e-04\n",
            "Epoch 3: val_loss did not improve from 0.00166\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0021 - val_mse: 0.0041\n",
            "Epoch 4/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 4: val_loss improved from 0.00166 to 0.00163, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 5/10\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0027    \n",
            "Epoch 5: val_loss did not improve from 0.00163\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 6/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 6: val_loss did not improve from 0.00163\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 7/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 7: val_loss did not improve from 0.00163\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0019 - val_mse: 0.0037\n",
            "Epoch 8/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0033\n",
            "Epoch 8: val_loss did not improve from 0.00163\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0017 - val_mse: 0.0035\n",
            "Epoch 9/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 9: val_loss improved from 0.00163 to 0.00158, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 10/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 10: val_loss did not improve from 0.00158\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.1860e-05 - mse: 1.8372e-04\n",
            "Epoch 1/10\n",
            "17/24 [====================>.........] - ETA: 0s - loss: 0.1055 - mse: 0.2863\n",
            "Epoch 1: val_loss improved from inf to 0.00246, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 21ms/step - loss: 0.0775 - mse: 0.2102 - val_loss: 0.0025 - val_mse: 0.0049\n",
            "Epoch 2/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 2: val_loss improved from 0.00246 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 3/10\n",
            "20/24 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 3: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0018 - val_mse: 0.0035\n",
            "Epoch 4/10\n",
            "16/24 [===================>..........] - ETA: 0s - loss: 7.4396e-04 - mse: 0.0015\n",
            "Epoch 4: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 5: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0033\n",
            "Epoch 6/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0028    \n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 7/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 7: val_loss did not improve from 0.00159\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2161e-05 - mse: 1.2432e-04\n",
            "Epoch 1/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 7.6052 - mse: 985.2321  \n",
            "Epoch 1: val_loss improved from inf to 0.01265, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 27ms/step - loss: 6.9941 - mse: 905.9621 - val_loss: 0.0126 - val_mse: 0.0253\n",
            "Epoch 2/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0044 - mse: 0.0088\n",
            "Epoch 2: val_loss improved from 0.01265 to 0.00372, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0037 - val_mse: 0.0074\n",
            "Epoch 3/10\n",
            "13/18 [====================>.........] - ETA: 0s - loss: 0.0024 - mse: 0.0047\n",
            "Epoch 3: val_loss improved from 0.00372 to 0.00159, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0019 - mse: 0.0038 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 4/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0032    \n",
            "Epoch 4: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0017 - val_mse: 0.0034\n",
            "Epoch 5/10\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 5: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 6/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024        \n",
            "Epoch 6: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 7/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 7: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 8/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 7.0538e-04 - mse: 0.0014\n",
            "Epoch 8: val_loss did not improve from 0.00159\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 1.7640e-04 - mse: 3.5281e-04\n",
            "Epoch 1/10\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0025    \n",
            "Epoch 1: val_loss improved from inf to 0.00135, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 9ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0013 - val_mse: 0.0027\n",
            "Epoch 2/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 2: val_loss improved from 0.00135 to 0.00120, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 3/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 3: val_loss improved from 0.00120 to 0.00114, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 4/10\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 4: val_loss improved from 0.00114 to 0.00105, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 5/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 5: val_loss improved from 0.00105 to 0.00103, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 6/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0021    \n",
            "Epoch 6: val_loss did not improve from 0.00103\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 7/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 7: val_loss improved from 0.00103 to 0.00100, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 8/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 8: val_loss improved from 0.00100 to 0.00098, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 9.8125e-04 - val_mse: 0.0020\n",
            "Epoch 9/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 9: val_loss improved from 0.00098 to 0.00096, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 9.5919e-04 - val_mse: 0.0019\n",
            "Epoch 10/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 3.5721e-04 - mse: 7.1441e-04\n",
            "Epoch 10: val_loss did not improve from 0.00096\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0962e-05 - mse: 2.1925e-05\n",
            "0.0046824092387198835\n",
            "{'activation': 'relu', 'output_dim_lstm': 16, 'output_dim_dense': 16, 'learning_rate': 0.0005, 'batch_size': 5, 'MSE': [1.0962480700982269e-05, 2.1924961401964538e-05], 'R2': 0.6837078503115039, 'RMSE': 0.0046824092387198835}\n",
            "Epoch 1/10\n",
            "69/70 [============================>.] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 1: val_loss improved from inf to 0.00127, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 2s 11ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 2: val_loss improved from 0.00127 to 0.00114, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 3/10\n",
            "66/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 3: val_loss improved from 0.00114 to 0.00109, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 4/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 4: val_loss improved from 0.00109 to 0.00106, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 5: val_loss improved from 0.00106 to 0.00104, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 6/10\n",
            "67/70 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 6: val_loss improved from 0.00104 to 0.00103, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 7/10\n",
            "65/70 [==========================>...] - ETA: 0s - loss: 8.5825e-04 - mse: 0.0017    \n",
            "Epoch 7: val_loss improved from 0.00103 to 0.00103, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 8/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 8: val_loss improved from 0.00103 to 0.00100, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 9/10\n",
            "63/70 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 9: val_loss did not improve from 0.00100\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 10/10\n",
            "68/70 [============================>.] - ETA: 0s - loss: 0.0010 - mse: 0.0021\n",
            "Epoch 10: val_loss improved from 0.00100 to 0.00099, saving model to model/tmp_checkpoint.h5\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 9.9019e-04 - val_mse: 0.0020\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 1.2884e-05 - mse: 2.5767e-05\n",
            "Epoch 1/10\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0025    \n",
            "Epoch 1: val_loss improved from inf to 0.00126, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 3s 17ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 2/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 2: val_loss improved from 0.00126 to 0.00119, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 3/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 3: val_loss improved from 0.00119 to 0.00113, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0011 - val_mse: 0.0023\n",
            "Epoch 4/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022        \n",
            "Epoch 4: val_loss improved from 0.00113 to 0.00108, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 5/10\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 5: val_loss improved from 0.00108 to 0.00105, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 6/10\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 6: val_loss improved from 0.00105 to 0.00104, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 7/10\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 7: val_loss improved from 0.00104 to 0.00101, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 8/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 8.9194e-04 - mse: 0.0018    \n",
            "Epoch 8: val_loss improved from 0.00101 to 0.00100, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 9.9732e-04 - val_mse: 0.0020\n",
            "Epoch 9/10\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 9: val_loss did not improve from 0.00100\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 10/10\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0023        \n",
            "Epoch 10: val_loss improved from 0.00100 to 0.00099, saving model to model/tmp_checkpoint.h5\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 9.9335e-04 - val_mse: 0.0020\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.7696e-05 - mse: 7.5393e-05\n",
            "Epoch 1/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0028    \n",
            "Epoch 1: val_loss improved from inf to 0.00164, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 2s 22ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0016 - val_mse: 0.0033\n",
            "Epoch 2/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 2: val_loss improved from 0.00164 to 0.00155, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0016 - val_mse: 0.0031\n",
            "Epoch 3/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 3: val_loss improved from 0.00155 to 0.00150, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 4/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 4: val_loss improved from 0.00150 to 0.00146, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 5: val_loss improved from 0.00146 to 0.00140, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 6: val_loss improved from 0.00140 to 0.00137, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 7/10\n",
            "19/24 [======================>.......] - ETA: 0s - loss: 5.1931e-04 - mse: 0.0010    \n",
            "Epoch 7: val_loss improved from 0.00137 to 0.00132, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 8/10\n",
            "21/24 [=========================>....] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 8: val_loss improved from 0.00132 to 0.00129, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 9/10\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 9: val_loss improved from 0.00129 to 0.00126, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0013 - val_mse: 0.0025\n",
            "Epoch 10/10\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 8.9895e-04 - mse: 0.0018\n",
            "Epoch 10: val_loss improved from 0.00126 to 0.00123, saving model to model/tmp_checkpoint.h5\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0025\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8415e-05 - mse: 5.6829e-05\n",
            "Epoch 1/10\n",
            "13/18 [====================>.........] - ETA: 0s - loss: 0.0013 - mse: 0.0026        \n",
            "Epoch 1: val_loss improved from inf to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 29ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 2/10\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 2: val_loss improved from 0.00154 to 0.00151, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 3/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0027    \n",
            "Epoch 3: val_loss improved from 0.00151 to 0.00149, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 4/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 4: val_loss improved from 0.00149 to 0.00146, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 5/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 5: val_loss improved from 0.00146 to 0.00143, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 0.0014 - val_mse: 0.0029\n",
            "Epoch 6/10\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 6: val_loss improved from 0.00143 to 0.00141, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 7/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0013 - mse: 0.0026        \n",
            "Epoch 7: val_loss improved from 0.00141 to 0.00139, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0014 - val_mse: 0.0028\n",
            "Epoch 8/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0025        \n",
            "Epoch 8: val_loss improved from 0.00139 to 0.00136, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0014 - val_mse: 0.0027\n",
            "Epoch 9/10\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 5.2511e-04 - mse: 0.0011    \n",
            "Epoch 9: val_loss improved from 0.00136 to 0.00132, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 10/10\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 4.5588e-04 - mse: 9.1177e-04\n",
            "Epoch 10: val_loss improved from 0.00132 to 0.00129, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 2.2107e-05 - mse: 4.4213e-05\n",
            "Epoch 1/10\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 1: val_loss improved from inf to 0.00129, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 3s 9ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 2/10\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 2: val_loss improved from 0.00129 to 0.00121, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 3/10\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 3: val_loss improved from 0.00121 to 0.00116, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 4/10\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0011 - mse: 0.0021\n",
            "Epoch 4: val_loss improved from 0.00116 to 0.00116, saving model to model/tmp_checkpoint.h5\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 5/10\n",
            " 15/140 [==>...........................] - ETA: 0s - loss: 0.0066 - mse: 0.0131"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3f885bd7b395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                               callbacks=[early_stop, checkpoint])\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2687\u001b[0m           f\"hashable.  Original error: {e}.\")\n\u001b[1;32m   2688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m     \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, key, use_function_subtyping)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mdispatch_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdispatch_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdispatch_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return (self.call_context == other.call_context and\n\u001b[0;32m---> 86\u001b[0;31m             self.function_signature == other.function_signature)\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    330\u001b[0m     return isinstance(\n\u001b[1;32m    331\u001b[0m         \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     ) and self.identifier == other.identifier and self.base == other.base\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     return (type(other) is type(self) and\n\u001b[0;32m--> 441\u001b[0;31m             self.__get_cmp_key() == other.__get_cmp_key())\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;34m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;31m# TODO(b/133606651): Decide whether to cache this value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    515\u001b[0m       ])\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    515\u001b[0m       ])\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    515\u001b[0m       ])\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    515\u001b[0m       ])\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;34m\"\"\"Converts `value` to a hashable key.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     if isinstance(value, (int, float, bool, np.generic, dtypes.DType, TypeSpec,\n\u001b[0;32m--> 504\u001b[0;31m                           tensor_shape.TensorShape)):\n\u001b[0m\u001b[1;32m    505\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytes_or_text_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_df"
      ],
      "metadata": {
        "id": "yqKwSAoFSIC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여기서부터 건들 ㄴㄴ\n"
      ],
      "metadata": {
        "id": "t50arYWOi4as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(LSTM(256, \n",
        "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
        "               activation='sigmoid', \n",
        "               return_sequences=False)\n",
        "          )\n",
        "model.add(Dense(16, activation='relu'))\n",
        "#model.add(Flatten())\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "8W7EMU_UiKi7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "loss = Huber()\n",
        "optimizer = Adam(0.3)\n",
        "model.compile(loss=Huber(), optimizer=optimizer, metrics=['mse'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model_path = 'model'\n",
        "filename = os.path.join(model_path, 'tmp_checkpoint.h5')\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                                    epochs=100, \n",
        "                                    batch_size=40,\n",
        "                                    validation_data=(x_valid, y_valid), \n",
        "                                    callbacks=[early_stop, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1aykEIEiNVj",
        "outputId": "26847901-014c-4f9b-8200-4b0a8e099c74"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0113 - mse: 0.0227\n",
            "Epoch 1: val_loss improved from inf to 0.00199, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 2s 64ms/step - loss: 0.0112 - mse: 0.0224 - val_loss: 0.0020 - val_mse: 0.0040\n",
            "Epoch 2/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0023 - mse: 0.0047\n",
            "Epoch 2: val_loss improved from 0.00199 to 0.00154, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 3/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 3: val_loss improved from 0.00154 to 0.00151, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 4/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 4: val_loss did not improve from 0.00151\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 5: val_loss did not improve from 0.00151\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0015 - val_mse: 0.0031\n",
            "Epoch 6/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 6: val_loss improved from 0.00151 to 0.00151, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 7/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 7: val_loss improved from 0.00151 to 0.00151, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 8/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 8: val_loss improved from 0.00151 to 0.00148, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 0.0015 - val_mse: 0.0030\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 9: val_loss did not improve from 0.00148\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0018 - val_mse: 0.0036\n",
            "Epoch 10/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 10: val_loss improved from 0.00148 to 0.00147, saving model to model/tmp_checkpoint.h5\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 11/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 11: val_loss did not improve from 0.00147\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0021 - val_mse: 0.0041\n",
            "Epoch 12/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 12: val_loss did not improve from 0.00147\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 13/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 13: val_loss did not improve from 0.00147\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0015 - val_mse: 0.0029\n",
            "Epoch 14/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 14: val_loss did not improve from 0.00147\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0016 - val_mse: 0.0032\n",
            "Epoch 15/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 15: val_loss did not improve from 0.00147\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0015 - val_mse: 0.0030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filename)\n",
        "pred = model.predict(test_feature)\n",
        "\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBzy9CFXiSYE",
        "outputId": "8f8d7730-ab4b-4830-dcb4-0f797502117c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(212, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgYxUySUG0M_",
        "outputId": "190e3fa9-cd36-4516-f9db-5595cd25fbdd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.12462908 0.02565163 0.01654001 0.0220596 ]\n",
            "  [0.13204748 0.02306578 0.01654001 0.02078819]\n",
            "  [0.13946588 0.02565163 0.01933393 0.02353176]\n",
            "  ...\n",
            "  [0.15430267 0.03728796 0.02631873 0.03303386]\n",
            "  [0.12462908 0.01789408 0.01654001 0.01804463]\n",
            "  [0.0504451  0.00884361 0.01095217 0.01001468]]\n",
            "\n",
            " [[0.13204748 0.02306578 0.01654001 0.02078819]\n",
            "  [0.13946588 0.02565163 0.01933393 0.02353176]\n",
            "  [0.15430267 0.02823748 0.02771569 0.02901889]\n",
            "  ...\n",
            "  [0.12462908 0.01789408 0.01654001 0.01804463]\n",
            "  [0.0504451  0.00884361 0.01095217 0.01001468]\n",
            "  [0.12462908 0.02306578 0.01654001 0.02072128]]\n",
            "\n",
            " [[0.13946588 0.02565163 0.01933393 0.02353176]\n",
            "  [0.15430267 0.02823748 0.02771569 0.02901889]\n",
            "  [0.15430267 0.03728796 0.02631873 0.03303386]\n",
            "  ...\n",
            "  [0.0504451  0.00884361 0.01095217 0.01001468]\n",
            "  [0.12462908 0.02306578 0.01654001 0.02072128]\n",
            "  [0.13204748 0.02306578 0.01654001 0.02078819]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.07418398 0.00281858 0.00226308 0.00294833]\n",
            "  [0.0074184  0.00346504 0.00318507 0.00312231]\n",
            "  [0.03264095 0.00524928 0.00328286 0.00432011]\n",
            "  ...\n",
            "  [0.07418398 0.00478382 0.00310125 0.00436695]\n",
            "  [0.0074184  0.00496483 0.00592311 0.0052101 ]\n",
            "  [0.02522255 0.00633533 0.00419088 0.00525025]]\n",
            "\n",
            " [[0.0074184  0.00346504 0.00318507 0.00312231]\n",
            "  [0.03264095 0.00524928 0.00328286 0.00432011]\n",
            "  [0.08160237 0.00186181 0.00547608 0.00405914]\n",
            "  ...\n",
            "  [0.0074184  0.00496483 0.00592311 0.0052101 ]\n",
            "  [0.02522255 0.00633533 0.00419088 0.00525025]\n",
            "  [0.0578635  0.00160323 0.00332477 0.00268066]]\n",
            "\n",
            " [[0.03264095 0.00524928 0.00328286 0.00432011]\n",
            "  [0.08160237 0.00186181 0.00547608 0.00405914]\n",
            "  [0.07418398 0.00478382 0.00310125 0.00436695]\n",
            "  ...\n",
            "  [0.02522255 0.00633533 0.00419088 0.00525025]\n",
            "  [0.0578635  0.00160323 0.00332477 0.00268066]\n",
            "  [0.         0.00217211 0.00097787 0.00132896]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "mse,mae = model.evaluate(test_feature , test_label, batch_size=16)\n",
        "print(\"mse : \", mse)\n",
        "print(\"mae : \", mae)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def RMSE(y_test, y_predict):\n",
        "    return np.sqrt(mean_squared_error(test_label, pred))\n",
        "print('RMSE : ', RMSE(test_label, pred))\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2_y_predict = r2_score(test_label, pred)\n",
        "print('R2 : ', r2_y_predict)\n",
        "\n",
        "from sklearn.metrics import median_absolute_error\n",
        "MedAE_y_predict = median_absolute_error(test_label, pred)\n",
        "print('MedAE : ', MedAE_y_predict)"
      ],
      "metadata": {
        "id": "8ASCaLYJmi9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a73fd0d-2315-4244-8d22-49bac0863c4b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 23ms/step - loss: 7.2224e-05 - mse: 1.4445e-04\n",
            "mse :  7.222428394015878e-05\n",
            "mae :  0.00014444856788031757\n",
            "RMSE :  0.012018676323940804\n",
            "R2 :  -1.0838332122498038\n",
            "MedAE :  0.013329710935314766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(test_label, label = 'actual')\n",
        "plt.plot(pred, label = 'prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "FP7Wpq5fiWYa",
        "outputId": "21b92057-7991-48d7-ede9-acc6d988a0e2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAIICAYAAACRnwO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebRkZX33+3323jWcsSe6aaAJ3QqhGVoItBGCGbkafB1Qo69x6c34mpgsk7vy3ihkuL73dZk3mrUSojdk4I0G41XjKwlXgohRARkEpUEUaBpo6AZ6Hk73qTPUsIfn/rH3s2tX1a6qPTyne586389aLE6frnrOrqpTXd/93d/n+xNSShBCCCGEEEKGY5zuAyCEEEIIIWS5QPFMCCGEEEJIQiieCSGEEEIISQjFMyGEEEIIIQmheCaEEEIIISQhFM+EEEIIIYQkxDrdB5CGM844Q27evPl0HwYhhBBCCBlhHnvssWNSyvVxf7esxPPmzZuxY8eO030YhBBCCCFkhBFCvNTv7xjbIIQQQgghJCEUz4QQQgghhCSE4pkQQgghhJCELKvMMyGEEELISsW2bezbtw+NRuN0H8rIUK1WsWnTJpRKpcT3oXgmhBBCCFkG7Nu3D1NTU9i8eTOEEKf7cJY9UkocP34c+/btw5YtWxLfj7ENQgghhJBlQKPRwLp16yicNSGEwLp161I7+RTPhBBCCCHLBApnvWR5PimeCSGEEEKIdu677z5897vfzbXG5OSkpqPRB8UzIYQQQgjRjg7xXEQongkhhBBCSGLe/va348orr8Qll1yCW265BQBw991344orrsBll12Ga6+9Fnv37sXf//3f46abbsLll1+OBx54AL/2a7+G2267LVxHucrz8/O49tprccUVV2Dbtm346le/eloeV1LYtkEIIYQQssz47//+NHYeqGld8+Kzp/Hf3nrJ0Nt99rOfxdq1a1Gv1/Ha174W119/PT7wgQ/g/vvvx5YtWzAzM4O1a9figx/8ICYnJ/GHf/iHAIDPfOYzsetVq1XcfvvtmJ6exrFjx3DVVVfhbW97W2Hz3RTPhBBCCCEkMZ/+9Kdx++23AwBeeeUV3HLLLfiZn/mZsO5t7dq1qdaTUuKP//iPcf/998MwDOzfvx+HDx/Gxo0btR+7DiieCSGEEEKWGUkc4qXgvvvuw7e+9S08/PDDGB8fx8/93M/h8ssvx65du4be17IseJ4HAPA8D61WCwDwhS98AUePHsVjjz2GUqmEzZs3F3oQDDPPhBBCCCEkEbOzs1izZg3Gx8exa9cuPPLII2g0Grj//vuxZ88eAMDMzAwAYGpqCnNzc+F9N2/ejMceewwAcMcdd8C27XDNDRs2oFQq4d5778VLL710ih9VOiieCSGEEEJIIq677jo4joOLLroIN954I6666iqsX78et9xyC975znfisssuw3ve8x4AwFvf+lbcfvvt4YbBD3zgA/jOd76Dyy67DA8//DAmJiYAAO973/uwY8cObNu2Df/8z/+MrVu3ns6HOBQhpTzdx5CY7du3yx07dpzuwyCEEEIIOeU888wzuOiii073YYwccc+rEOIxKeX2uNvTeSaEEEIIISQhFM+EEEIIIYQkhOKZEEIIIYSQhFA8a6TleHj7zQ/hkRePn+5DIYQQQgghSwDFs0ZmFlp44pWT2if+EEIIIYSQYkDxrJGG7QIAXG/5NJgQQgghhJDkUDxrpOH44tmheCaEEEIIGch9992Ht7zlLQD8oSmf+MQn+t725MmT+Nu//dvwzwcOHMC73vWuJT/GOCieNdKwg5GTy6g7mxBCCCFEJ67rpr7P2972Ntx44419/75bPJ999tm47bbbMh1fXiieNaJiG45L8UwIIYSQ0WPv3r3YunUr3ve+9+Giiy7Cu971LiwuLmLz5s244YYbcMUVV+ArX/kK/uM//gNXX301rrjiCrz73e/G/Pw8AODuu+/G1q1bccUVV+Df/u3fwnVvvfVWfOhDHwIAHD58GO94xztw2WWX4bLLLsN3v/td3HjjjXjhhRdw+eWX48Mf/jD27t2LSy+9FADQaDTw67/+69i2bRt+4id+Avfee2+45jvf+U5cd911uOCCC/CRj3xEy3NgaVmFAIhknuk8E0IIIWQp+fqNwKEn9a65cRvwpv7RCcWzzz6Lz3zmM7jmmmvwG7/xG6EjvG7dOjz++OM4duwY3vnOd+Jb3/oWJiYm8MlPfhJ/9Vd/hY985CP4wAc+gHvuuQfnn39+OMa7m9///d/Hz/7sz+L222+H67qYn5/HJz7xCTz11FN44oknAPgiXnHzzTdDCIEnn3wSu3btwhvf+EY899xzAIAnnngCP/jBD1CpVHDhhRfi937v93DuuefmeproPGtExTZczzvNR0IIIYQQsjSce+65uOaaawAA73//+/Hggw8CQCiGH3nkEezcuRPXXHMNLr/8cnzuc5/DSy+9hF27dmHLli244IILIITA+9///tj177nnHvzO7/wOAMA0TaxatWrg8Tz44IPhWlu3bsV5550Xiudrr70Wq1atQrVaxcUXX4yXXnop9+On86yRJjcMEkIIIeRUkMAhXiqEELF/npiYAABIKfGGN7wBX/rSlzpup1zjU0mlUgm/Nk0TjuPkXpPOs0ZUbMOjeCaEEELIiPLyyy/j4YcfBgB88YtfxOtf//qOv7/qqqvw0EMPYffu3QCAhYUFPPfcc9i6dSv27t2LF154AQB6xLXi2muvxd/93d8B8Dcfzs7OYmpqCnNzc7G3/+mf/ml84QtfAAA899xzePnll3HhhRfmf6B9oHjWiIpt0HkmhBBCyKhy4YUX4uabb8ZFF12EEydOhBELxfr163Hrrbfive99L17zmtfg6quvxq5du1CtVnHLLbfgzW9+M6644gps2LAhdv1PfepTuPfee7Ft2zZceeWV2LlzJ9atW4drrrkGl156KT784Q933P53f/d34Xketm3bhve85z249dZbOxxn3Qi5jDa3bd++Xe7YseN0H0Zf/uE7L+DPv74Lv3L1efjY9Zee7sMhhBBCyAjxzDPP4KKLLjqtx7B371685S1vwVNPPXVaj0Mncc+rEOIxKeX2uNvTedZIe8Pg8jkhIYQQQgghyaF41oiaMEjxTAghhJBRZPPmzSPlOmeB4lkj4ZAUimdCCCGEkJGE4lkj4XhuimdCCCGELAHLaa/aciDL80nxrJEmnWdCCCGELBHVahXHjx+ngNaElBLHjx9HtVpNdT8OSdEIM8+EEEIIWSo2bdqEffv24ejRo6f7UEaGarWKTZs2pboPxbNG6i2KZ0IIIYQsDaVSCVu2bDndh7HiYWxDIxySQgghhBAy2lA8a0TFNjxmkQghhBBCRhKKZ43QeSaEEEIIGW0onjWi2jZczzvNR0IIIYQQQpYCimeNNGxuGCSEEEIIGWUonjXScHzHmeKZEEIIIWQ0oXjWCMdzE0IIIYSMNhTPmpBShuKZ47kJIYQQQkYTimdN2K6E0sx0ngkhhBBCRhOKZ02ojmeAmWdCCCGEkFGF4lkTKrIBUDwTQoDv7j6GN3/6AbQcVlcSQsgoQfGsiabd/oCkeCaE7DxYw9MHaqg17NN9KIQQQjRC8awJ5TxbhmDmmRAC2/X/HeDJNCGEjBYUz5pQo7knKhY/LAkhcFz/3wSeTBNCyGhB8awJtWFwkuKZEALADv4dcF3+e0AIIaMExbMmVGxjvGzSaSKERJxnbhgkhJBRguJZE/VW4DxXLXiS4pmQlY46ieaVKEIIGS0onjXRCOqoJitW6Djp4B8feBHfee6otvXufuogvvC9l7StRwiJx2bmmRBCRhKKZ01EYxs6Pyv/7r4X8NUn9mtb74vffwX//F2KZ0KWGodtG4QQMpIkEs9CiOuEEM8KIXYLIW6M+fuKEOLLwd9/TwixOfj+Twohngj++6EQ4h1J11xuNAPxPFGxtGUcpZSYrdtaP3xn6zYzmIScAtT7zNZ4JYoQQsjpZ6h4FkKYAG4G8CYAFwN4rxDi4q6b/SaAE1LK8wHcBOCTwfefArBdSnk5gOsA/IMQwkq45rJCVdXpbNuo2y4cT2q97DunWYwTQuKh80wIIaNJEuf5JwHsllK+KKVsAfgXANd33eZ6AJ8Lvr4NwLVCCCGlXJRSOsH3qwDUp0iSNZcV7diGPvFcq/tPnc6qq1rDZgaTkFOAep/x/UYIIaNFEvF8DoBXIn/eF3wv9jaBWJ4FsA4AhBCvE0I8DeBJAB8M/j7JmsuKhuPCNAQqlgFPAp6GD8zZuj/WV3cMxGHvLCFLjopr0HkmhJDRYsk3DEopvyelvATAawH8kRCimub+QojfEkLsEELsOHpUX+uEbhq2h6plwDIEAMDVUFdXayjxrOfDt2F7sF29MRBCSDzqJJXvN0IIGS2SiOf9AM6N/HlT8L3Y2wghLACrAByP3kBK+QyAeQCXJlxT3e8WKeV2KeX29evXJzjc00PDdlEtmTDNQDxr+MCsBc6zthhIQ63HDUyELDXqihHfb4QQMlokEc+PArhACLFFCFEG8MsA7ui6zR0AfjX4+l0A7pFSyuA+FgAIIc4DsBXA3oRrLisatueLZ6FRPCvnWVPMolbX62QTQvpjK+eZMSlCCBkprGE3kFI6QogPAfgGABPAZ6WUTwshPgZgh5TyDgCfAfB5IcRuADPwxTAAvB7AjUIIG4AH4HellMcAIG5NzY/tlNJwXFRKBswgtqFDoM4u6nWeZzU72YSQ/rSdZ77fCCFklBgqngFASnkXgLu6vvfRyNcNAO+Oud/nAXw+6ZrLmabtomqZYeZZx4bBWsNv27A1XfbV7WQTQvqjnGeb4pkQQkYKThjUhB/b0Os8a888B9V3HJJCyNLjuMw8E0LIKELxrIlww6DhP6U6BG9YVafJKVbr6arSI4T0J+x55pUeQggZKSieNdFwfPG8FFV1+pxnO/xax/ERQvpjc8IgIYSMJBTPmmjYHsZKJgwlnjW4TbpjFkqMA/xAJ2SpUbENttsQQshoQfGsiYbtt23odJ5nNVfLzUacZzX9jBCyNKj3LU9UCSFktKB41kTY86zEswa3WH/PsxN+zQ90QpYWm84zIYSMJBTPmmgEVXWFbtuIxDb4gU7I0uKEmWde5SGEkFGC4lkTftuGEXGe84lTz5OYa6rMs37xrEuQ7zm2gFsf2qNlLQCYbzq46ZvPMVZClj1qrwJPVAkhZLSgeNaA43pwPKl1PPdc04GKTetyrqKZZ10f6P/y6Mv4v/99pzaxe++uI/jUt5/H0wdqWtYj5HTB8dyEEDKaUDxroOH4wrFaMmCaemIbKrIxVbW0Zp6nqv5QSUeT2D082wCgz8k+XPPXo/NMljts2yCEkNGE4lkDDdsFgI6e57xDSFTEYu1EWcuHr+dJzDVsrJ0oA9D3gX5Qs3g+OtcEQPFMlj+2x8wzIYSMIhTPGgjFs9WObeQVpypisWa8rEWYzrcceNJfD9DvFOsS423nmW4dWd7QeSaEkNGE4lkDDdv/kKxo3DCoauXWTZS1DElRMZB1ynnWIE6llDhU0+s8H1HOs0O3jixfPE9CvSV0DEwihBBSHCieNdAR2zA1iecgtrFmogxPaoiBBGJ8zYQ+57lWd8ITB11TENtONsUzWb7Ykd9fOs+EEDJaUDxroOm0xbOhqW2jxynWJMbVerYGcapcZ0C/89yiW0eWMdErOxxIRAghowXFswaU+1q1DFiG/5TqaNsQAlg1XgKQ/wM4zFBrdJ4PztbDr3XEQOotF3MN3yFnbIMsZ6LvBzrPhBAyWlA8ayAa29CWeW44mKpYKJtKjOcTk8rJXqsx83xYs/N8ZK69HmMbZDnTEdtgcwwhhIwU1uk+gFEgdJ5LZvg9HbGN6bGSVjEOAGs1tm0cmm2GX+tw1w7X2usxtkGWM4xtEELI6ELnWQPKeR6LOs8yf8xiuloKe6O1Vd9NlIL1ipd5jjrPjG2Q5Uy0p5yxDUIIGS3oPGugEW4YNOBJPYMRag0bq8ZKsFRsI6cTW6vbmKpaKJumlvUA4FA086xBjEedZ8Y2yHImKpjpPBNCyGhB51kD7Z7ntvOcX+w6mB6z2utpEOPT1VJkPQ3iudbUFisBfOdZrcchKWQ543Q4zzwRJISQUYLiWQPtDYPtISme5tiGrgy1rh5qwN8wuHG6CkCPGD9aa4brtRjbIMsYm5lnQggZWSieNdC0XQgBlE1DW0ZZxTZ0OcW1uoNVGp3spuNiZqGFc9aMAdAkxucaOHO6AssQdOvIssbhkBRCCBlZKJ41ULddVC0TQggYGpxi2/Ww2HJ9pzjojdYxsVCnk30kyCdvCsSzjgz1kVoTG6aqsEzB2AZZ1tB5JoSQ0YXiWQMN20O15D+VOsSpGhQyXbXCmIWdsyu2HdvQswHx4KzfjLFptUbnudbAhukKSqbB2AZZ1kQzz3nfu4QQQooFxbMGGrYbdjzrcJ5VrdyqcX1O8Ww9aO/QFANRNXUqtpE3ZtGwXdQaDs6crqJsGoxtkGWNen+ZhqDzTAghIwbFswYajheKZx3iVE0D1NWO4bgeFlpux3p5q/QOB87zOavHg/X0xEDWT1X82IZDwUGWL8ptrloGM8+EEDJiUDxroGG7qFj+U6mjuq3WCMSzpsxzGAMZs7Q6z2MlE6vH1dCVnOI5GJBy5nQVJdPgpW6yrFGxqGrJpPNMCCEjBsWzBqKxDVNojG1E2zZyZJTj1sv7gX6o1sDGVb7Q1bGeGpCyYaqCsmnApuAgyxgVO6qWTC2baQkhhBQHimcNNCMbBnXELGp1tWGwhJKZv1oudLKrpVDs5m2zODTr18rpqtKLOs9+bIPOM1m+qPdXpWTQeSaEkBGD4lkDDaftPAshYBoCnpbYhqVXjI/pyzwfmm3grFVjkQ2NOTPUtSZKpsCa8RJjG2TZEzrPlsnNr4QQMmJQPGugEfQ8K0whcond2bqNkikwVjLbmWddsQ2RX4x7nsSRuQbOnK5qG0d+ZK6BDVNVCCF88Uy3jixj7DDzTOeZEEJGDYpnDUR7ngE/upFnPHctGM2tXGwgp/MccbINQ8AQ+TLKM4st2K7ExumKtnHfR2pNrJ+qAABKjG2QZU50wyDbNgghZLSgeNZAdMMg4NfV5XFiaw0H02N+i4UOcRqtvvOPL1991qGgpm7jqqrWzPOGUDwztkGWN9wwSAghowvFswa6xbNhiFwZYDUNEIj2RufbMGgZAuPloIvaFB0T0NKixPOZ01Vt48MP15o4c7oKAIxtkGWPim2MFdx5fmVmEU3HPd2HQQghywqK55xIKVG3XYyVO51nN09so2FjumoFa+Ufp12rO5iqWhBB3tk08mWyZxZaAIAzJvW0bTRsF7N1O+I8M7ZBljfq5NRv2yjm73LTcfHGm+7HbY/tO92HQgghywqK55w0HQ+2K8NIBJB/JO9C08FE2RfPpobYxnzTwWQgxoFA3OdYrxkRBjraNo7O+R3PHc5zztjGPz20B88dnsu1RpS7nzqE+587qm29x18+gS987yVt661E7vzRATy0+9jpPoxY1MlkkTPPtuuf+J9ctE/3oRBCyLKC4jknKk88FRGnZs7M83yjLXZ1TAScj4hx//jyZZ6VK1w2jdB5ztMbrdpA1LTCkpnv+KSU+NidO/GvGh21v7n3eXzmwT3a1vtfj76Cj371acw1KFyy8v98ezf+8YEXT/dhxBJuGLSKO2FQHVeeWk1CCFmJUDznJDpKW2HmjG3MNx1MVqxwLSCfs7sQWQ8InOccYle5wiUz6jzni20ACHPjlinQyhHbcD0JKYG5ppN5jW5sR2oVQS3Hg+tJfO/FGW1rrjRs18O8xtdYJ47nQQigbOU7EVxKZPBvVJ5/qwghZCVC8ZyTWkNNA+x0nrMKLSklFlouJiq+kCwZ+ScCLjQdTETFsylg5xDjUfGsI/PcDIRyxfIfazlnbEM9V/MNjeLZ87QOu2gFj+/BgsYOlgMt18OcxtdYJ7YrUTKM3BGppUQdFp1nQghJB8VzTtqxjU7nOauYbAaOpBK7OjLPc5ozz8oVLpki7KLO44yr3f6VwHnOG9tQJwY6XUnb9bSKIHVyUNTM7nLAcWVxnWfXg2WK8ERaFtDdVb/PdJ4JISQdFM85Uc7zqrFOcZrVzVFiQMUsdGSeF5oOJstdmew84tmVKJuGtvaOhq06cf1fRytn24a6r1bn2ZG53P+e9YK1nj8yj8O1hrZ1VxLFjm1IWIbQ8v5dKsLYRjHLQAghpLBQPOdEbfiKtm0YOcZzLwRiIGzb0JJ5djtjG4aRO/NcChxxf718GerQeQ5GnJdNI4w1ZEE991ozz5qd55bjhSdIdJ+zYbse5htOIV1d/z1iaLlytFSEsY0CPn+EEFJkKJ5zUqv7Ai0a27DM7LEIleGc6HKes7qeniex0HIwWWn3UPtOcb7Mc9nqHEeeK/Nsd2aec8c2XBXb0NdkYbueVvew5Xq4+OxprJ0oM/ecEceTcDwZZuaLhONKWKYI9ywU0Xl2Q+e5eMdGCCFFhuI5J7WGjZIpwsgB4FfBZf1AUs6zqr5rZ4qzrbdou5ASHZnnkpkztuH4rpoib4Y6rm3D9bK3WyzJhkFXah12YbseKpaBn3r1Ojy0+1gh3dOio06Sirhp0PY8WEZ7Q22eKzNLhYqWUTwTQkg6KJ5zUqvbmK6WwvwvAJgi+wfSQqvTeQbyObthDKSipw0E8F3TqHjO2xvd3bah1s7auOG47Q2DukSpbufZdj2UTQOvP/8MHK418cLReW1rrwSkbGfQi5h7dlyJkilgmSrzXDx3XMU1GNsghJB0UDznZK7hdAxIAYJMceYNg74LG41ZWDnaLLo3IKrjyzPExXZlR2wjz/EB8VV1QPZL3UpU2a6eS/pS+vEA3ZnnkmngmvPPAAA8+DyjG2mIvhY6rzDowvE8WJEqxyK6u+qQinhshBBSZCiec1Jr2B0DUoB8zm4/pziv8zyp0Xm2HS8UuHmPD/BjG5YhYJnttg31czIdX8Sx1uFKKjGe54Qjbs2yZeDcteP4sbXjeHD3cW1rrwSiewDmNGbbdWG7xW/boPNMCCHZoHjOiYptRMmzIS9OPJfM7E7xfKN3vbxDUlquh5IVadvIsUES8J3nSsTJzh3biDw2Ha6kOo6lcJ4B4MfPnMTB2bq2tVcCtubXWDeOatsINgwW0d1l5pkQQrJB8ZyTuNiGP547+3pAu6pOrZfVuYqPbeR0nnsyzznbNhw3HJACtGMbds7YBqDLefaFmu62jXJwAlKxzEI2RhQZR/NrrBvH89s2iu08+/9nzzMhhKSD4jkntUav85wnA7zQdDBWMsOsZO71Yjcg5ss8t7piG3l7nhu2h2o0Q60xtqGjiaEVOs962zbUCUjFMsKua5IM3dEc3diuh1KkbcMpoEJVJ9CMbRBCSDoonnNSqzuYHut0ng1DZBanC63OUdpATue5od95bvX0POdv24g6z/nbNvS6kmo9rW0bkROQSskIpyySZOg+QdKN6nkutvPM2AYhhGSB4jkHtuuhbrsdA1KAYDx3Rjdnvul2CF21Xv72jojzbOYfktLb85yjbcN2+2Sesz3mVoewyr+ZbCkyz7YrUbKU82yiadN5ToPuaI5ubE/CMo1wE2wRBar6J8ql80wIIamgeM6BcrymqzHOc452jIlITR0AWDk2DC40HRgCHUNcrJwZZduRHeO5c7dt9DjPaqpiMZxn3ZlnKWVHV3alZDDznBJH8wmSbhzXQ6ngbRtKNHsFPDZCCCkyFM85qNX9D+3uqrp8TrHTsVlQrZfVKZ5vOpioWJ1DXHLESgA1nru7hzrPeO5+znP+tg0tmWdHVdXpEbjKNa1EnWfH45TBFHQ4zwWObbR7not3csTYBiGEZIPiOQe1wPHqjm3k6VGebzg9sY1c6zUdTHWtV8oxxAXwM8o6nef+VXUZYxuO3s1kSox7Uo9Lp04K1HOoHnurgJvKikrhNwwGQ1JC57nA47m5YZAQQtJB8ZyDfrENU+QYktJyOpoxgHwxi4Vm73p+5jmn82x2tmPkFeNVnbENzdPnosehIx+qxH20bQMAoxsp0H11QTeOK1EyBCcMEkLICELxnIO+sY0c4jRW7OaNgcRuQNS3YTB324bu2EZwv7GSqcWVVLENQI/QaDvPKvPsnzg02biRGHVVQtdrrBvHDZxns7iZ5zC2UbxDI4SQQkPxnIN2bKNX7Ga9vD/f7B26YplGZiG50IyPgeTLPMuOqrrcbRuOh4oVV1WXtW3Dv9/aibIWVzL63OsQQSqeUbY6necGGzcSo16TtRPlQopn2/M31aoJg3nabZaKMLZRQGFPCCFFJpF4FkJcJ4R4VgixWwhxY8zfV4QQXw7+/ntCiM3B998ghHhMCPFk8P9fiNznvmDNJ4L/Nuh6UKeKMLbR5TybIpvz7LgeGrYXu2Ewj/McV32XRwRGR0sD+cV403E72kDyt23491s9XsJ8M38TQ1T45BkGo1AnBSr6oiIrjG0kR/2+rR4vFXTDoAfLKHjmmbENQgjJxFDxLIQwAdwM4E0ALgbwXiHExV03+00AJ6SU5wO4CcAng+8fA/BWKeU2AL8K4PNd93uflPLy4L8jOR7HaaFWtyEEMFnudnaNTG7OQst3Hrur6vJsyFtour2xDTP7hkFVs1Y2uycg5pswGO8858s863Ilo7ENHQ5i/8wzneekRJ3nuQI6z71tG8UTqO3YRvGOjRBCikwS5/knAeyWUr4opWwB+BcA13fd5noAnwu+vg3AtUIIIaX8gZTyQPD9pwGMCSEqOg68CNSCZgwjMkobyJ55VkJP75AUB5PdvdE5qu/U4+qcMJh3w6CLStR5DtbO6tYpcbp6vKx/w+AStm3QeU6OHTrPZbQcr3AnHrbnX50pFTjzzJ5nQgjJRhLxfA6AVyJ/3hd8L/Y2UkoHwCyAdV23+SUAj0spm5Hv/VMQ2fi/RLSIeJlQa9iY7qqpAwAjY9vGQiCeezcMZhuSIqWM3TBoGiJz7Vq3awrki4G4noTtSlSjznNwMpK1us3xPJiGwFTV0jokxV97KTLP3DCYFnXyt3bcf/8tNIslnh1XwjLameciOhsUsIcAACAASURBVM+SzjMhhGTilGwYFEJcAj/K8duRb78viHP8dPDf/97nvr8lhNghhNhx9OjRpT/YFNTqTk/eGQic4gwfSP2c51LGcdpNx4PrSUx2b0DMMfWsuykC8MV9VnGgHMMO5zlnbMN2/c1aU1VLy4bB6ImLDhGkTkDKkQmDAGMbaVDP4ZqJMoBiDUqRUsJR47mLPGEweHvReSaEkHQkEc/7AZwb+fOm4HuxtxFCWABWATge/HkTgNsB/IqU8gV1Bynl/uD/cwC+CD8e0oOU8hYp5XYp5fb169cneUynjFrD7mnGANoxhrQT45Tz3C12s2ae+4nxPG6Yck1LVrfznE3oKre1o6ouZ2zDdj2UDANTFQtNx+sYmpKFlmbn2e56DtttG3Sek6JehzXjvnie07AxVBfq2Dp7nov32jLzTAgh2Uginh8FcIEQYosQogzglwHc0XWbO+BvCASAdwG4R0ophRCrAXwNwI1SyofUjYUQlhDijODrEoC3AHgq30M59dTq8bGNrJuEwtiGpraNfuu1c5jpP9DD0dJR5znHkBSV840OSbHyxjaCzVrqpGEhZ3SjM/OcXwSp9XrbNug8JyXaqAIUy3lWJ31Fd57D2EbxdD0hhBSaoeI5yDB/CMA3ADwD4H9JKZ8WQnxMCPG24GafAbBOCLEbwH8FoOrsPgTgfAAf7aqkqwD4hhDiRwCegO9c/0+dD+xUMNdwMD0W7zwD6R2d+SC3GecUZ3FhVWQhLvMMZHSeVebZ6mzbyCoOVLexziEpaojLZHBikzf3rD3zHLR3cMJgdqJd3kCxRnTbXntDqFngqjrGNgghJBu9yi8GKeVdAO7q+t5HI183ALw75n4fB/DxPstemfwwi0m/DYO5neeYdow8znPP0BXtmWeRuf9YCcZoVZ0ZXO7OHtuQvngOThry5p6jw1p0iKD2hkHVtsGe57Qo51nFNooknkPn2RCwwiEpxROojG0QQkg2OGEwI57nN1lMx2Ses4rT+T5tG1bGDYMLrf7tHUA2Idi92Q3I5zyrqEJ0SIpaM3vPsxduGASK5zzb3T3PasMgJwwmJsw8B86zjo2hulDC3jQNmGbxM890ngkhJB0UzxmZbzmQsne6INB2ntN+KM03HViG6IgwANnFaTsG0utkA1kzz70bBvO0bTTsXucZ8MV51syz7XqwIs5z3imDS5Z5thjbyErYtjGuJ5qjEzuyYbDImWc6z4QQkg2K54zU6r4g69e2AaT/wFwIOpm7K69Nw8gUi1CbqCYrnQLfMvNnnnud54xtGzFVdYAvzvPENixDhK0lRYttdEdfyqYBISie06C6vMdKJkxDFGzDoP86RjcM6hjrrhv1li1iBzUhhBQZiueM1Or+h7XOzLM/DTAmBpJxYmG/DHVWcQ+0hWTHkBQz+9CVuKo6IGdsw/VQtvyqOkCHeNY7YbDZFdsQwr/awNhGcpygy1sIv1WlUM5z+B4Rud5rSw0nDBJCSDYonjMy1/Cd535DUoBsGwbjxHPW8dfzfavvsvc8d0cO/PWytYsAQCPMPHcK/FKu2Ean81y4zLOq+4s8hxXLpPOcglbQ5Q347TSFyjwHlq5lGBBC5B5fv1RwwiAhhGSD4jkjtUZ8kwXgj+cGsohnt8clBvzspJ1lw2DTwXjZhGF0x0D8P2dxdsMhKWZ7zTxDV/o5z+VcsQ0/8zxWMmGI/B3AtqN3wmBcY0nFMtjznALV5Q0gmCRZoCEpYc+zf3xZhxwtNeqQ2PNMCCHpoHjOiMo8x8U2smaK54LMczemYUBmiEX0jYFo6HnuzjwD2VzZuKo6tWaenmc/R6znkr7+nmcPhmifxAB+5rvJCYOJUV3eAAoY2+g8wfSrJov32qr3v0fnmRBCUkHxnJHagNiGmbHbtV9swzKzV9/pXA/o3/MMZNsUpYakdFfVlUwjR1Vd1JUs5c88e1HnWU/bRvT5AxjbSIvq8gb8cfZFEs/qfaXiUaYhOjadFoX2hMHiHRshhBQZiueMzA2IbZiZYxv9nGe962nPPOcY993PeS5ZRmbB0SGsKlb+qrrAKQY0Oc/BhsYojG2kQ3V5A8FrXKDMsx22bUSd5+IJ1NB5LuCxEUJIkaF4zkitbmOsZPY4iMAStG1k7GWebzqxGeo8I4NbzgDnOVNso3c8NxDkvHON5w6ElQZX0nY9jAUbGnVlnss9zrMRdl6T4ahcOxBcXSiS89zVSGMaRrEzz4xtEEJIKiieM1Jr2Jgei59uniVTLKXsH9vIKHbnm25PxzOQzyluBcegM/NcNo2eTY25YhuuF7rrU9X8rqTtSYyVzWBtPZnn7pOuasmk85wC1agC6HmNddJu2/CPr2QWM/PsMbZBCCGZoHjOyFzDwVTMZkEg2qOc/AOzYXvwZO8obcAf8+uvlyVDPcB51hTbyNO20bDdHtcZ0BvbyOtK2o4Xxkr0OM8SJavzZMGPbRRPYBUVJxJ9maxYqNtuOJzkdNPdhV7ctg1uGCSEkCxQPGek1rAxHZN3BiLjuVN8KM0Fudw4sZunNzpOjKt+3Cwb/Gynt6our/PcPV3QP0Y9sQ0tzrPrhc5zlsrAblqxsQ2TbRspiDrP6mrNQrMYzn13VV1RM8/tqrriHRshhBQZiueM1OpObNMGkC1moT74B20YTBuzmBswdMVfL0Pm2fUgumrW2pnnDBsGba9nsyCgr21DV1WdzsxzXGyjUkq/YdDzJB5+4Xju41mORDPP4Rj2nBtDdREdkgIU13luV9W1mzcIIYQMh+I5I77zHC+ejQxOcXuUdoxTnKE32nY9tBxvYFVdpp7noGZNCD3Oc8Nx453nnENS2rGNEhZbbi7Ra7syFM86Ms9237aNdCcLj+w5jvf+z0ew80At9zEtNxxPhu69GsNelLo6JzKeG/BFdJarPEtNVDAXUNsTQkhhoXjOyMxCC2snyrF/l2Vctfrgj3eK/ZcpTQZ4kBjP6mQD/rS9Spdrmqe9o6/zbIgc47m9jg5gIJ+wst12tGTp2jbS9zyrusQiTdc7VfjOc7tRBcg/SVIXofPckXkuXiQn+qvM6AYhhCSH4jkDtuthruFgzXi8eDYyOLGDxG6WzPMgMZ61vQMIhGmXa5rHyW46bs+AFCBv24ZsZ541uJLR2IaOy++2I2PaNoxwYEya4wKQ+SRjOdO9KRRAYerqwg2DwfvMMosd2wC4aZAQQtJA8ZyBE4stAMDaicGZ5zSXagc7z+md4vlBYtzM7qL6ed3OpoisExUB5TzHxTZEJnEvpfQzz0aX85zDlbTddlWdjsqxZswJSBbnORTPK7Clo3tTKFAg59ntdZ6L6OxGYxtFPD5CCCkqFM8ZOLHgXyZf0ye2YWqObWRxnpWTPRnTCJInoxyX183aBgL4znNcbMMyjEyOqt2VN50Mnefs0Qb9zrOHctcJSMUy4HoyVd2aeqwrUTxHu7xVl3lhMs9qPHekbUNHVl430X+fOCiFEEKSQ/GcgZkF33nuF9vIMnGvHduIEZIZep7ng/aOQT3PWVzUltvbFJEnQ910vNjYRtnKFttQx9CdeZ7L5Tz7JwyG0Jh57naeg+cgjfvM2Ia+qws6acc2/OOzDKOQzm70kDiimxBCkkPxnIGTi4PFc7aMclBVV9aTUVZCYlCGOssQkpbTu9ktj/PsD0mJq6rL5tbZjnL99DUxKKFmaRqzbMecgKjnIJV4dhjbAIDxkgkhipN5bsc2opnn4r1GHmMbhBCSCYrnDMyEmed+znP6TPFC08F42ewZU+2vl97ZXUiQoc7ygRkn/PL0Rjed+MyzEqppHTE7dJ47mxjyOM/KbdeVXY3tebaU85x806B6vlei8xzt8jYMgclycUZ02yq2Ebwvipp5jr63GNsghJDkUDxn4EQQ21g93mc8t8jWthHnEgP62zZKGcd9A74L25t5zj6x0I9t9DrP6meknejndI1GViPU89S5OYHLqSu72op5DtVzkGbKoBLN9op1ntvPYZYhM0uFn8cWYRe6VdAhKZ2xjdN3HIQQstygeM7AzIKNibIZK/oAwAwcsTSuab9pgEA2ZzdJz3P2zHN320aOISm2G9+2YWar01M5YHXCMVE2YYjszrPrSXjSF+OmKbS0bcT3PPt/bqQQgCqishKd527xXDbTD5lZKqKuOBD0PBdww6DHDYOEEJIJiucMnFhs9W3aALK1Wcw1+o/7Dp3ilNV3ZcvoiQcAbWc8a+a5e818Pc9e7IRBKxwMk62+TR2jEAKTFSuzeI6up8tBjKv7CzcMpnCeVYxnJWaeHVeG7zPAv1JRlOfBdr1wsyCgIkjFOLYo0ZN7bhgkhJDkUDxnYNB0QQAwRHpnt1a3MR1TKwdkc4rnm064Wa7n+AyRuTnCdnszylnbNhzXg+tJVOM2DAY/I62ranfFNgA/ulHLGNtoue0MtS4HUdeGwVbYtrGyhI/q8u6IbVhmYcSz4/Y6z4XMPHPCICGEZILiOQMnFlt9mzaAbBnlWsPu6zxncbIHZaj9NbM1R8QJv6xtG41A7MQ5z+W8sY2IeJmqZneeoxlqHW0bnucLv56qugwbBsPYRkFE46miu8sbCJzngsRXHM8L216A4mae2fNMCCHZoHjOwDDnWWWe03xg1uoOpqt9NiBmrL4bKJ4z5nej/brdx5dWIDSDcdT9hqT4Py+lmx0cQzRTPF0tZd4wGI1t+A5iPoFmd/VQK0LnOUVsY6VOGOzu8gaKFtuQ4WhuQL3XiidOoxMGGdsghJDkUDxn4OSiPdB5NkVW57lf20aWzLMdOyAlPMaMblhs5jlDNR/QjijEDUlRsY2smedu57lWz+Y8K0EWtm3kFBlqvZ4NgxmGpCgRmWWYzHKmu8sb8J/Poohnx+10nk1N/eC6iZ4H0nkmhJDkUDynpOm4mG86WNOnpg5IP567YbtoOV5f59ky02eKF5pu3/YOIPvI4FbMdLysznNjgPOsYhtpNzW22zaimWcLcxnHc6v1ypaenue4yAGAMPetnpMktFZqbKOryxvwXx+dVXUyh5i0u9o2rIJmnl0OSSGEkExQPKfk5KIvwga1bYTiOaHwU5vZTmXmOasb5tesdQq/MPOc0gFVLmu/ISnq56VBnRCUrajzXMqeeQ4HXhiZ3foobTHeecLA8dzJ6e7yBpR41vc8/J9f+SH+4MtPZLqv09W24W80Ld5r5HXENk7jgRBCyDKjv7oiscwsDJ4uCKQfkqIiBcPbNtJV1Q1znjP1PMfENrJkvIFobKN/20bm2EZEvEyP+RsGpZTh4IqkdMQ2NGRXo+tFyTZhcGWK5+4ub8B//nQ+D9/fMzMwmjWI7raNojrPnDBICCHZoPOcEjVdcNAHq6qC8xJ+IA13nrP1PA/bMJi5baNnwmDGto0wttF/SEr62IbKw3Y6z64nUU8RiWivF4hdS0/bRisSA4mSqapupcY2urq8Ab0bBpuOiwMn65l+XwAV24g4z6YIR3YXCVbVEUJINiieUzKzONx5BtJtyKvVA/Hcr20j5RASz5NYbA3PPKf9wJRS+uO5dbVtDKiqU8IofdtG74a8qcDRzxLdUGK8HAxJyd224fYeH9AW02zbGI76PevsedYnnl+ZWYQngXorm3j2YxvLwHmOxjboPBNCSGIonlMSOs8T/TcMAr6gTFr/VAtE3aq+bRuBC5tQuC20/PUGiecsAz9CIdnjPKd3xoHBVXVZxXO7baNzSAqATHV1TiQioGNIimqKiKv7K5kiU2xjpbVtKJEcvbpQNvXFNvYcWwSAzM5z75AUA64nc21CXAo8bhgkhJBMUDynZGYh2DA4JA+Z5hL/MOfZSrkBcb7pi+fhQ1LSiY3otL0oymRL68oOrKrLGdsodVXVAe2TlDS0orENHZln1w3X66Zqmek2DK7Q2EZcl3fZMlK59oPYe2wBALDYyjjS3evcF5A11rTURN+u7HkmhJDkUDyn5MRiC1NVq8c57CbN+Othmee0sYiFUDwP7nlO+2Fu9+koFiJbB/Kgqrq8znOpY0hKIJ7r6Z3naGxDR19vy+kV94pKyUhXVbdC2zbiurx1Thjcc9wXzw3byyQqHVd2bGa0Mm6oXWo8ThgkhJBMUDyn5MTi4OmCCss0kovnuoOyacRunAN8cZpG7M43fQE21ae9A/DFW9oP8+jmuW6yiPElyTyrDYNG54ZBIGvmuS3GdWRX1Xpxr3UlrfO8QjPPcY0qZdOE60kt7q5ynoF0Gzijx9c9nhsooPPM2AYhhGSC4jklMwutRBVWqTYMBtMFB9WopVkvdJ7LgzPPaT8wWzGuriKL89zueY5znvMNSYkK/HwbBtsup2mI3PniOGdcUUnZVaxOFFaa8xzX5a1OwHScSETFc5bohuPJjisLptoTUDCBGj0cbhgkhJDkUDynJKnzbIrkzQy1ut0376wopRi0oETisMxzWiHYb7Q0kE2MD66qyxrbCGIRhp4Ng71tG7p6nnsfs5/bTR7boPPcOZ4byP9cNGwXB2Yb2LRmDEC2TYOO63UcW1GdZ9eTkf0Kp/dYCCFkOUHxnJITCzZWDxjNrfDFZLI1aw0HU33yztH10jrPg2IbmTLPfdo2AD+mknYD4qAJg6F4TimGnJg87ETZhCHyxzZ0jOce5N5XSuliG60VK557u7zDqj8334jul477TRsXnzUNIFtdnd3TthFkngumUD0pw9/Dogl7QggpMhTPKZlZaGFtgtiG38yQxnkePOwxTYZaVdXpHpIyKHKQLfPsomIZsXGVUsZNVmoYRTTzLIQIRnRncZ4jEwa1jOf27x93wlC1jHRVdcFaK62qLq7LO0tPdhx7gsjGRUo8Z3Gevc7x3FbKDb+nCinb7+WixjZeODqPHXtnTvdhEEJIBxTPKai3XNRtF2sSxjbSZZ71Oc+qqk73kJR+VXVqvfQ9z17fTZLqQz1tntd2PZRM0SPIp6pWriEpVtC2sZSxjUrJRINDUoYS1+Wtfo/y5r/3Hu8Uz4sZnOfenufixjaslAOYTjV/c89u3PhvT57uwyCEkA4onlNwIuF0QSAYkpJ0PHfdSZR5TupkzzccmIboK0z94zNSi90w86ytbcNFtRRfp9eObaRb03G9WGE6VS1l6nmOTgT0nWddGwZjqupSbhhcuVV1vXV/ujLPe48tYN1EGRumKwCyOc921+9gkavqiu4811tuqqsxhBByKqB4TsGMmi6YtG0joThVbRsD1zOTr7fQdDBZGdzekUUI9hst3V4vg/McU1MH+M+fIZDhGDs7dhW+85whtuG0xa6pYUhK+BzGVtVljW0Ub3rdUuKE4rk3tpFXPO85toAtZ0xgvOyf1GXJPDte5++gatvIO9pdN56U4RjxojrPjicTD4cihJBTBcVzCtI6z0k+kBq2i5bjDXWe00wsnG+6AyMbQCDGT0Pm+R++8wIef/kEAKDhuLE1dQorwcjlO354AHc9ebDjGOOOb7pqZXOePQkhgvHZGjLPAzcMWmaqzK7telDnR6PsPn9/zwz+6aE94Z/bbRuRqrrg90hHbGPzGRMYK+UQz66EGXHFSwXNPHuyXelYsEMLcTyvcM8bIYRQPKfgxKLvXK6dGN62YRki0dSuYdMFFemGpNgDpwuGx5c28zwgr5tk3LeUEn/xjWdxy3deBOA7z3GjuRVl0xga27jpm8/hMw+2hZXjyr6xjawbBkuGEQyqMXK7YIMzz8ljG54n4Xgy7PIe5dzzPz7wIv7qm8+Ff47r8tbhPC+2HByuNbHljAmMBc7zYpbYRteGwXbbRrFEoCfbDnlRx3M7rp7BN4QQohOK5xScSBHbMBKK01rdd0OHtm2kiFksNN2BTRv+ehkyzwOq6pKI+7mmA9eT+P7eGUgp0XS8gc6zPwWx/2OebzrYe3yhY1OXP92tX2wjg/PseGG2NktDSc96rgfTEKGgipImtmEHz4uKF6QdJrOc2HmwhnrLDaMpcV3eOsTz3mN+Td3mdW3nuZHSeXY9CSk7a/SKuinP8yJVdQWN/dgunWdCSPGgeE7BzEILQgCrhrjEQPL2iaTOs5UibzsfZJ6HHV/qnucBQ1KSCMvZwLmfWWjh+SPzaNjuwE2Nljl4kMuzh2qQst1rDfgxi3jn2cJ800mdDbZdL3Q4dfQ8266Mff4AoJqi51n9bqmTpFF1nmfrNvadqMPxZPjcxHV5q+c0z+Yy1bSx+YzxUDynbduIiza1JwwW6zXyIlV1RRP2Cl0j1wkhRCcUzyk4sdjCqrFSR0VWP8yksY16IJ6HZJ5Nw0jsLi4kEM/mEFc3jvbl8l7XNImwPLnYjk1878XjaDpe37YNwBdErQGxjZ0HagA6Ryg7rhfbZDFVLcH1ZHoxFBHjOto2Wk788QG+89xyvESX0NVroeI5oyqenzlYC79Wr11cl3fY85zjeVAdz5vXTcAyDZRNI3XbhhNzbFZBYxvRqrqitm3YFM+EkAJC8ZyC4/OtRJENILlLqTaxrRrStpHGKZ5vOgliG+kjCIM2uyVx2k/WW+HXj+yZCYek9GNYbGNnIKwWml2xDSPeeQbSTxm0HS/c8OXXD+bLh7ZcLzb2AqTb9KZuM64yzyO6YVCdIAHtKwxxXd4VDbGNV2YWccZkJXzvjJXNcIR8UtqueG/muWgi0G/bKLbz7LheYY+NELJyGaywCJ49NIe7njyIbzx9CLsOzeHqV61LdD9/oMbwD97kznNy1zNJbMM0ROrNb3l7npXzfPFZ0/j+nhmMlcxcsQ0lrOq2C9eTMA0B25V9nWcAmGvY2LiqOvA4o0RjG9FJceWYzHKi9Ryvb2yjEpmSN8iRByKxjfJoO887Y5xnJ+YESceQlPmm01EZOVYyO65qJCGug7rQEwatYgp7hevJwsVdCCGEzvMQbrn/RXz6nucxVbXwp2++CJ/65csT3S+pU5w485xwPSllothGyUxefadQwiC+53l428bJ4EThFy/ZiKNzTew/WR8oEksDYhuO62HXobnwWNTldcfrX1UHIHVdnR1p7zA1uHRRMd6N6rxOktttxzZG33lWr7EaOx93gqRjw2DD7tzAOl42UU857lu9B6yYto2iCVRXyvA4CxvbcL3cV3sIIUQ3FM9D+IM3XIBH/+R/w1c++FP4Lz/9KmyYTuZaGgnHc9fqDsqmMdCBBXwXNsl6Ddv/sBkW28iy+S1vz/Ns0JP9i5eeCcAXE4Med3lAbGPPsQU0HQ/bNq0CACyqS/qO7NO20Xae0xDtjW47iNkFWqtPDzXQjm0kye2G4jmIbQxy6JcrLcfD80fmIq9xkHmOeQ51iGd/4mV73WrJRD2l86yuCER/B9WxFs15jk4YLOqvj3rOitoGQghZmVA8D2HTmnGcMVlJfT/LEIncEjVdcNA0QLVekg1Hc01fHE4m6Hm2U4rAltO/Zi1Jhvrkoo3xsokLz5wKn9PKAOd5UGxDXc5/7ea1APxL7kDQsavVeW5v8NPhILac+DYQAKFwS+Y8+8cwPsIbBncfmYftyp7XOK7Lu922kcd5dlHtcZ6ztm1EJwyq35tivUZSto+zqM6z+jevaK49IWRlQ/G8RCRts6jV7aF5Z0Blnod/gKjNc0mcZ5nycqjdp8lCrTc081y3sXqsBCEEXrfFF0TVIRsG+w1JUZfzX6NcyTAP239ICpDFeY60bZj5s6t2gg2DjQRRASXSJke4qq59grQGQLtVxfZ6u7wt04Ah8sc2os7zWNlM3c7Sbttor1PUzLPftlHwDYPBv6FFe+4IISsbiuclwhTJ2zamEvZGJ3GuVCNBkp5nIN2H0qDIQZKe55OLNlYFbSWve5Uvngc5zyXT6OuO7zxYw49vnAw7t6NNDFaMM561baOl3Xn2UB5QVQekyzyPctvGMwdrqJYMXHK2f4K0oKrq+pwgla3h49wH0bDdjgy+H9vQ6TwXSwD6bRvFPDYFnWdCSBGheF4iEo/nrttDpwsCyZ3n+aTiOYPj1BrQFOG3iwwTzy2sDsTu67b4rSWDq+riYxtSSuw8UMPFZ02HE/bCDuA+G/LGyyZMQ6R2np3YzHPODYMJ2jaGoTZSTo5wbGPngRq2bpwOT3wWw9hG/BUQvxc8T+a5s+UkS2wjzDx3OM/+10WbAul5EoYhYIjixjbU+5/imRBSJCiel4ikVXB+5nm481wyh4tTAJgPnNUkPc9Aus1vgyIHSQaInKzbWD3uP9YfP3MS//1tl+Atrzm77+37xTaOzDVxfKGFi8+aDh9nRxNDjPMshMBkJf2I7o7YhmrbyCGCBornUvINg47X5TyPmHiWUmLnwRouPns6nPa3EDlBiuvyrqSY0BiH7zxHYhsZnOewbSPqPJvFzDx7EjCEnsmZS4U6LtbVEUKKRCLxLIS4TgjxrBBitxDixpi/rwghvhz8/feEEJuD779BCPGYEOLJ4P+/ELnPlcH3dwshPi2G7ZhbZiR1imt1J3nmOYFoUyJycoibrS4lp5l61u9yuVpvmKg8uWhjdRDbEELgV39q88DO5X6xDdXvfPHZq9rOczPSAdznGKeqWcRz2+VsZ57ztG3IAZnnLFV1yQerLCcOzDYwW7dx8VnTMAyBibLZblTp0+Wd13n2x8W3neexcgbxHPY8Fz/z7Em/G90Qya6SnQ7UNMmiintCyMpkqHgWQpgAbgbwJgAXA3ivEOLirpv9JoATUsrzAdwE4JPB948BeKuUchuAXwXw+ch9/g7ABwBcEPx3XY7HUTj8aXS9/+C3HA+7j8yFf1ZtG8NIOho6cWwjc+Y5/hxnWNuGlBKz9VboPCehX2xDbSTbetZU+DjbbRv9Bf5UtRQb22g6Ll48Oh97n2jOW0/m2R0+JCWBAFSxDeW8j1pVXfsEaRoAMF6xwhPDfl3eFctIdOLRj4bjhV3bQOA8axjPXeTMsxB+e05Re5TVxMaijTYnhKxskjjPPwlgt5TyRSllC8C/ALi+6zbXA/hc8PVtAK4VQggpZIlMEgAAIABJREFU5Q+klAeC7z8NYCxwqc8CMC2lfERKKQH8M4C35340BaKf8/xvj+/DG2+6H3uOLaBhu2g5XmLnWWdsI8vAj5bjoWzFb/CzzMHHt9hyYbsyzDwnoV9sY/eReZyzegzT1VIYWwibGAYI/KmqFVtVd9tj+3DdXz+A2XqvsHY6Yhs6Ms/xrimAMG+bJPM86rGN54MTzAvPnALgT1JUTTL9urzLVnbn2fMkWo7XU1XnBN9PijqJseKc54IJwDC2IUQhe549T0K91Yp24kEIWdkkEc/nAHgl8ud9wfdibyOldADMAuieY/1LAB6XUjaD2+8bsiYAQAjxW0KIHUKIHUePHk1wuMWgX4xh7/FFeBL46hP7E08XBJL1KAPt1onxIeOds0QQbLd/U4Q/YbD/8anpgmmd57jjm2s44XNWtgyUTBHmYftV1QF+13NcbOPoXBMt14t1nzt7nvVMGBwW22ikiG0o5z1P1reIzC7aqJaM8CRwvGx1VNXpbttQz1932waAVO5zO7YRGc9d0Do415MwhYDR5yrZ6Sb670lRYyWEkJXJKdkwKIS4BH6U47fT3ldKeYuUcruUcvv69ev1H9wS0a9t40itAQC444kDqAWCMknbhmUaiTaqzTddTFYsGDGb5rqPD0j3gT5os9swZ/xkMF1w1Vg58c8r9cmwLrYcTJSjDqEVycP2dgArpqul8DnvXM8XR3uPL/T8XfyEwSXeMJik5zlw5FXme9RiG7VGZ//5RKXtPPc7QcqTeW4EAjm6YVC5+o0U4llFS8YiIrzImWcV2yiasAc6T+yLeHyEkJVLEvG8H8C5kT9vCr4XexshhAVgFYDjwZ83AbgdwK9IKV+I3H7TkDWXNUYfp/hQIJ5fPLaAh3YfB5DceU4yEXCh6YSbyAahcphp6rPsAdPxhmWyZxezOM8i9vgWWy7GIuJ5omx2NDGUYpoYALVhME48+4Jnz7HFnr9rOb2ZZyeHUG06CarqkjjPwXNdsQxYhhi52Eat7nS8LyYqVkc0J67LO09sQ7n9Ued5rOy/HmkGpRw46b+/z1o9Fn6vyBMGDVHcDYPR937RIi+EkJVNEvH8KIALhBBbhBBlAL8M4I6u29wBf0MgALwLwD1SSimEWA3gawBulFI+pG4spTwIoCaEuCpo2fgVAF/N+VgKRb/x3IdrDVxz/jqUTQOff+QlANCbeW46Q/PO/vGlv5TcHBA5GOo8a4xt+M5z+zGOB8JKZSQHbRicbzqQXUJBNXXsPdbrPDteO6Osy3keVPdniGQRDNtRwziMXKKxqPjOc/s1nihbnSdIMc9hJU9sw1axjeiGQf/np2nc2H9yEavGSh0bdk2R/kT1VOB6EqYBmEa6SaOniui/J3SeCSFFQnQLidgbCfGfAPw1ABPAZ6WUfyaE+BiAHVLKO4QQVfhNGj8BYAbAL0spXxRC/CmAPwLwfGS5N0opjwghtgO4FcAYgK8D+D055GC2b98ud+zYkfpB5uLrNwKHnkx9t1dOLGL/yTpet2UtBNou2aN7Z7B+qoKm4+FEEGW4bNOq8IN62HpXbemOknfyzKEaHFdi2zmrBt5uZqGF547MYds5qzqE6CB+tP8kKpYZbuJKc3yH5xrYc2wBV/zYmr5tE/3W7H4Of/DKCUxVSzh//SQA4MkDs7AMgQvPnML3987g3DXjOCfi/CkOzNbx8swiXrt5bShoAOC5w3OYWWxhomz1PG/f23McZ60aw4+tHUetYWPnwRou2jgdTjZMyyN7juOc1WM4d8147N9/f+8Mzpyu4Ly1EwPXiT6Wx18+gTMmK9iybvB9lhNP7p9FyRTYutFv23jh6Dxm6zau+LE1/utfsXD+hs7fw2cPz6Fhu7hs0+rUP2+x5eBH+2dxwYZJrJuoAABO1lvYdWgOl5w9jalKstd716EaWq6H15zTeQzDXvfTwff2HsfG6SqOz7ewaqyEVwfvp6LQcj08/vIJAEj1GhBCRoyN24A3feKU/1ghxGNSyu1xf5dINUkp7wJwV9f3Phr5ugHg3TH3+ziAj/dZcweAS5P8/OVIXOrWlRKu9KMPU1UrFM9mn5hB3HoSskNIduN5MrxMPHC94CZprtZK2b5f2uNrT15LXudtRI4x+nP9jU7tP5vCd/nVQ+l3jGHswvNgmu3L8+qSdcNxO45fwl9TrRc+Z8jmgqn7DXoG/GlvCdYKbiPgX3pPchK8nHA92eECm5E9BP7vQ++zaIh0v89R1HNuRNZVX6dJW7QcL3bkvED2Y1syJCAgIAQy/kYvLR2/00U8QELIykVKuWz+u/LKK+Vy4W/ueV6ed8Odsmm74fdeODInz7vhTvmvj70i6y1HXvLRu+V5N9wp6y0n03px/OJN35H/5XOPDl3v3l2H5Xk33Ckfe2lm+IMJ+Nm/uEf+/pcez3R8f/a1nfLCP70r8c+SUsq/v2+3PO+GO+VC0+74/oV/epf8s6/tDP/8m7c+Kq/76/vliYWmPO+GO+VnH3wxdr07ntgvz7vhTvnsoVrH93/pbx+S591wpzzvhjvlsblG+P2m7crzbrhT/s09z0sppfzByyfkeTfcKb/9zKFUj0NRbznyvBvulDff+3zf27zuz74lb7jth0PX+utvPifPu+FO6bie/Kk//7b8gy//INMxFZUrPvYf8k9u/1H4509+/Rn56j/6mvQ8T27/+Dfljf/6o577/NcvPyF/6s+/nennPfzCMXneDXfKh54/Gn7vyX0n5Xk33Cm/8dTBxOtc+t/ulh/9/57s+f7WP/26/PidT2c6tqXiVX/0NfkXdz8jf+Yv7pH/R5/39elk77H58H358AvHTvfhEEJWGPDTFbF6lOO5l4i4wQiHa00AwMbpKqolE/9p20ZMVqxwo9ggko7Tnm86Qwek+Ov5PzPNRpyW4/WNXAwbBHFysYXVKZo2gHbFV7Tr2fUkGrYXtkwAfhPDYssJ866DJgwC6Nk0uNhywxxytHEjHLVsdGWeI8/ZkVojcdOFOr5BsZVKyUjU7mC7HkzDb0ooW0bh8rR5kFLGtG1Yfuey6/Xt8i5bRubKPvWcV3JU1dUaNuYaDs6OiQwlrZo8lXhSwhDC73ku1qEB6NxbUMRMNiFk5ULxvESoTG1U7B4OmjY2TPsjqf/kzRfjy799Vewl6J71Em5WS9u2kabnueXK2I1awHBx74/mTpdZVIK26bbFixIy411VdQtNNxS1/bqopwIx1j0oZbHlhDnuaOOGEu39Jgw6rodr//I7+NL3X070eNQmv34bBgGgaploJKmqizRO+BVt2SfrFY2G7cF2ZWfbRmQMe7+quoqV/XloxGwYVL9jSTcMHjhZB4BY8WwOGSJ0qvHdk6Bto6ATBqMnqUU78SCErGwonpcIJbSiWlKJ5zOn/Q1Jq8ZKuOTswRv7FGEv8xCLaKHpYjLBxhrVhZy25zmz81y3U2+yiwomhaorGy9bHbdbbDmRXPVg53m+Rzy7+PEzp2AaoqNxQznF6oShZHaewCzaLuaaDvYHomkY4XoDnOfxihl2BQ/CdmX4Woxa20Y4PCjiPI8HV1MWWk7fLu9cbRtxVXUpnedB4nnYEKFTTTTj7U8YLM6xKaJXdIp4fISQlQvF8xIRN8HvcK2JibIZOqBpMAOhNOgDuOm4aLkeJhM4z1lq1/zx3MOc5/j1ZjM4z6pyb77ZFpNKSHfGNiwsttxQAPUbkqLWW2j2iudVYyWcu2YMeyKxDTuMWcRPGGwEjmT3ev3odrLjmKxYHY+371qRurZ+fdjLlXB40FhnVR3gnxz26/JWJxEyw8689pCUaM9zcPKW0HneH3Q8b1oTH9tIMuToVKEmCpqG30lfxJ7nqGAu0okHIYRQPC8Raqd+Z+a5gTODyEZaSgliFmoCW5qe5zSZ535ZU2D46OqT9fSZ56k48dxS4jkirIKTBeVY9nPHJ2PWk1JiseVgvGxi8xkTHc5zt5PdfYKgLvUvNJOJqzDzPCC2MVmxEonxjtjGinCe/dd4vmn37fIumwY8mU1oheO5I69NxTIgRPIJgwdO1lEyBdZPVnr+zixY5lm9T4Xwu8ULGdvomDA4Or/fhJDlD8XzEhHGLGSneN4w3fvBmgQzZrNaN0p0JRHPaaeeeZ4MBoZkc56zZJ7jnOJ2bKMz8wwAs4Fj2W/DoIqBRMVz0/HgSV+cbV7ni2flXHbHNrqfMzWVbq6RzHlWArdfJhvwH3N3rCQOO5L7LVsmmiM0nrtW9x9/Z+a5+zWO3zAIINOJRNyGQSEExktmYuf5wMk6Nq6qwoipY7TMwRM4TzUyGtsoqPNsM/NMCCkoFM9LhBEjdg/PNbAxo/OcJKOsROFUEufZTBfbUOOg+4lnc0Amu2G7aDoeVo+nc54nq/2d5+imSPX1ycX+wsr/voFqyegS44GTXTKx5YwJLLRcHJ33W1G6Yxu9znPK2EaCzHOa2IYSi2VThJsRR4G289x7dUG9xv3aNoCs4rnXeQb86EbSzPP+E3Wcvao3sgEU0HmOxjYKmnmO/ttZxOMjhKxcKJ6XCKtrA52UEodrzcyxDRWLGPQBPJ/JeU72oaQESb9avbiMt0INg0nrPMfFLJTzHJ3I2O08D6qCm6yUMB+JWSjhO16xsPkMf0LfnqN+dKNb7HY/Z6qFIckGv7j14o/PH0M9LLcbjdCUc2yUKyLtzHN/5zk2tqHEc4bnomG7sAzRc9VirGyG2fZhHDhZxzkxeWeguJln5Tx7BXSeO2MbxTs+QsjKheJ5iTC7YhsnF220HC+sqUtLtxiPI414LqXMPKtLqEOd55jjU27h6rRtG5XedoxY5zkQVqHzPGCK4WTF7BDj0eo7Nd5adT2rx6wElco+q+83ghOKJDELIFnmeaJihV3Wg/Azz8p5HrXMc3AFJeI8j/dcXYjPPAPZnedqzGTAsYSxDcf1cKjWiB0LD/gnv0VynmXwFBW5bYNVdYSQopJoPDdJT7eYPDzn78TPHNsI1osbyPHU/ll87cmDuOvJgwCQqBLOHOAUxzHMNR2UeVaCZ1VK53m8ZEKIzljEQiBkxsq9sY1hmWfAj4J0rKdOOMoWzl5dRckUYddz+zEHbRtmV+Y5EN5JYhZAW9QNdJ4jUZXoY+zGjnRul0wj8aCW5UCtbqNaMlCxek+QQuc55gRJ5ZWzDEppOG5Hx7NirGwlim0cnmvCk/E1dUDgPBco8+yGzjNgGOlGkJ8q6DwTQooKxfMS0e0UH5rt7HhOvV6fzPMPXzmJd/ztQxBC4KpXrcVv/8yr8er1E4mPL6mj0xoy4GNQ28ZsPYhtpGzbMAyBibLVEbOot9piV6Ec6iSxDX+9iPMcEeOWaeDcteNh40Y789yvbSNt5lkNcRkU22hvalw/1f93xe/cHt22jemuOkfVuTwwthF8r5lhUErDdjvEevvnGomGpAzqeAaKl3kOYxvBlMoinnxFn68iPXeEEELxvER0i8kjwWhu3Znnu58+BEMIfPfGX0gVCUmdee5yYbtJ4jynzTwDvqs832yP01a1cGOlaNuGuqTvi/R+GwYBP1N8MDiRAdpOthLjW9ZNRGIbfTLPbpd4brnwPBnbshDFThLbKMd3UcetFcY2Rk08152OvDPgi7zxsjnwNa7k2DDYdLx457lk4th8a+j995/wxfM5q+Pfg6WCTRhU1XSGEMtjw2ABxT0hZOXCzPMSoYwxJSbbo7kzOs99xO69u45g++Y1qbPUodhNnHnudGG7GVR9d7KeXTz7vced47nHSmaHUE2ymSxcr2p1bPALNyAGAnzLGRPYc2wBricjmecgtiG6nef2Y002FXDwCYg6PmB4FCQa2yhbxmhV1TXsjqYNxUTFGnh1IU/bRrOP8zxetsLfkUHsX3bOs///Im8YjLrhRXruCCGE4nmJ6HaeD9UaWDNeiv2ATkLb2W1/oBw4WceuQ3P4ha0b0q9nDh5q0s2w6XiDxPjJRRtly+hwi5PSXd220HQ6Op6B9maytnhO3qPcvQHxwo1TaDoeXjq+0HPCYBj+QAm3K7YBJMs9N5NknmM2ScbREdsIMs9ZJusVkVrd7nGeAb+ne1CuPV/bRrzzXC2ZQzdvAv57cc14qWN4TxTLMOAU6ATHi2SeC7thMHJMRRT3hJCVC8XzEtHtFOepqQMiVXARcXrfs0cBAD9/YQbxrDYgJtwp1HJ9odg/89w/BjJbb2H1WAlCDI41xDFZ7c0od2+kK5sGLEMk2zDYJcbbPc++6Nm6cRoAsOvQXOwmSSvSmtDhPCfsZgaGt20Aw53s7rYNmXGyXhGpNZyezDPgu8ADh6TkattwY9s2xstmIuf5wMl6X9cZ8N8fRRKo6lgMQ/jjuQt0bApmngkhRYXieYkwRKdTfGQu+2huIH5D3r3PHsE5q8dw/obJDOv1H2oSR2uY8zxg6EqW6YKKiXJXO0bL6dgsCPiT4KKX9AfGIioWmo4XCtnFZmds44IzJ2EIJZ6DxxwRu5bZbk2odzjPwzeV2c7g6AsQP5I8DqcrtgFkE41FxHee42Ib5pLFNvy2jZgNgwmHpBw42Rgonq2CxTY6JgyKYsY2ok59kTqyCSGE4nmJUGJSGbuHZhuZmzaA3g15TcfFQ7uP4ee3rs/k6Hbnd4ehpr5NxWRRgcFtGycWW6mbNhSTFatj/PVijPMM+Jf0Q7FrJHB2A3G6aLsomSIUXtWSic1nTODZQ7W28xzJV0ezqx2xjQRdz93jvgcd37D1WpEhKeqEpoiNCWmRUsa2bQC+8xzm0OOq6izVtqEvtjEWxDa8Ae8TKSX2n6z37XgGiuc8e5EJg0U7NgV7ngkhRYXieYkwIxllx/VwbL6ZueM5up5yPR/dcwKLLTdTZAPoze8qdh+Zx5s+9QC+ufNwx/ePzPltIRv61KcNa9uIy7AmoXeDn9sxIEUxHhkMM6hto9vZXWw6PTnVrRunfOc5JqNsRYRGtBIt2Uht5d73P77xcm+3dfxaXniSMErOc8P2YLsy9vdlsuM1zuc8d+fDG7aLalxVXXCi1hhQf1drOJhvOgPFs2UWy3l2IxMGDUOgQIcWEn2+iijuCSErF4rnJUI5u64ncXyhBU8i83RBoC241AfKvc8eQdkycPWr12Ve0zI7p549tX8W//kfHsYzB2t4dO9Mx22P1howBLBuMl48D2rbWGg5fR3rYUxU/NiGEjuLLbdjNHd4u4gbPWhDXtt5dsP1ujcgXnjmNF6eWcRs3RewUac4Oimu3nKhTP8kmefFlgPTEANjG0IITJYtzCVq22j3PAPZHNeioa5wxDvP7ddpUGxjWPPIv//wAH7yf3y744SnYXvhkJW4nzmo6/ngrN+0cVafmjrA/70pkgBU7ychBMyYk+gioGIbhqDzTAgpFhTPS4TKT370q0/jY3fuBJC94xmI9Dy7bfF81avW9d3dnwTLEOEH1KN7Z/DeWx7BWMnEuolyWK2nODLXxNqJSiiS49YC4j/k4jb5JWWy4l+qV8JwseXEO8+R52GweFZDSOxgvRjxvHEKUgI7D84G67Ufs2WISM+zh7Xj5WC94eJ5oekGzvLgmI06YRiE7Xrh4yyPUGyjFmSa4zPPg68uVEz/dRzkPDdsF39+1zM4OtcMBxcB/lWESkycRr2PB43ong16zNXvQhwlQySe5nkqUL8qpijuhkE7OKaKZRYyk00IWblQPC8RF2yYxF+++zJs3TgVRiA2rxvPvF5UnL5wdB4vHl3Az1+4Ptcxqvxuy/Hw259/DOunKvjKB6/Gq9ZP9Ijno3PNvpENtRYQ72AttlyMZ6ipA9qX6sOMcozYBdqi2BDoK/CBdmZ7PnSee2MbF501BQB4cl8gno2o8xzJPDsuzgic+CTieb7pdEQP+uGPEB+8Sc2vquuKbYyCeE7oPMdOGEwQ2/h/H3kJBwLRrH4WADRtr2/bBtCZb+9GvfaTA66umJGTriLQXVVXRHHqeh5MQ/iRlwI9d4QQwgmDS4RhCPzSlZvwS1duwnzTwSszi7jgzKnM60VjEV994gCEAN506Vm5jlHld+979ghmFlr4y/98Gc5ePYYzp6t4+kCt47ZH5poDB7xYXc64QkqJuh0veJMQjVmsm4zPKEdvN6imrnM9X/AsxIjxc9eMY7xs4sBsA2ZQ5aXws6u+OGvYLlaNlWAZIqHz7HS4p4OOMUlsw4r0PAOjkXmuBVGZ2J7nSvTqQkxV3RDxPNewcfO9u7FhqoIjc83Q5XY9iZbbf8MgMNh5VhtaB50YWaYIndQi0D2eu4jOs+NKWOHxLf/fbULI6EDn+RQwWbFw0VnTudYIe5ldiTue2I+rX7UOG1dlj4EA7fzuV394AOsmynj9+WcA8OMlh2uNjk1VR+Yag51nM955bjoepATGMsZLlCCZa9qQUmKxjxBXgro0wHUG2tMIVZtFPUY8G4YIT3S6RVrUea7bHiolI3CKkznPScTzZMUcuJ7nSbieDN1XlckeidhG6Dz3Pk/R1ynuJMk0BCxDdGzkjPKPD+zBiUUbN75pa/Cz/OdY3T62qi743qC6urmkznOMQN2xdwY/2ney7/2WCqVF2xsGiyeebdf/HS9azR8hhFA8LxOUWHj85RPYe3wRb7/8nNxrlkyB2XoL39p5GG9+zVmhGDtzuoLFlhu6qZ4ncWy+hfUDxHO/zLNy7MZiXL0kTEac54btC/FY5zkQVoNq4IBobEM5z05HU4fioo1KPHeuF808N4NR4RNlK7HzPBmT1+5msmsKYjdqsE135nkkNgyGmef0zjPgu89xzvPx+Sb+8YEX8eZtZ4UniepnqWE31ZjfnbEEGwbVazVV6d8oEzdh0PMkPvTFH+CTd+/qe7+lYnlMGPRjG0V1xgkhKxeK52WCim3c/dQhlE0Dv3jpRi1r3vfsUTQdD9dHxLja2KhyzzOLLbiexIb/n703j5LkLM98ny+W3LP2ql6qWmqpu6VWIyEhJFZjMNgGZnwQ9sU2eGPGXOPx2Pd4Gc+A77lwz9gz48O9c8wZH+MZL1xvYwwMxmONDchmswGDkAQSWrrV3Wqp1VW91F6Ve8by3T8ivsiIzIjIiFyqIrPe3zk66s7KisqqzK544snnfd5iWJuAf9uG2M7W62CjyDJXGrrrWMFVdUpIx7N1PK94rgXksW8PEM+yZ8OgtVijm9gVVBpGx4KXoMcYJsbbK+/GqapOuMF+7Szun11Ql3dKkXyz3/9wfg2VpoGfe8MJR5gLl1vkmYOWpADhznO5oUGWmG/sQyD7uKdPLG/j+m4d21Ut4LOGhzEKsQ2TQ5WZZ6snQRBEEiDxPCIIZ7faNPDG0wuY7LE3uf2Y1aaBYzNZ3HvTlHN7Szxb3c6ru+Edz+7H136SE45dr20bQkSVGnprlXbAkhQgvEPZ+riEtCK1Ms8BUYqWePYeT3HlL8VijfYu6iCiDgwW0+HH0w1/51kbg6Gq3ZqGjCoh7dO5nEu7YxsBzrPs7zw/ubKDrCrjjiMTSCsSUrLk5KvDxLNY2x6WeS7Xrec1rEXl+GwO1aaBp1Z2nNseetoaJC5FuPAaNNzd88wS2vNsr6BPqrgnCOLgQuJ5RHA3SDxwz9GBHvOBuxc9J/5253m1ZP0/LLYR1LYRJnij4B7wax3LJw9r3y+spk5QcDm7Nc2/Ru/04Qnf43kzz5bzbDnF3Vc4WzV7EZ3nut6xyEPQbBfPY+U8+28XBNqc54DnOSi28dTKDs4cnYAsMTDGMJFVXM6zHdvwcY4zKeu2bpnnbhdFb7t7EWlFwl9880UAlnh96OnrALytH3uF+GdqtdMktefZGopVSDwTBJEwSDyPCMLZLWYUfM/p3rYKdh7Tevrf/jKvGBdrxK/b4nnN2S4YHNsQx2p3P6t9Os/uddXCjc355IZFljhsu6D7mOWGjqZubbPL+zy2mXwKC8V0xzIO94m8bmeei2kF5QgCqNIwIotn3eSBGebA2IbRXcAnnd2aHriNsltVHWD9LNqXpBgmx9NXd3HX4qRz20RGdTLPYmDQ1+22BXst5J2Acr37EqDJnIp//tIj+OvHr6LS0HFhtYzn1yuYK6RQCrlQGhbiNez0PCdwYFA3rbaNpPZQEwRxcCHxPCKIzXRvvfOw79vLvZBNyXjJ0QmcXPBW6OVSCooZxYlrOKu5Q6rqgjLPNa3PzHOqlVEWERC/jLI4ftj2PkHBXkLSipT4P7YzRyc6RL9Ys2za4jatysin5a69zE3dRNMwIw0Mtg81ttO+NlyIZ00ffYFhOc/+z4dwd8O6vP1iG8+vl1FtGrjTJZ6LWdXJVwvnOR1SVVdrBrv6UeM4P/aKm1Bu6Pib71zF5566DsYsR9oweaizPQxMz4ZBBjOB4lQ3TShO28bov6tCEMT4QD3PIwJjDH/8L+/vu/LOzX/6wbsCh5xEXR1gOc/FjBIq2ru1bfQa25AlhlxK9sQ2/NxbIbKjOM8itlG1hb2f8wwAv/62OzsErCJJqGmG4wpnVCnSRkDx8UjOc6oVVZnzWYeut7VtCAe621rqUWC3pmE677+pL+e8uxB8gZRW5Q7H/kk7Z+x1npVW20ZIVZ0sMaQUyXmt+FFu6JgJeMxuXn7zNE4tFPCxb16Bbpi496ZpnFjIA7Ac9362hcZFGM1Om0UCnWfN0/OcvMdHEMTBhZznEeI1J+cChUUvnDk6gVvnC74fOzyRcWIbq6V6aN4ZsKb2GevMTjrubh9uuSN27bfO/SIgjrDq0rYBWA0e5YbuuMVBkZKbZnM4c9R7sSIyz2LIzIltNMPfei/HEc/pcOe5qYvYhvW9RllLPSrs1vWumeewLu+0LKHZ1vP85PIuMqqEE/N557aJrOpkjRtiYNAntgFYz3E9wsBgNxhjeNcrbsITV7bx9NVdvPklh1C0v9fSHueexb9TiVlDg5xjz6Mj3dAN08k8U9sGQRBJgsQz4cvCRNqJbXRbzS3wO8mJt6N7zTwDbvFsO8/riqOUAAAgAElEQVS+Pc8xYhsZFZWG4Qj7KPVxAtG24XYr82kFnIc3Moi8dpSv5cQ2AloYNGdgcAyr6moaJrL+PyNxARbW5e03MPjUyg7OHJnwONZW5tkb2wh6FyaXkrsODHbLPAt+6N5F5/l680sOOxGV3T1u3PDENgKGffcbK/NMbRsEQSQPEs+EL4cmMlgt1WGa3FrNHTIsKPA7yfUb2wDgxCJE9MHXeU5FHxgsCOc5pDc6CFli0A3uEVzdnGLAHdvo/rWchpGAIbWg2MaobxjknIe2bUh2hCfs3YX2nmfT5Hj66o4nsgGgrW0jOLYBWP8WHr281bHkRBDVeQaAqVwKP3rfMbzylhncPJt3nOe9btwQ4lnENgAkLrqhG62eZxLPBEEkCRLPhC+HimloBsdmtYnV3UbX2AYgtqj5i+egt8SjIJznWogQF+IlLA/rOV7ddbyIwsc6vnWBUHN9X90G/KyPGZ7HGf74ZM/ntNMe21BkCRIbfee5rlntJ0FtG4A1GBrW5d0+MHhpvYJK27AgYDnPTd1EXTO6iud/9foTuLRWwae/tdLxMd0wUdMMFEK2C7bzG2+/E5/42VcDACZtl32vu55b67mt2Ib7tqSgm1bPsyR1zlIQBEHsJySeCV8OT1pO86W1CmqaESm2IbsWiAhqTR1ZVYYUklPthuhRrjQNpGTJt6ZMZJ5TEavqaprhuH3xnGdr25kT20jJngG/IOIMDAohFjW2AQRv1hslxPMR5DwD1oVFWJd3e2xDLCW5a6ndeW45vmLAMB0QB3nzSw7h7mNT+PDnzztCWyBy84WIsY12HOe5tj/Os8QYxI8zcc6zKXqeyXkmCCJZkHgmfFmwF6WIpoKwmjqBX+a52jT6imwAImahodbUfTueActxVCQWaWBQuL+ivzrO4xO1WXXXkJm7izoI4UpHcZ7dK8n9aI9tiD+PuvMsBGRQ5hmwnOewaE5KkTxtG0+u7CCjSjjZNhjrZI1ruiuC4/86YIzhfW+5Hdd26vjv37js+VipYT3mqJnndpwNmvuUeRYbBoEEZp5dbRvkPBMEkSRIPBO+iC2DTy5vAwhfkCLwyzzXmv4b/OJQyCio2M6zX8czYAmcXEqOXFUHAGtlIZ6jCx9ZYjAMjoYr8xwltlHtoaquFLFtA7Bc04PgPOfTMtSQC6R0m/P85MoO7mgbFgS8znNdN6DKLLA7GgBec2IOrzs1h4986aInnyye82KM6I+brCpDkdiet204GwalVmd20rqeNaPV89z+jhZBEMR+QuKZ8EXENITzHC3zPBznOe/KPIflkyeyaqRKPCFg13Z7dZ65p0Wk24Cf9THRUd39a0kSQ97utvbDN7YxFs6z9f2GZZ4nMioyIc+XO7ZhmhzPtG0WdB/H+poa6poRKZP/vrecxlZVw8ftFdtA692GXmMbjDEUM8qeDwy6NwwmdmDQdDnPRrIeG0EQBxtakkL4osoS5gopXFqvAEC0zLPs4zzbK6z7oZhW0NRNbNeaoUL3wz96D+Z9loq0I4TOaqkBiQVnXf0Q7novsQ1VZr4roP0IW7zSEs+u2IYijXzbxla1CQCBGwYB4H1vPe0Ma/rhXs/9wkYF5YbeMSwItAb1dutWbCMd4TV65+Ik5otpPG//mwBa7w5EbdvwYyKr7ltsg7liG0lzng2TQ5ElMGYmLlJCEMTBhsQzEchCMYP1chMpWcJkiBsoUOxhOjeDiG3kXRnlsE1u9x+fiXQ8IXRWS3XkUwoYiz7MKJxnd0624FTVhfQ8N/RIkQ3nMWaUwNiGcOHcfcfj4DxfWqtAlhgWp7OB97ntUDHwY4BYkmKCc47zN0oAgNOHOz/H7Tw3NCOw47md2XwK6+Wm83dxwdRr5ll87l4PDLZvGASS5zxrhmkvxJES99gIgjjYUGyDCEQ0bswX05EEpl/bRlXrf+1wPt1yigexwlhkildLjdjCXrYn/1v1ZhIyqlUVV24EC6ByQ4+1jKUQ4jw3g9o2Rlw8n79RwvHZXGR33g+xgEQzOM7fKAMATi50btFszzyHrZ53M1dIY8POygOtQb84VXXtFNN77zy7NwzKSR4YlBlkn82lBEEQ+wmJZyKQQ3bDRpS8M2C7sj49z/06z2IYa7uq9Z2fBlou4XZVi+UGA5Zg1U3TyTxnVBmMMVvshjvPcd7az6eU7lV1UlvbxojHNi6slrs6y90Q4rmhGzh/o4RjM1nfC660IiElS07bRtTozmwhhY2Ky3m2L5h6zTwDVrtIu3hu6MZQ12V72jakpPY8c8iSZNVDUuaZIIgEQeKZCEQ0bETJOwPBbRtBDRlRcQvcQYhn9/Hi5rHF99jQDDBXXloscgmi0jACa/b8KGSCj+cb2xhx57muGbi8UcEpH5c4DsK1buomLtwo47YFfzHOGHO2DDZiOM+z+TQ22mIbjKGv13gxo3oGBg2T43Uf+hI+8ciVno/ZDUc8S0nueTbtDYO0npsgiGRB4pkIRMQ2onQ8A8Nt2xAMJLbhErFR2i/cOJln3XIrRZwlnw52igErthHHeS6klcD2Dr/YxqhX1V1aq8DkwKkBOc/VpoFL6+XQ401kVLttw4yeeS6kUG7oTmyn1NBRSCl9LQGayHhjGxvlBlZLDaxs13o+ZjecqjrXhsGkCVSr51mCLFPPM0EQyYLEMxGIE9sodO94BsJ6nvsTvO5hrEE4z2lFRsq22+I+NlmSwLkVw3C7lYVMsNgF7IHBmJnnOLGNlDzabRsXVq3hvr5jG/bzemG1BM3guO1QsJNdzKp220a0qjoAmCtYA6siulGu631FNgDr9V1u6M6/nRt2heIwBaN3wyDz3JYUrJ5nRj3PBEEkDhLPRCBObCOy8yw52+8AQDdMNA1zoM5z3Ixy8DGtx5SP+djEEpZKQ/dEPrrHNuK1beRDMtS6wSFLzON2jvqGwfM3SlAkhlvm8n0dRzjPT63sAggX4xN2y0VdixfbAOAMDcZ9R8EPZ8mOfbF0Y7cOYLhOsGm6xHNCnWfD1fOctMdGEMTBhsQzEcgdRybwy997G978ksOR7t9+knMWifSZeS70kVEOPKYtWOK3bVhCo9zwCq6wAT/AWpJSiJN5TstoGiYaeqeA1gzTE9kARj/zfP5GGcfn8o747RXx+U+u7IAx4MR8sPM8kbWyxlbPc/TYBgAn91xu9O88u5s/AOBGyRLPw3wnwRPbkJInnjnn1pIUWYLMSDwTBJEsqOeZCESWGH7xe09Fvr8iM9R1l3hutrbw9YPbHY6bUQ4+puL5f1QURzxrnoYGa4W4v3jmnMfveRZbCxtGR3Vb0zA7VlSnFAnaCDcSXLhRwpmjE30fR4jnp1d2cNNMLvS1Z2WedQA8VlUdAKzbznOprvfV8Ww9DrGwxRLPq3ZsY6jOsx3RkKWW85yk2IaIrKgSo8wzQRCJg5xnYmC0O89VWzz3G9tQZMkZ6Oo3Py0Q4jTuY2s5z7pHmIXFNhq6Cd3ksWMbAHwFuWaYnqYNwIptNEbUea5rBi5vVnEqoBkjDmk783x1p971eKJto66ZkTPPs+2Z58YgxLPlPIuhwVXbeR6mYBT/Tpl7PXeCBKqzPpzaNgiCSCAknomB0d7zPCjxDLSWUMTNKAceLyPEc2/Oc6XhHTLLp2WUG7pvN2+lhxXO4r5+yzN0g3fENtKKhKZPxGMUuLhaBuf9DwsC8MQvwoYFAUu0NnUTlaYeObaRSynIqnIr81wfRObZK56dgcEhxja4T2wjSc6zeyhWtjeXDrP3miAIIg4knomBodjb9wQ1zRIDg3CLRV643wiIIN+z82z9kyk3dE+9WSGtwuRw1na7EYN/cddzA/Bt8GgaJpQxim20mjb663gGgJTcej5PdRPPdtaYc0R2ngF7UYo789zHdkGgNTAoVnSLgcGhOs8+sY0klbWIi3DRtgG0ctoEQRD7DYlnYmDI9vY9wSCdZyE842aUgyjYx4mzuARwO89tVXX2cUo+K7rLjvMc/WuJ79cvCqIZvGOwTpXZyPY8n79RhiozHO+zaQOA5+fSNbbhiltE7XkGgNlCGmvlBkyTD3RgsCQGBvcw82xtGMTQv15cNPv3iGjbAOD53UIQBLGfkHgmBkZ7NlGI50E0ZPSaUQ48Xqa/zHO1aXir6jKtAb92hHscx3kWK8n9Gjx0v7YNWYZh8kQJoKhcuFHCLXN5qHL/v46EeJYYcLLLtkIhWgFEHhgEgLm85TyL53ViAD3PgBXb0A0TGxUR2xjec9mKbSRzYFC8jhVZavVQk3YmCCIhkHgmBobctmGwNtDMs3CKB9Xz3GPm2b3Vr62qDvAf8BPucZyv1XVgUO6MbQAYybq68zfKAxkWBFo/h5tmcl0FsRjUA+I6zylsVBqudxT6e02q9kDsbl3DernpCNthOq2G0/OMRA4MOrENqRXbIOeZIIikQOKZGBjtA4NOz/MgxLNwigfU81zs0cl2Z429mefgAb9eBgbDYhtNw+q/dSOc6FGLbtSaBq5sVbvmk6MiNgxGWfM9mXXHNuJkntPYKDed57rf2AbQWtEt8s7AXsY2bPGcIOfZGRh0Oc9JEvcEQRxsSDwTA6OQVp3cJuDKPKv9iwvHKR5Uz3OPzrM4kQMIiG0Ei+c4HdWFEPGsGyZSPm0bwOg5z8+tDa5pA2hd0EQZPnQ7z+1d2mHM5lPQTY6V7RqA/p1nwIpu7NY1RzwrEhvqAKizYdDd85wgcepU1Xmc5+Q8PoIgDja0JIUYGPPFNCpNw1kIUmuKto3+Be9kVkVKlhxncRDHAxC7o1dxiedM23puwH9gUOSg44gsWWLIpWRfJzs0tjFizvOO3TAxm08N5HjFjIrfeOAleNMdh7re1515jlpVB7QWpVxer9hfcwDOc9Z2nktW3vnwZGbIzrMV2QCSGdsQFw6qzJyGmyQ9PoIgDjaRzhiMsbcwxp5ljF1kjL3f5+Npxtgn7I8/zBg7bt8+yxj7EmOszBj7nbbP+bJ9zMft/xYG8Q0R+8d80bt9rdo0oEis75XLAPBTr74Zv/dTLwdjrPudI/CmOxbwWz9yN051GSprR5bd4rn1fYnv/fpOo+NzWs5zPJG1UEzjuuttfIF/bMP6uzZizrMQ++1LX/rhJ199HEensl3vl1ZaF2Nxq+oA4IWNKgD0XVUHWKJ/t65jbbcOiQGHJzJDzfianDuiWUrgwKDutG1I5DwTBJE4up6xGGMygI8AeCuAMwDexRg703a39wDY4pyfBPBhAB+yb68D+ACAXw04/I9zzu+x/1vt5RsgkoMQkGullngeVC/zkcksvuf2wV1fZVQZP3TvUmwxHuQ8FzMqJrMqVrarHZ9TbupIKVLsNonF6SxWtmodt2t6Z2xjVJ1nETMZ1DsKcWCMYcLOPccaGMzbzvOG5TwPIvNczCgo1TTc2G1grpBGWpWG2rZhcO689lvO89C+XGyE8yzLrg2II9pjThDE+BHljPEKABc555c4500AHwfwQNt9HgDwJ/afPwXgTYwxxjmvcM6/CktEE2POfMErnmtNY2DVcklBDhDPALA45S92K43ettAtTmWdXK0b3fSJbcijmXkWg2GDeHeiF0TuOVZVne08X3ac58EMDO7Wddwo1XFoIuNs1RsW3BPbsP6fpIFBEdGwNgwmb6CRIIiDTZQz1iKAK66/L9u3+d6Hc64D2AEwG+HYf2RHNj7ABvV+PLFvOM6ziG1oRuyBvKTjbdvwCq6l6SyWfcWzEWtYsHW8HNZKDdQ1b3e05hPbGFXn2RHP++A8A0AxG188z9j57Bc3BymexcBgAwvFNNS2zvRBY5rcGRSUEjgwKFaTK27nmarqCIJICPvZtvHjnPO7ALzO/u8n/e7EGHsvY+xRxtija2tre/oAiXjM5FOQmNt51mOJklHA4zy3uaWL05ZTzNscsnJD72kz4qKd273a5j43db8lKaPpPIvHO8jMcxzEgpM4sQ1FljCdU6GbHLmU7HlN9Pw4siqauonlzSoWJjKQJeZcWAwDg3NHNCdyYNBsDQxS5pkgiKQR5YyxAuCY6+9L9m2+92GMKQAmAWyEHZRzvmL/vwTgY7DiIX73+33O+X2c8/vm5+cjPFxiv5AlZq0uFuJZG7/YRlDmGbCc4mrTwHbV27jRa2xjadoSz+3RDd00O5zaUV2S0nS1KuwHonEjzsAgYHU9A4NxnQHXlsGGjkMTaSjycJ1nzgHxXp8Q0UmKRQiXWXbFNoaZAScIgohDFPH8CIBTjLFbGGMpAO8E8GDbfR4E8G77z+8A8EXebr+5YIwpjLE5+88qgB8A8FTcB08kj3mXeK6Oeea5fRhSOMXt0Q1R3ReXxWn/42kGD6yqG6ZbOQyE2E/L+/M6EZnnOFV1QKtabxDDgoC37u7QRAaKJA1VPBtmq22jtf46OeJUc28YlJPnjBMEcbDp+pufc64zxn4BwEMAZAD/H+f8acbYrwN4lHP+IICPAvgzxthFAJuwBDYAgDH2AoAJACnG2NsBfD+AywAesoWzDODzAP5goN8ZsS/MF9NO5rnWNJwhwnHBvZ673a1sOcVV3LU06dxebuhYms7F/lqH7bfv24cQNd30PA6gVVU3as6zs0lO2S/n2foVGGdJCtDqei4OyHl2L2w5NJG2lqQMuaquI7aRIOdZd96RkJyeZ4ptEASRFCL95uecfwbAZ9pu+6Drz3UAPxzwuccDDvvyaA+RGCXmi2mcv1ECMJ7Osze24XUrlwKc4kqjt5+DIks4PJHpiG1oYbGNEXOeRS913Bq/QfGOe5eci5Q4iK7nwTnPLfG8ULQezzCr2UwOZy13IgcGndiGawNigsQ9QRAHm/GqQiD2nfliGuvlBkyT2z3P4/USk0PaNiazKvIpeWCxDcCKbixvebujfWMbI+o8Nw0TjHkvSvaSU4eKONXDanDR9TyozLNwwAFgYSINRR5uVZ1p8kRvGNQ9GwYp80wQRLLYz7YNYgyZL6ShGRw7NQ21pj7mzrP3e2OMOY0bAs45Ks3eBgYBYKmtO9owOQyTd8Q2RtV5btqrxketqdJxngewXRBoOc+yxDCbt2IbQxXP7tiGMzA4tC8XG2fDoCxR5pkgiMRB4pkYKKLrebXUsHuex0w8B6znFixN5zxit66ZMHn81dyt42VxfbfuZIOdjPCYOM+azvet47kfxKKU4oAHBucLaSuqIDGn63gYuKvqxJspSYptiIFBVXI5z9TzTBBEQhi9sxaRaIR4Xt6qgvN4yydGgbANg4DVuOGOWZQbOgCg0MOSFMCKbZgcuL5jLekUbmRQ5nnk2jYMY9+2C/aDqKoblHgupBQwZg0LAlZcYdhVdUI0J3FgUHzvstTqeSbnmSCIpDB6Zy0i0QjxLLavjZ3zbCsORWK+Q26L01ns1nWU6lbXc8UWzz1nnqeslg6RoxYDdmPTtqHzfet47genqm5AmWdJYiikFSxMZABY2XptyLGN9g2DSRKnmtGKbbSc5+Q8PoIgDjYknomBIsTz5Y3xFM/iRB7kqLcvNin3KZ7bjxcU2xACdNTEc9MwR9J5PjqVxenDRdy1ONn9zhF57Yk5vPrWWQDWxdmwe57bq+qSFNvQzc6BwSSJe4IgDjbjVYVA7DvFtIK0IjnO87i1bSiOePYXfM6ilM0aTh+ecJznXh3KI1OWEymiIFpAbIMxhpQioTFysQ1z32rq+iGjyvjcL333QI/5336y1d4pNgxyzocyTOneMCgncMOgyHtTbIMgiCQyemctItEwxjBfTOPyRgUAkBvTzHOQ87zY5hRXmv05z2lFxkIx7QwhBsU2AEtQa/poCQxN7+ysJloXacOKKrg3DEpJdp6l1pIUEs8EQSQFOmsRA2e+mMYVW+yNW2xD6SKe5wtppBXJcYpL9f4GBgEruiEyz42QpSIpRULTMHr+OvvBqMY2hs2wBaO7qs76eixhzrPVQy25nGfKPBMEkRTorEUMnPlC2sneZsdMPMtdYhuMMSxOtbqeP/XYMqZyKo7acY5eWJzOOcf79LeXwRhw++HOxR4pWRq5zLM2orGNYSMy7MNqTzE5PHEQmTEkKfGjmSYU+3XRyjwn6AESBHGgobMWMXDE0CAwfuKZMWuAKaMEf1+L09Zik384v4avXFjH//HGU8j1kf1ems7i2k4NVzar+KOvvYAfvGcRt/lsxUspktOPOyqMatvGsBn2kJzJOdzXLJKUrPXXhsEdx5mcZ4IgkgaJZ2LguMVzTh2vgUHAEjZhFwVL01lc2arhNz9zFjfN5PCTr7q5r6+3OJWFZnC8/9PfAQD8mzff7ns/VWYj5zw3DBOpkAuRg8qwBWNHbIMNt90jLrrZEs/UtkEQRNIYP2VD7Dvj7DwDlrBJhznPU1lsVprYrDTxOz/2sr4zvWII8WsXN/CvXn/CafRoJ6XITiZ6VLAGBsl5bkdEFvQhvZNgcnjEszTkary4uOM8JJ4Jgkga5DwTA2e+4HKex1Q8B2WeAWtFNwDcfWwK//yuI31/vWO2eJ7Oqfi5N5wIvJ8V2xgt8UwDg/4MeyW1aVoDee6vl6TYhm602kBIPBMEkTTIeSYGjsd5HrOqOsByBcPWjt+1NInJrIoP/sAdA+noXZrO4chkBr/4plOYzKqB90uNYGyDBgb9GXa38SjENsTrQmz1pMwzQRBJgcQzMXCEeM6oktMhO05818k53H98OvDjJ+YLePyD3zew5RYZVcY/vf+NXY+XUiTUtRETzzqJZz9EbGNYA6CGyT3/NqWkOc+m6XSZk/NMEETSIPFMDBwhnvtpmEgyv/2ul3W9z6C3wkU5XkqWnF7pUYFiG/4M23nm3GrYECTOefZr2xixJhmCIMYXOmsRAyetyJjMqmMZ2Ugy6gj2PDdpw6AvQ88881amWHy9JMXlddN04hqSxMAY9TwTBJEcxtMaJPYdd+6Z2BtSyuiJZ82gnmc/xM9kWG6r0ZZ5TlrPs25wzwp6mTHKPBMEkRhIPBND4fBEBpXmaEUIRh1rPfdoiWeKbfgjD3lIzn/DYHLEqWZyJ/cNJG99OEEQBxsSz8RQ+MAPnBm52rRRZ9TWcxsmh+FqVSBaDL1tw+RwG/5SwsSpYZrOzwCwfh4GZZ4JgkgIJJ6JoXD74c710cRwGTXnWVxckfPcSWtIbniZ5/aqOjNJzrNrYBCwnGeKbRAEkRTorEUQY0JKlqCNkPMshD4NDHYi8r7DjG1IHQODyRGnelv/tyJLiXp8BEEcbOisRRBjgjpqzrMt9Cm20YnIPA8ztuGuYJdY0nqe2wYGyXkmCCJB0FmLIMaElCxBM3ii3n4Po0mxjUBEZGFYcwMdsY3EOc9tsQ3GqKqOIIjEQGctghgThAjVRkRkaLol1sh57kS4rkNdz922YTBJ83junmcgeT3UBEEcbOisRRBjgsgOj0rjhnCeqee5E2dgcJiZZ8/AIBL1jkV7z7Mik/NMEERyIPFMEGOCcJ5HRjzbjzNNsY0OFKfneZixjdbfExfbMKltgyCI5EJnLYIYExzxPCLvb2sGDQwG4aznHtaGQZNDdm8YZMnqedYN07MkRUmYuCcI4mBDZy2CGBNEbENkiZMO9TwHM+zMM2/fMCglrOfZ9K5tlyWJnGeCIBIDnbUIYkxQHefZ2OdHEo0mVdUFImIb2hAHBt0/9qStv9YN78AgOc8EQSQJOmsRxJggnOfGqGSeKbYRiLOee0gRHMP0VtWxhG0Y1E3uRFcAqw1kEM7zIy9s4r1/+ujQNjcSBHEwoLMWQYwJYvBOS1LnWAg0MBiMvAcbBllb20aynGdvbEMZUKzkm89v4u+euYFL65W+j0UQxMGFzloEMSaoI1ZVJ0Q+Oc+dqE7bxh7GNhL0stFN78Cg1bbR/wOsa1ak6ey13b6PRRDEwYXOWgQxJoxaVZ1GPc+BiMjCUJektLVtJC224a6qG1TmWUSazl4r9X0sgiAOLiSeCWJMcDYMJslCDEGIfGrb6EQZclWdaXau5zYTEtswTA7O0bFhcBAuvHCez10n55kgiN6hsxZBjAnCwR21gcEUxTY6kCQGiQ1zSYp3w6CUoLYNcfGnyENwnjXhPJN4Jgiid+isRRBjQpqWpIwVyhC7jTs2DCYotiG+Z2/PMxuIC1/XLef5xm4Dm5Vm38cjCOJgQmctghgTUrIMANBGxXmm2EYow1yZbbRVwSWp59mwRbLcFtsYRKxEOM8AcI7cZ4IgeoTOWgQxJqiKJYbIeR4PFJkNLb/evmHQGhgcypeKjWZ2DpIOyoWv6wYWp7IAgLPXaWiQIIjeUPb7ARAEMRhSI1ZV1zQ6354nWgxzq15HbEMaXrNHXEQ8o31gcFCZ58WpLBq6SblngiB6hiwfghgTRrFtIyVLHgeUaCEPMfNs8OHHNv7zQ8/im89vxv48MSTZXlU3kJ5n3UBalXDHkSI1bhAE0TMkngliTFBHbD23ZpjkOoegymwoa6Q55wGxjcGJZ845fvfLF/HZp67F/lzHeW4bGDQGMDDY0EykFRl3HJnA+RtlWtNNEERPkHgmiDFh5GIbuknDgiEMqtu4HWEwy2x4znNNM2ByoK7Ffy06znPHhsHBZJ7TqoTTh4to6iaepzXdBEH0AJ25CGJMkCQGdYhDZoPGcp7pV1AQw8o8C5HszjxLbLBfq1zXAbSWksTBWdveHisZUOY5YzvPAA0NEgTRG3TmIogxIiVLo+M8k3gORZGloWwYFJVvUps4HWRso9ywxHOtGV88C5Est2WeB+GMN2zn+cR8AarMaGiQIIieoDMXQYwRqiKNTFVdUzedxS5EJ4MakmtHHLJ9PfcgYxtCPIulJHHwqzCUJWlgmeeMIiOlWAKaup4JgugFOnMRxBiRkiWKbYwJijyYrXrtmAGxjUHqdBHb6MV5Ftlmz3puebCZZwC448gEnqXYBkEQPUBnLoIYI1KKNEJtG5wGBkMYVlWdEM/eqjoM1HkuNXrPPOuG3+PrP/NsmNBw4F4AACAASURBVByawZFRrE2cc4UUtmtaX8ckCOJgQmcughgjRirzrFNVXRjDGhgUDrO7qk4e2sBg720b7nclBhFhadgREuE8pxV5ZC40CYJIFiSeCWKMSCkjJJ4pthGKIg2nOcU3tmH/ZVBDg5WmHdvow3l2L0mRGIPJrf7oXmnYQj5jv9uRUSXbjR6Nfy8EQSQHOnMRxBiRUkYn80w9z+Eo8nCr6jyxCNuFHlR0o9RXVZ2/8wz0t0K87jjPVmwjbcc3yH0mCCIudOYiiDFClUenbUMzTGexC9HJsDPPng2DMcXpZqWJS2vlwI87VXU9iGe/qjrZjvf08/NwnGdV8vy/F4FPEMTBhs5cBDFGjFLmmdo2wlGHVFUXtGEQaAnrbnz478/j3X/0zcCP97UkxRbI7jz8QJ1nhZxngiD6g85cBDFGpBQJzSHUmw0Dim2EI0vDqaoTAtSdeXZiGxHF6Ualges79cAMcsV2njWDQ4/5Toi4vyJ5e56B/pznepvznCbnmSCIHqEzF0GMEepIOc+cnOcQhpV5bg0MdsY2ohrd1aYBzeBOPKOdkuv2eoTX41MrO/j5j30Ldc1wBHL7hkGgP+e5oQU4zz00ghAEcbChMxdBjBFpRUKzh61u+0HTIOc5DGVImWdhFnvWc9t/jDowWG1Yr7Gtin9PsohtANGc3X96bh1/+51r+MLZVcdtd19YicfaT4xFiPiOzPOI/HshCCI50JmLIMYIq21jhGIb1PMcyLDWc/vGNmI6u1XNEseb1abvx92OdJQtg2VbjP/Vt5ed71kZcOaZnGeCIAYFiWeCGCNUmY1QbIMGBsOQJQZjqOu5fWIbsZ1nf/FcaeiOOI/iPIuM9JefXcPqbgMAoHoyz4MYGCTnmSCIwRDpzMUYewtj7FnG2EXG2Pt9Pp5mjH3C/vjDjLHj9u2zjLEvMcbKjLHfafuclzPGnrQ/57eZuzeJIIiesAYGR0c8U2wjGEWWnOaJQeKIZ7+e56jOs+0mbwaI51JDx2whDSDalsFyXbeddo6/fmLFekzkPBMEkVC6nrkYYzKAjwB4K4AzAN7FGDvTdrf3ANjinJ8E8GEAH7JvrwP4AIBf9Tn0fwXwMwBO2f+9pZdvgCCIFilZhjYCzrNpchoY7MLQ1nOLzLPPhsGoX09sENwKim3UdczZ4jlK13O5qeOmmRxOHy7iymYNgHfDoCz13/MsnOd0m/PcIOeZIIiYRDlzvQLARc75Jc55E8DHATzQdp8HAPyJ/edPAXgTY4xxziuc86/CEtEOjLEjACY459/gVtfRnwJ4ez/fCEEQlvPcGAHnWbNzreQ8B2NV1Q1vPben55lFj21wzh3n2U8864aJmmZgvhhdPFcaOvJpBT9076Jzm3fDoPXnQTjPGbFhUCXnmSCI3ohy5loEcMX192X7Nt/7cM51ADsAZrscc7nLMQEAjLH3MsYeZYw9ura2FuHhEsTBJWVnnoP6d5OCyGXThsFgVJkNpW1DCFDmsyQlijhtGqZzv02fto2KnYeeK6QARM88F9IK3nb3IsTD8g40Wv/vp/daLENJ2xdsGYUyzwRB9Ebiz1yc89/nnN/HOb9vfn5+vx8OQSQa4eQOQ3QNEs2pI6NRhyCGtZ6bh8Q2ojjPYlgQ8B8YLNuRjnkn89xdnJbqlvN8eDKD156YgyqzNnE/GOeZsdYFGznPBEH0ihLhPisAjrn+vmTf5nefZcaYAmASwEaXYy51OSZBEDER4rmpJ7vJQrPjCCrFNgIZVubZ8FlC0hoY7P75VZcY9quqEx3PIrYRyXlu6iikLTH7vrecxsPPe08fzsBgH++o1HUTaUVyRLnjPNOGQYIgYhLlzPUIgFOMsVsYYykA7wTwYNt9HgTwbvvP7wDwRR7yvjHn/BqAXcbYq+yWjZ8C8NexHz1BEB6EYE56XR3FNrojNgz6/Sp9fr2Cf/FH30S16b/hLwy/qjrxNEQR61W7Vo6xAOe5YUU5nIHBCD3PlYaBfNrycu5amsT//rpbPR9vxUp6f103NMPJOwNWm4ksMSfOQRAEEZWuZy47w/wLAB4CcBbAJznnTzPGfp0x9jb7bh8FMMsYuwjgVwA4dXaMsRcA/BaAf8EYW3Y1dfxrAH8I4CKA5wB8djDfEkEcXITzrCV8aFDU6dHAYDBKSMPEY5e38OVn1/D8eiX2cZ22DZfzLMUYGBTDgoeKGd+BwVKb81yLWFVXyAS/Eer8LPrIPNc108k7CzKKRM5zgqhrBrYDGlwIIklEiW2Ac/4ZAJ9pu+2Drj/XAfxwwOceD7j9UQB3Rn2gBEF0Rzi5SXfThLgn5zkYd87XZZgCaEUN3Guwo9Jynt1fK/rAoKipW5zO4vEr2zBN7hHiYmBwNuLAYFM30TRMFFLBp6NBLElp6F7nGbByz0n/t3KQ+O0vXMDfPXMDn/+V1+/3QyGIUOjMRRBjhJN5TrrzbAuWJOey9xsxTOn3LoIQfO412FExzc7YhhQjUyxiGEvTWRgmd5xmgYhtFDMq0hGcXbFdUMQ2/BCruvvqeSbnOfFc26njxk69+x0JYp+hMxdBjBGpEck808Bgd8LcVsd57kE8G36ZZxHbiOQ8W197cSoLoHNoUIjpQlpBNiV3FafiewiLbUgxNyD6Qc5z8qk1DaoOJEYCOnMRxBgxKpnnBg0MdiUs8yx+fu2ubxT8qurixCJqdmxjaToHoHNFtyOG0woyitx1SYr7/kGIJSmDdp6jOOPE3lHTDGgGH0rLDEEMEjpzEcQYMSptG6LnOaVQz3MQiv1c+g3JNfpwnp0Ngz4Dg1FiGyLTvDhtOc/tjRuVho5cSoYsMWRTcteBwSixDco8HwzEhRZd0BBJh8QzQYwR7p7nJKNR5rkrsuM8dz6X/QwMhm0YjNIEJwTO0rR/bKNsr9oGojm7kZxnuX/xTM5z8hF5enpOiKRDZy6CGCNGZmCQquq6ooS4rf0MDPrHNqz/R3Oedagyw6GJDIBO57lU11G0hXCszHME59nvQiIqDd1wtgoKMuQ8JwrHeabnhEg4dOYiiDFi5AYGyXkORMQ2NJ/YhhCku3Ut9nHDYhtRBgarTQNZVUY+JSMlS77Osxj+y6py1yUprdiGHHifsAuJqJDznHzIeSZGBTpzEcQYMTLOMw0MdiWS89xHbEPyiW1E2jDYtGIZjDFM59UO57lc1x0XOaPKXdsTynaGOsx5Fo+1n4HBhm52ZJ4zqpz4C82DRJ0yz8SIQGcughgjUvJotG1QbKM7kTLPPQ0MWv93aed4A4NNA9mUJUKncylsVrzud7nREs/xnOfhZp4bmkHOc8JpDQwm+/cXQdCZiyDGCBoYHB/EkhS/tg0hLgbVttEaGIy2JCVvbwOcyac6VnS7xXNGlbsKoXJDR1qRQl8Lg2nb8HOeJco8JwTOuSOeG3RBQyQcOnMRxBgxKlV15Dx3Rw7pNm7og1jP7RPbiDgw6DjP+VRnbMOVec6o0do2wiIbQKvnuVfxbJgcTcMv89x9oJHYGxq66Qyz0qIUIunQmYsgxohW5jnZSwbEEJxwV4lOwjLPws0t9RHbcItn8bWixH1qmoG8LZ5ncinPwCDn3JN5zqrdl6RUXGI7CDlkYUwUxMUkOc/JxR3vodgGkXRIPBPEGJEekdiGeHyqRL+CgnA2DPoI2r6cZ2dgsHXbZFYFAOxUu7d3WEtQLLE7nU9hp6Y5j7Ghm9BN7nKeLWeXhzja5bruxECCaF1I9Pa6Fu6yn/Osm9z3Z0zsLe6LLHo3gEg6dOYiiDFilGIbqswgSeQ8ByGG5PzcVuHM1TQjtvDzi20I8bwVQTzXmgZyjvOsgnNgp2Z9XntnczYlw+Th7S9RYhv9Os+NEOfZ/XFi//CKZ3o+iGRD4pkgxghZYpAllvi2DU03aViwC63Ms5/z3LpNrMuOioiBuAcGFVnCREbBdtvwnx+VpuE0Y0znUwDgDA0KJ9w9MAgA9Wbw67HS1EM7nt2P1egxjhTmPLs/Tuwf3tgGPR9EsqGzF0GMGSlZSnzPs2aYNCzYhVZsw2dgUDOcLX5xF6Vwn6o6wB7+i+g8i4HBGVs8i7q6dudZOLthA2CVhoFCRg39mnKfPc/kPCcfj/NMA4NEwqGzF0GMGarMRiS2Qb9+wgjrNq7rBuaKaQDx6+r8quoAYCrXWTvXTlM30TRMZ2BwOifEc9PzWNwbBgGEdj2X6joKXZxnSWKQWOuxx0U4mUIsC8h5Tg40MEiMEnT2IogxI6XIiXeemzqn7YJdcBow2sSzYXJoBses7frGFc+GT+YZAKZzKra7OM9C4GRdPc9AZ2yjmLacZCe2Eeo8dx8YBKy6ul6d51Zsg5znpOJ2nqnnmUg6dPYiiDEjrUiJd54pttGdVrex97kUTRtzBdt5jtm44bdhELBc5G7Oc1WztwF2cZ5Fhrmb82yY1mKMblV1gOWU99rz3IptkPOcVOrUtkGMEHT2IogxYyRiG7pJHc9dkAMyzw37Le3ZgiVc43Y9i9o4mbXHNro7z2I4UWSesykZWVV2FqWU2mIbwnkO6nquNL0Z6TAUifnmv6MQ5DynyXlODBTbIEYJEs8EMWakFCn5bRuUee5KUFVdvU/n2TCDYhsplBt66IWXEDjumMVMvrUopTO2YYvTADEk7p+PIJ4lifXc80zOc/Kp2q+tiYxCA4NE4qGzF0GMGakRiG00KbbRFSVgPbdw5VoDg/HaNvw2DAJW5hlAaF2dcIpFzzMATOdVx3muNHTIEnNEqnCoA53nRnTxrEiMMs9jjHiNTOdTdDFDJB46exHEmKGOQFVdk3qeu+Js1TP8M88zuRQY6yHzLJznth//VE4M/wWLceE851xi99h0Dk8s76Dc0J2FJ8wW5pkuzq7ISBcjiGdZYj23bQhxnCbnObHUNQOMWQt7KLZBJB06exHEmJGSpcQ7aZphUttGF+Sg2IYtLLIpCYW0Ejvz7LdhEGgN/4UNDfo5zz/7+hPYrDTxe//wnF071xLC3ZznclznecCZZ3Kek0OtaSCnysgoMl3MEImHzl4EMWaMQuaZYhvdUQNiGw2XECymFZR6bNto73meznePbYhcqls833NsCj/w0iP4g69cwnNrZY94znRp26i0tXOEIcvDa9ugarT9p6ZZy3fSqoQ6XcwQCYfOXgQxZqTk5GeeNZ1T20YXnJXUHQODLSFYyCg9VNVZx/OrqgPCYxtVIXbbepn/3ZtPwzA5Hr+y7amd6+bslu32DjFgGEY/Pc8NOxLQ/m4HOc/JoaYZyKgyMqpMFzNE4iHxTBBjxigMDFo9z93dxoOMsySlPfPscp4LaSX+hsGQtg0gPLZR1bxVdYKbZnP4qVcfB+CtnUvJEiQ2GOdZYv7bFqPQ0E2kFcnJYgso85wcak0DWVs80/NBJB0SzwQxZoxCbKNBPc9dESupw51nNXbm2Qjoec6mZKQVKbTrudowIEsMaZ/IzS98z0lMZBRn8yEAMMaQUeUBZZ4l6D1W1dU1oyPvDFid6BIj5zkJiNhGRpFoYJBIPN1/YxEEMVKMRGyDBgYj4RdVqLdlnle2qrGOGbRhELC3DFbCM885Ve5wcAGrYuyvfv61Hc0Z2RAnsdzQoQSI8Xb63TDYnncGLHGfpgG1RFBrtmIb1PNMJB0SzwQxZqjKCFTV0cBgJBSZQe+oqmvVrvUS2+CcQ2LwFcBTOTU889zUkQuJWJyYL3TcFuY8Vxo6ChnF97G0o/QxMBjkPFuPL/ntNAeBumZgOp9CRpXoYoZIPHT2IogxYyScZ+p5joTssxhEZJ4zqtzTwKBh8o68s2A6l+qyJMVALhXPc8moUuiGwfbhwyD8fhZRCXKeAZDznBBqmjvzbDpr5AkiidDZiyDGjPQIOM+awUk8R0DxiSo4zrMioZhRUGkasRxZk3cOCwqm82rowGCtqXtq6qKQTYVnngsR8s6AtfwnSIR3g5zn5FN1DQwClEMnkg2dvQhizCikFdQ1E9VmPEdyr+CcU2wjIoosQTM6M8+idk0Iz0qM59rkvGO7oGAqlwodGKw0jNjiOaPIwW0bTd1TbRfGbD6FzRBhHwY5z8mnrhnI2EOrAHq+UCKIvYDOXgQxZtx+uAgAOHe9tM+PxB8hBlPUttEVy3nuzDxnFGtor2gLzziLUszQ2IaK7ZoW+JZ5VYsf28imggfAyg0jUtMGAMwWUtgoN2J9bQE5z8mn1uY809AgkWRIPBPEmHHm6AQA4Jmru57bP/noFfzFN1/suP///PYKLm9U9uSxAa3eYnKeu+OX861rBtK2i1qwl4vEyT2bvLOmTjCdS8EwOXYDjldt6JE6md1k1GDnuVzXUIh4vLlCGltVrWOAMgrkPCcbzjlqmvWuhiOe6TkhEgydvQhizFicymIio+CZa17x/F8+fwH/4W+e8bQzXLhRwi994nF8zEdUDwsxzEiZ5+6osgTdJ7aRsV1UEXkoN4KjFu2YnPvW1AFWbAMIXtFt5VLjDgzKgc5upWFEzjzPFtIAgM2QKr0gwpznNDnP+07TMGFy2FV11u8F6nomkgydvQhizGCM4czRCY/zfH2njpXtGipNAw8+ftW5/c8ftkRzJWbdWT8I55nEc3f8uo0buulynnuIbXAOSQqObQDBK7qrzfjOc1aVQjcMRo1tzNnLV9bL8cWz+2fWjuU8k1DbT8TrI6vKzoUhOc9EkqGzF0GMIWeOTOLc9V1HeD12eQsAUMwoTnSj2tTxl99aBmA5gHuFcPkottEdRWIdW/XcznPRcZ7jieeg2IZwnoMWpVSbRsdq7m4E9TxzzlFuRm/bEM7zRiV+7rmumV0yzyTU9pOaa+07xTaIUYDOXgQxhpw5OoG6ZuL5dSvL/NjlLWRUCb/4plN4cmUHTy7v4H89cRWluo6UIu2p87xassTPfDG9Z19zVLGWpHQ6z5k25zlO5tkw/RekAG7nuVM8GyZHQzcj9zILgjYMVpsGOI+2mhsA5gqWsN/oyXk2QjPP1Oywv3icZxHboCgNkWBIPBPEGHLmiD00aOeeH3txCy9dmsIP33cMaUXCXzzyIv784Rdx26EC7jw6EavqrF+ubtcAWNlsIhw5YD13uiPzHP35ExsG/ZgWzrNPbENUH8auqrMzz2bb9yEu2OI6z+uuxg3OOX7lE4/jqxfWQz+3sQfO843dOv7fh871vAXxIEPOMzFqkHgmiDHk5EIBqszwzNVd1DUDT6/s4L6bpzGZVfEDLz2KTz26jO8s7+AnXnUz8mllT2MbK7Z4PjKZ2bOvOar4LUmpa67Mcyp+5tkwOeQA9TyRVcGY/8Bg1XYH428Y9K8eK8cUzxMZBarMPJnnnZqGT397BQ89fT3w80zT6hUPb9vo3+X89LdW8JEvPee820NERwhlj/NM4plIMCSeCWIMSSkSTi0U8cy1XTxxZRu6yfHym6cBAD/2ymNoGiayqoy3v2wR+ZSypwtVrm7XMJFRUMyoe/Y1RxVFYs6ApaCht1xUSWIopJWYmefgDYOyxDCV9d8yKJzi2BsGA9oTxGOOGttgjGE2n/Z0PYsLsStb1cDPExl7IeLbGZTzfNZ+l2enFr35hLCoNa3nKJuSndc2RWmIJBPPQiAIYmQ4c3QCX352DY+9aA0LvuwmSzzfe9M0XnnLDO45NoWJjLrnzvPV7RqOUmQjEorMOkREQ/PmdwtpBaV6dMHGQzYMAlZ0wz+2IZzn+LENAB1Dg3GdZwCYK6aw4RpmvLpdBwAsb9UCP0cI43TAgGpakaEZPNSRj0JLPPe2BfEgIy7eaUkKMSqQeCaIMeXMkQl86rFlPPTUddw6n8eMXfXFGMMnfvbVzv3yaXlPM88r23UsTZN4joKVefaKCGtgsCVgC5l4zrPBgzcMAsBUTg2NbUR1igWinaP9bXgRNSlGXM8NALP5tCfzLPLzy1tVcM59ByGF4x3mPAOWyI4bSWl9DQPPrZUBIHS9OeGPuLDKUGyDGBEotkEQY4rYNPjE8g5ebrvOfuRSyp62bZDzHB01oKrO7aJazvNgYhuA7TxXggcGe6mqA9DR9Xx9x3KND8fIvlsrut3OsyWe65rpcaTddHee+1/Kcf5GCSKanjTxvF1tBvZs98Jjl7fw+WduDOx4gCvz7BkYpNgGkVxIPBPEmHKH3bgBAPcdDxbPhbT1tnVzD6qhyg0dOzWNxHNEZCmoqq4lYIsxnWfTDG7bAKyu51DnudeBwTYn8ep2DSlFwqz9jkgU5guW88y59TMRmWcgOLrR3Xm2M7Z9xATcC4mSlnl+1x88jP/noXMDO97vfuki/q//+dTAjge0LqxyqgxVliBLjJxnItGQeCaIMWUyqzrxCDEs6Id4q3ov3GfhFJJ4joYi+7VtdDrPcXqezS6xjemcOtDMczbASVzZruHoZCawc9qP2UIKDd1ExX4sV7drjvheDhgaFCIs0HkewDros9d2UUgrKKaVRIlnzjkurZWdf3eDYKvaxPXd+kC/z5rWGhgEgIwiDdx5bujGQH8OxMGGxDNBjDF3Hp3EVE7FrXOFwPuIga29yD2vOB3PVFMXBaWt51k3TOgm92aeY7dthA/GTedTqGlGh/PXa89zNmBgsJf4zmze7nq2F+1c3a7j/uMzAIKd565tG8oAnOdruzh9uIipvH9efL8oNXQ0dDPW66MbIpZycbU8sGPW7NeWuMDJqPJABwaXt6p4+0f+CW/+8D8671oQRD+QeCaIMebX/tlpfPTd90MKEUu5tCUeqgPMRQZBznM82tdzt4Sgy3nOxHOewzYMAtbAINCZ3RW56vg9z9Zj7RTP9fjiWWwZrDSgGSZulOq47XARUzl135xn0+Q4e62EO45MYCqbwnaCnOc1+yKjPMA2HVFjeOFGaWDHrGkGsqrsvC4zAVspe+HhSxt42+98DWev7aLU0LFb27v5DmJ8IfFMEGPMzbP50MgG0GpPGKQ7FcTV7RoUiWGhSM5zFGSJwXBlnltC0JV5TisoN/WODX5BhG0YBFpbBv/h/KqTUf9PnzmL//L5C1icygYuGwnCL/MshG9c8TznbBls4vpOHZxb72IsTWdxZbPlPO/WNfybTz6BD33uHL787JrncXQ8PqdXuDextrxVQ7mh48zRCUzl1ETFNoRD30sk63NPXcNrfvMLnufNNLnz/V0YpPOsGZ5B1LQqDaTn+aGnr+PH//BhTOVU/OKbTgEA1iuNLp9FEN2hqjqCOOCIAbDqHnQ9X92u4/Bkpq8+3YOEIkvQXKLYz3meLaTBubW2emGi+0VJt9jGbYcKyKgS3veXT+L//KunkFWtKsN33LuEX33z7bEyykArx1p1CTi38I2DEM8b5abnXYxj0zmcdzmhXzq3ir/81jIkBqcFYyJgKY/jPPc4MPuM3e98x5EJfPXiOlZCOqf3mjW71i/OOxOCJ1d2cHWnjrVSA8dmcgCsdx/Ez/P8IJ3npunEewDrgqZf5/nCjRJ+5ROP4yWLk/iz97wC37myA8B67ZyY7+vQBEHimSAOOnk7trEXzvPKFtXUxaF9Pbef83zboSIA4Nz1UiTxbPDw2MbJhSK+/YHvx7de3MLXn9vAtZ06/uVrj+POxcmevoeZXAoZVcKLLme41/iO6CpfLzeQTUnOMZams/jiuVWn6/nbL24jq8r41ge+D5fWy9it6bhpNud7zHSfzvPZa7uQGHD7oSKmsmoiYxu9OM+bdvXfZqXpiOdtewFMSpYGmnmutznPGVXqK/O8W9fw3j97DNmUgt/7iZdjIqO2Ij9lcp6J/iHxTBAHHMd53qOBwVfcMjP0rzMuyG3ruVu1ay3n+fRhIZ538d23dbfUusU2AMstfu3JObz25FwPj9qLJDGcXCjgwmrLqby605t4TikSJrMqNsoNxz0/OpnF0nQODd3EermJ+WIaj13ewt3HJpFNyXjJ0XDRnxmA83zLXB7ZlOzENoIWtuw1YqFMuanHfkzr5ZZ4FogWlpcuTeLRy1vYrWuBjn4cqk3d6zyrcl8Z9F/++OO4slnFx37mVU6PuBDP6wF94AQRB8o8E8QBRwwMVoY8MGiYHNd36zhKTRuRUduq6pyFHy6hMZ1P4fBEBueuRXsb3TA55D0WdrctFD1OpVirfXQy/rsQs4UU1itNrGzXMJNPIZuSnUrG5a0qak0DZ6/t4t6QxUBuBuE8i071qWwKhsn35F2cKAjnmfP4A8HCoXWLZ9Ekcr99ATwo91kMDAr6GRj8xqUNfOHcKn7tn93huVAXWf7NMolnon9IPBPEAcepqhvyCX+1VIdhcixO+b99TnQit1XVCTeuvTni9JEizl6PJp679TwPg5OHCri2U8du3XIu3cI3LnP5NNZLDbvqzroQW5q2XlPLWzV8Z3kbusm7DsoKwjLP//dfP4W/+c7VwM/dqWlY3qo52zwns/5NJfuFEM9A/H/fG5VO51l8X6+w6wEH1bhR00xk2mMbPYrna/bmyu+9Y8FzuypLmMqp2KCBQWIAkHgmiAOOVRHlHegaBq2cKznPUVEkBt1wV9VZgqK9OeL2w0VcXC15Ih5BmByQ9vg3/6kFK1oinEq38I3LbCGFjYo1MCic60XHea7hsRe3AAAvi+g8OxsG28TaynYNf/L1y/jPDz0b2A0shubuOGyLZ7vmLymNG2uufG9cN1ysQd/wcZ7vXJxEWpFw4cZgnOd600DWFUWyBgZ7i22IKr1pn82Vs3nveneC6BUSzwRxwGGMIZ9SBtoF64dYYrFIA4ORUWQGk8OpoQtynu84PAHN4Hh+veJ7nLVSwxE+1nruPY5tHLKW9Ain0i184zJnr+h2D58W0gqmcyqubFXxrcvbuGUu7wwXdkP8LBttzvOXzq0CAF7YqOLh5zd9P/fFDatb+mZ7GHEqmyzxvF5qOj+HSox/33XNcMT2psupFZnn6ZyKE/MFnB9gbMPdH55W5Z6X1mxWmlAkhmK6c6Rr1n7tEES/kHgmCAK528/7AgAAIABJREFUlDz0gUGRcz1C4jkyij0UZ9jOZ5DzfPqI5eyetWvT2vnpP34Ev/bpJwHsT2xjaTrnOJWc875aV2YLKWxXNVSahudC7NhMDlc2q/j2i1uR886A1RzBWKfz/MVzq1icyqKYVvDJR674fm57a8hkwIKZ/cA0OdbLDRy3hX2pEf0xuaMa7j/v1DRMZBQosoTbDhVwcWCxDcPzmrZiG706zxqmcinf4cg5+10LgugXEs8EQcRe8dwLV7drmMyqTsaa6I5s5yt0e1FKI8B5vnWuAFVmOOeTe65rBp65tosnrmwDsKrqwjZODgPZbtw4v1rGbl3vEL5xmLW7ngFvW8fSdBbfuryFjUoT9948Ffl4jDGkFcmTea41DXzt4jq+78whvO2eo/jbJ6/5uskr2zXMFdKO8JvKWi6vqHTbSz712DI+9Llzzt+3axp0k+P4XB5APOfZHW3Y8LRtNDFlD96dOlTE1Z06SvX+LxRqzcENDG5VmpjJ+zeAzORTVFW3z2yUG/itvz+P9/zxI3j1b34Bb/udr+73Q+qJSOKZMfYWxtizjLGLjLH3+3w8zRj7hP3xhxljx10f+zX79mcZY2923f4CY+xJxtjjjLFHB/HNEATRG7m0PPT13FbOlVznOKiyJXLFiu56gPOcUiScmC/gnI/zfOFGGYbJcXWn7tSo7ceOmlMLllPZ74r2+UIrjuHOTS9N55zGmKjDgoKMKnuc569fWkdDN/HG0wt45/03oaGbePCJzsHBle2aZ9FL0GrzXmjqJv7wK5cii9OPfvV5/PHXXnAiPiKecMusEM/RL47FFr6l6WzHwOC0/T2eWrCiOP02bnDO7Q2D3syzbnJP3j8qm9Wm06zRzmw+bV1U9HBcYjD8ydcv47e/cAFXtqooZhR8Z3mn54jOftJVPDPGZAAfAfBWAGcAvIsxdqbtbu8BsMU5PwngwwA+ZH/uGQDvBPASAG8B8Lv28QTfwzm/h3N+X9/fCUEQPZNLKUNv27CEBonnOIguY1FX13B6njtbKk4fLvo6z+4ox7PXS9aGwX3oIBZOpRiy631gsOU8L7Y5z4D1LooYUIxKWvHGBL54bhW5lIxX3jqDOxcncMeRCXzikRc7Pm9lu+YMKwLW85JWJOwOIPP8qceW8R/+9iw+8+S1rvfdqjRx9touapqBFfviRDRtCOe5FOPft3CeTy0UOqrqJl3OM4C+hwY1g8MweZvz3Hv3tuU8+4vnuUIKnLey28Te843nNnD30iT+7pdfj3e/5jgAYKsyes9HFOf5FQAucs4vcc6bAD4O4IG2+zwA4E/sP38KwJuYFTh6AMDHOecNzvnzAC7axyMIIkEU0goqQ848t7t0RHdE5lkzxMCg2DDY+av79JEJXNupY6dNGDxzbdcR4c9e34Vhhm8YHBbCqfyH82sAeh8cnbWFkSozZ1030BLPL7tpKvb694xrQI1zji+eXcV3nZxDWpHBGMM77z+Gp1Z28dTKjvM5nHNc9bkgnMyqfTvPpsnxh1+5BAA4G6G/2z3QKJxgIZ5vmYvvPItow22HiijVdTRtEbtdaznPN83kkFIkz/KbXqjZr+msa2BQXBz2Et3YqjZ9mzaA1oUX1dXtD7WmgW9f2cKrbp0FYL0TAGAkhzijiOdFAO5piWX7Nt/7cM51ADsAZrt8Lgfwd4yxxxhj7w364oyx9zLGHmWMPbq2thbh4RIEEZdcSkZ1iG0bOzUNpbrucemI7iiy9SvacZ51E7LEoMo+4tm1adDNM9d28dKlSUxkFJy7Xtq32IZYI/6P59c6hG8chAA6Mpn1ZLdF13PUijo3buf52RslXN2p442nWz3Bb79nERID/v6ZG85tG5Um6prZET+Zyql9Z56/cG4Vl9YrSMlS4BCom29c2kDKfk0I8SwEybHpHCQWTzxvVppIK5KzllvUv21Vmk6jiCwxnJwv+L7b4cfqbh0/+dGHcd3uYRYIgezrPMcUz6bJsVXVMBMY2xArumlocD947PIWNIPjVSds8WxHsDZHcIhzPwcGv4tzfi+sOMjPM8a+2+9OnPPf55zfxzm/b36+++pZgiDiM+yBwcsbVoXaTTP5oX2NcUQ4qE7mWTN8XWcAzpY7t5jhnOPstV2cOTKB04cncO56ydowuA/q+diM1bixXm52CN84TGQUpGSpI/ZxYr6Af/2GE/jR+4/FPqbbef7CWaui7ntc4nkyp+Lm2bx3xfi2f/XiVDbVt/P8+//4HBansvjBly06FzxhfP25Dbzy1hnMFVLOY1wrNZBSJExkFeTTCkr1GJnnchNzhbRHbBomx25ddwYGAeCuxUk8ubLT9fEBwD89t4GvXFjHg0+seG4XsxaezLPjPMeLbZTqOgyThzjP9oruEXQ6x4FvXNqALDHcby/ZEfGacRXPKwDcv42W7Nt878MYUwBMAtgI+1zOufj/KoC/AsU5CGLfyKWUoQ4MXrb7cI/P0XbBOIjYhtO2oZu+eWcAWCimMZ1TPc7z8lYNpbqOO45M4PSRIs5fL8HYh6o6wLoQODFvRTf6WZTDGMPSTBa32sdyH//fveV0T3EQ4Tw/cWUbH3v4Rdy5OIFDE97HeHKhgPOufO+K6C1vezdlMqf21fP8rRe38MgLW/jp77oFdy5OYKem4fpuPfD+G+UGnr1RwqtuncXJhQIuuGIb84U0GGNWLCtObKPSwEw+5RE34nsSQ5EAcPexKWxXNby4We16TOGIi4sTQa3Z6TyLlelxnedN2yEPatsQMYFRFGvjwNcvbeClS5NO45JzcTaCz0cU8fwIgFOMsVsYYylYA4APtt3nQQDvtv/8DgBf5Nal6IMA3mm3cdwC4BSAbzLG8oyxIgAwxvIAvh/AU/1/OwRB9EIhLaPS1CM5SL3Qcp5JPMdBxDZ0s5V5zgQ4z4wx3N42NCje8j9zdAK3Hy6i1NBxdbu251V1glOHhHjuL77z39/zSrzvLacH8ZAAWE7nkys7+KH/+k8wOce/f9udHfe57VABL6xXnPzvSoDzPJntTzz/wT9ewkRGwTvvP+a8mxAW3RB551efsMTzxVWrS3ut3MB80RKLeZ+Zhhu79cB/7xvlJmYLLfG8UWkt2XE3Wbx0aRIA8MTyTudB2nhuzRLPj17e8vx8ROa5vecZQOwWBiGKg9o2JrMqZIlRbGMfqDR0PHFl28k7A8BERoUisZGsD+wqnu0M8y8AeAjAWQCf5Jw/zRj7dcbY2+y7fRTALGPsIoBfAfB++3OfBvBJAM8A+ByAn+ecGwAOAfgqY+wJAN8E8Lec888N9lsjCCIqubQCzlsnskFzeaOKhWLas0WM6I7S1rZR102kA5xnAHjp0hSeXtl13pZ+5touGLPy0CITXdfMfck8A62hwX5bV45OZTGZ9XcXe0HElt5291F87pe+27fq7tRCEbrJ8YJ9IbiyXUM+JXc8jqmIA4MN3eioTNupanjo6et41ytvQj6t4LbDYvlNcK74689tIJeScdfiJE4tWAN+q6UG1koNJ1deaIttbFWaeN2HvoT/8diy7zE3yg3M5tOOeN6qNJ2GikmX83z74SLSiuR0iIdxcbWMwxMZGCbHP55vzS8JdznnOzAYL7ax1UU8SxKzup5pYHDPefTyFnST49Uu8SxJDNP51Ei+ExAp88w5/wzn/DbO+QnO+X+0b/sg5/xB+891zvkPc85Pcs5fwTm/5Prc/2h/3u2c88/at13inN9t//cScUyCIPaHvP02WpxFCnG4vFF1VhgT0ZGdtg1LRDRCMs8A8CP3LaFpmPj4N61atbPXdnHLbB65lOIM7AHYl9gG0Ko3S1rf97998+342M+8Eh/+0XsCRfkpZ8W45aCubFk1de3NJVM5FTXN6Oqa/sh/+zo++ODTntvOr5Zgcjju3ERGxdJ0NtR5/salDdx/fAaqLOHkQusxrruc5/bYxtWdGpqG6TSfuOGcY73SxFwhZW/qE7GNTmGqyhLuXJzsKp51w8QLGxU8cM9RTOdUZ/U54B/b6LVtoxXbCF7NPptPYZ2c5z3nG5c2oMoM9x33XpjO5kdz6yNtGCQIAvmUdbIaVtfz5c0Kbp6lYcG4iCUpUZ3nkwtFvO7UHP7sG5ehGSaeubbrvPVftIUYsH/i+b6bp3H30iReccvMvnz9IG6dL+A1J+ZC73NivgCJwempXglY+iN6kMOiGxdulPDE8g4ecVXMWbdbwlw49IA1CBrUaLFWauDCahmvttsLxOc9e6OEzUrTFduQPRfGwul7+NJmR3Sj0jTQ1E3MFlKQJYbpnCVuRBfvVNvFxd1LU3jq6k7o4pHLm1VoBsdth4p4w+0L+NKzq85ruqr5DQyKto14zrMTLQkTzwXaMrgffP25Ddy9NNXx7uPMODvPBEGMN+IX2jC6nmtNAzd2G7iZ8s6xcdZzO0tSgjPPgp9+7S24sdvA/3h0GVc2a7jjSMtxFtGN/YptzBbS+Otf+C5ncHCUyKgybprJOYNvfh3PABznur1v281nn7oOALi0XvE41BdWS8ilZBydbB33jsNFXFor+7qw37i0AaDlVM8X05jIKHj40gZM3trGWEirnjYdkfldLzfw/HrFc0whLGfs4Tohbrbti4H2SMTdxyZR10zPMGU74md2YqGAN55ewFZVw+O2W11v+mSeex0YrGhIyZJjBvgxm0+PpFgbZcoNHU+u7DgXeW5GdWU6iWeCIJzp52HENsQk/s1z5DzHpdW2IdZzB7dtCF5/2zyOz+bwoc+dA2ANCwpOH7b+vF/O86hzcqGI8zdKqDZ1bFU1395y4cxuhzjPn33qOhSJwTA5nlttideLq2WcXCh4BjpPH5mAyf03+T36wibyKRl32s8xYwwnFwrOEGErtiF7xbNLPD7c5n6LSIOodZux31bfrjYhMaCY8TqHdy9NAQC+sxwc3XDE83we333bPGSJ4YvnrM7smm/Psy2eYw4MblWamM6roUuALOeZxPOw+OK5Gx3vunzuqeswTO4ZFhTMFdIU2yAIYjTJpe3YxhCcZzFgRc5zfNoHBrtlngFrCOfdrznunMBEbAOwBrzEfYj43HaogOfXK071op/zLKrcgpznyxsVnL22i//t3iUArRgIYAnkkwteV95p3LjemXt+fHkHdy1NOq0sgDXYKJ57T9tGo9Wms1lpQJasRTUP2+61QLiAc8J5ztnOc1XDZFbteO3cPJvDZFbFEyHi+bk1a1iwmFExmVVx383T+PtnbuCzT17D589aIjqb8luSEi+2sVltBg4LCuYKaZQaek/bC4lwlreq+Ok/fhQ/86ePOq0013fq+I2/eQb3HJvCK33iWjP5lGeL5ahA4pkgCJfzPHjx/KLoeKbMc2wUWSxJ6d7z7OYdL19CPiVjKqfisKuveL9jG6POqUMF6CbH1y6uA/AXz5NdnGcR2fi5N5yAKjMnz7xbt/qcTy0UPfe/aSaHrCrjXFvjRkM3cPbqruP8uh+jYL5gPff5tALd5GjYAmWj3MRMPoVX3jKDh5/35p6FC+g4z4WU3bbR9CxIETDG8NKlSTx+Jbiu7rlV70XBm+5YwPkbZfzcn38LD1/axPedOTSQgcGtSjN0WBAY7cUcSUe0wnzz+U38+//1NDjn+LefegJN3cSHf/Qez0WewGl0qY7W80G9UQRBIGe7PsNY0f3CRgWTWdVTcUVEo5V57r5h0E0xo+L9bz2N7armeQv7lrk8Uorku96b6I4Qtl9+1mqp8I9tWGJgO0AMfPbJa3jp0iSOz+VxYr6AZ21HWUQbTi10Ln+57XCxo3Hj3LUSmoaJu495xfMJ1+fPFa3HIqIW5YaOjCpjo9LEbD6FV946g7998hqWt2rOKm4hKoWomc2nsFUV4tn/3/A9x6bwu19+DrWmgWxKxk5Nw0RGAWMMnHM8t1bBO16+5Nz/J151M6ZyKdx2qIg7jhSdpSgC8Rpv9NC24X6nxQ/31sSktb7EhXMeGlHZa87Zr9GfevXN+NOvX8byVg1fubCO33j7nbglILYnno/1cqNjMVGSIfFMEETLef7/27vv8LjrK9/j7+/MaDTqXZZky5abXME2GOPQwfSQmOQGAkuygZC2gYRscnOzyeY+YTd5stnsJpuwyyWbgCkpEC4JhJtQlhiW0LGNDe69SLKsZvU6Gn3vH7+ZUZd+smTPjPm8nofH0m+KvsI/z5w5v/M95ySUbRw53kGZ2tSdkIlMGBzqkx8oG/58Xg/33XLWsOl84s7cgnSMcTJrPo+hMGP4m31GwIcxI3fbqGrq5N3KZv7X1QsAp4wm0nFjX6TTxrThfzeLizN4btuxQcFSpMZ4aPAcCb7T/N7oRuA0f/+Vpfz0ZKePc7qfc2c7NahvHmiIBs/1bd2kJ/ui51lump8+C4fqOygfYW3g1D2H+ixvHmzgtb31PPT6Ie5aM58vrZnPsZYu2rp7mVvQHzyl+n3cuHL0MerGGGfq4wQv5Te295A7TtlGXrj3dX2C93r+8Qt7eHZrNc9/5aJTVob1w+d24TGG/3nVghFv31XTSmluCt/50BIqGzt5cVctF5cX8IlzZ476nJG/j0S7EqD0g4j0d9s4CWUbhxramamSjRPiG9qqLhiK1oOeqDWLpo2aBZKxpfi9lOak0hPqoygrEO3DPZDHY0adMvhcuGTjmqXFgBM8H23uorkzyN7aVpJ9HmbkDP+gubAok8aOIDUt/QHflopm8tP9lGQNDuBLslJISfJG652hv497ZFDK8fYectOSmV+YTk5q0qBNg5HpghGRDHRVU+eo9cRnljqTBm9/aAMPvHaQvHQ/6147SGdPaFCnjYkIJHknVLYR6rM0dQbHbFMHkB/+3Y6HNw1+9fEt/P2TWye0tsn67YYjbDp8fPw7juHpLVXsrW1jyxi15lOp4ngH//mXAzy+sWLU++yqbmFhUSZej+EnNy3nby8v519vWDZmdjxRy2gUPIsIfp8Hv9dDe8/Ulm309PZR1dipzPMJimSegwNqnode4pZTK5J9HWtKYtYIUwattfxhSxULizKiH14iNeh7a1rZU9PG3IL0EQPyFTOd7PLLe/qHi7xb2cSyGdnDAhNPuMyjaEBQHSnbiHw4jpRteDyGVbNzeetg/6bBhvbu6KV0cFq7RX+vUco2CjMCLJuRxZkzsnnqi+fz7zefRWNHkN+9U8n+cPA8dCPkeAJJngkFz82dQayFnHHKwyKZzob2bjYdbuT371Txx/eqRx1VPuhndAT5xhPvUdPS5XpdI63z75/cxnf/uPOEn+NgfTuHwntJIh/ITrYHXj1IqM9Gp1cO1RUMcbC+PXpOZwaSuOvy+YM+xI1kYBlNIlHwLCKA03FjqjPPVU2d9Fln05NMnC9c8xzq6yMY6iPUZyedeZbJmReuex4reM5OSRq2YXBzRRPvVTZzy+pZ0WMLwq0Ddx1rZV9t24glGwBnTM9idn4av3+nCoDWriD769qGlWxE/OiGM/ne9Uuj36cNKMvq7g3R2tUbDVpWzc6j4ngnR5s6gUjmuT/gyUnrD0bH6mTxhzsv4Kk7zmdZaTbnlOVw5ows1r16kD21bWQGfBSkjx1EDeVknt2XbQyt1R5Nmt+L3+ehoa2Hf3thD+AEtEP7XY/kkTcO8duNFTz42iHX6xrq5T119PZZtlQ0cbhh/J/Z1t3Ln3fUDAruIxMaF0zL4Jmt7gL/yTje3sNjG45ES2+2Hx2+OXRfbRt9tr8dpltZKUl4PSbhRqbrVVhEAKcucqr7PEfeHDRd8MQkhTdONbYHo1k4ZZ5jK5p5HmGzYERWqp/mIRsGH3ztEBkBHx9dMT16rCQrQEayj3eONFLV1Dlss2CEMYaPrJjOWwePU9XUydaqZqwdXu8cMa8wIxrkg9PnGaCtOxSdFJgbLl+4aL4zWfG3G5zL8fVtPdHSBhiceR5tw+BI6/3MhXM4UN/OHzZXMbcwfcIb2wI+p2zDWstz246xrWr0bh7Q361hvFZ1xhjy0/y8sKOGV/fVc+NKZyPj5iNjlz9094Z45M3DADyxqZLgGBMVx7J+Zw0ZyU5d/B+2HB3zvqE+yx2/fofPPLKRF3bURI+/tLuWuQVpfPqCMiobO9l+dPTx7VPhl28cpivYxw8/tgxgxJ8X6RqzsDhj2G1j8XgMOalJKtsQkcSUdhIyz4ejbeqUeT4RxZkBFhdn8sCrB2kJ16sq8xxb5dOc4GDGGMFz9pCa52PNXTy7tZqPryyNZoHBCeTKizKigdG8wtEDj4+Eg+6nNlfxbrgt3JnTs1ytOfIz27p6oxm+SFA8f1oGHzyjmF+8coCali4aO3oGBcwDM88jtaobzbVLi5ienUJ7T4h5J7BBNZDkobWrl289uZUv/GoT3/vTjjHv3+gy8wxO6caB+nYKM5K5+8NLyEj2sbmicczH/PHdaupau7n1vDLq27pZv7NmzPuPpDfUx3/vruPKJUWsKsvlqS1VY2aNf/zCbl7eU0dKkpdfvHIAcEpv3jpwnEsXFHLF4iK8HsOz26onvBa3OntCPPzGIdYsLOTsWTnMzE0dMfO8q7qFZJ/nhFqS5qUlq2xDRBJTqt835d02Djd0DNu8JO55PIZvf3ARVU2d/Oy/9wOQ7LLbhpwcS0oy+dcblnHdmSWj3idrSNnGr986TMha/nqEDigLijKiG/lGK9sAKM1N5ZyyHJ7cXMW7FU3Myksdd3NcxMA+7g1DJggCfP2qBQRDfdz99HZCfXZQAJrs85IRfnxkeqIbPq+H284vAyZe7wzOef7GgQYefbuC6dkpbK9qoa9v9EAzmnl2FTw79/nSZfNI9ftYVpo9ZubZWsv9rx6kfFo63/7gIooyAzy2YfSNc6PZeLiR5s4gly8qZO3y6Ryoax81a/zctmrufWk/N51TytevWsCGQ428c6SR1/c30BPq47KFheSm+Vk9J5dnw51YToYnNlVwvL2Hz188F3DO/5HWvLumlfJpGSPW7I8nMgI+kSh4FhHAeYPtmOINg4cb2pmVlxpXvUgTzXnz8lmzsJBfv+VcMnbT51lOHmOMM4QmefROr7lpfpo7g9z70j6Ot/fwm7eOsGbhNGaOcAUmssEqyWvGncJ5/Yrp7Ktt46XdtcOGo4wl0qqurbt3xNrgsvw0bjl3VnSAy8DAGvpLPMYriRjqplUzWbu8hCsWT5vQ48AJ1ANJHu65eQVfXjOP1u5ejhzvGPX+xyPlKC7WOK8gndn5adx4jtMub8XMbHYda6VzlNe/Nw40sLO6hU+fPxuf18ONK2fw8p46qsJ14m6t31mD3+vhwvICrj2jiCSv4anNVdHbQ32WjYeO8/1ndvLVx99leWk2/7B2CR8/p5TMgI9f/OUAL+2uJc3vZWWZM63v6qXFHKhrZ2/t8PHtU+H3m6tYXJzJOWU5ACydnsXhhg5augbX9O+sbo1OMJ2o3HR/wo3o1quwiADOoJQpL9s43qHNglPgm9cuin4AcdvnWWLnltUzuXRBIf/y/G5W/9N6Gtp7olnYoRaEy0Dm5KePOIFtoOvOKMHv9dDd28eZM9yVbIBzBSPV76Wtu5f6IeO3I768Zn40w5w/ZHNfJNB2W/MckZ7s46c3rTihvuLfvX4p//WVi/nwshKWlDi/69Yx6p4bO3oIJHkGjfkezbeuXcSzd10Y3T+wvNTpUz3a86979SB5aX6uD5fO3BDuUf14OPvcFQxFN1xGNLR186VHN3Pbg2/TFn5dXb+zlnPn5JKe7CM71c/F5YU8/e5R2rt7uf+VA3zgn9bzsZ+9wYOvHWT1nDx+9omzSfZ5SUv28YnVs3hu+zGe2VrNBfPz8Yc/RF+1ZBrGwLNbp77rRl1rN1sqmrhqSVH09WdxSXhc/IDsc31bN/Vt3dEPghOVl+aPjoVPFBqSIiKA80Y31WUbNS1dnD83b0qf8/1oXmE6t5w7k0feOKzMcwIozAiw7tZz2FLRxD3r92Kt5bxR/h1EsnXzxijZiMhKTeKyhYU8t/0Yy0fZLDia9GQf7eHMs89jyEwZ/Pafm+bnby6dyw+f203xkN7ReScYPE/GwGlz5dMy8Hs9bKtq5kPL+stlIhM3jTFO72qXmXGPxxDw9AfZkf+Xm480smp27qD7HqhrY/2uWr502fzoB9fS3FQumJfPr986wruVTbx5oIGuYB8fmJPHpy+YjbWWbz25lZbOXkLWctuDb/OdDy3hQH07nzqvLPrc168o4c87a1j9/fW0dvdy3tw8vn3dYi5dUEBGYPD/61vPK+P+Vw7S1BHk0gWF0eOFGQHOnpnDi7tquOvy+a5+f7de2lWLtXD54v6ftyQcPG8/2sK5c5xzendks+AEO21E5KUl09LVSzDUlzDTTxU8iwgQaVU3dWUboT5La1cvWROok5TRffWKcpK8Hs6alRPrpYhLy0uzWXfrOWPeJzvVzw1nz+Byl6UNn7t4Dp3BEEtdbhaMSE/2RTOguWn+EUupvnDRXC6aXzAsU5yT6sfnMdHa6VPN7/OwsDiDbQM2qjV3BLnghy/ytSvKufX82TS297iuAR8qLz2ZWXmpI9Y9P/jaIZI8Hj45oMUgOMHs7Q9v5EhDBzevmkluqp9H3z7CZx/ZCMCi4kx+9Zll7K9t58uPbebmn78JwJpF/YHomoXTmJWXyoycFO5aUz4scB+oMDPA9StK+L+bKrlkQPAMTjb4yXeqpnxc9ws7ayjJcjYtR9eREaAgI3lQ3XNkdPxEO21ERMqCGtt7KEyQEd0KnkUEcHbkT2XZRmu4Ji5TwfOUyE7187+vWxzrZchJ8C83LHN937Nm5vDwp1dN+GekhYPnrmDfqB0pPB4zYlB+xeJpJIUzvLGypCQr2tPYGMP6XTW0dvXyHy/t56ZVMzne0TPhmuyBVpRm8/r+hkEBaFNHD09sqmTt8pJhm57XLJrG1ruvHJQh/sIlc3l++zEa23u48ZxSkn1eFhZlYrHc9dgWFhZlDJqrdfvwAAAQ80lEQVQgmeL38vLXL3W9xm9ft5iPnjVj0AAcgLK8NFrDVxXyRuin3dbdy09e2EN5UQYfXlbiqvSrKxji1b313LByxrC/d2fTYP8Hmd3HWslP9w8r93ErcmWjvk3Bs4gkmDS/j+7ePnpDfePWXroRadWlzLNI7EVaUYb67ISDnCuXFHHlkqKTtDJ3zpiexaNvH6HieCcz81J5fvsxAkke6tu6+e2GChrbe0Ycbe7Wipk5PLXlKNXNXZSEB+A8+nYFncEQt184e8THDC2tSPJ6RuzCct2ZJRRnpZCWPLn9CpmBJFbPGV7+U5bv/N6HGtqHBc+1LV3c9tCGaKb4n5/dxS3nzuTC8gIWFmUM+x0iXt9fT2cwxJpFw6+ILCnJ5JW99XQFQwSSvOw61nrCJRuQmCO6FTyLCOBsGARo7wmRlTJ1wfNEesOKyMmRnpxEVVMnHT29kwoyY2XpdCc423a0mYKMZF7eU8eNK0vZWd3Cz17eT2tXL7mTqMnur3tuoiQ7hWCoj4dfP8T58/ImFRhGnH0Sy60ivZUP1Xdw9qz+0o+9Na3c+uAGGjt6ePC2c0j2enjg1YPc8+I+7nlxH+Dsp/jBR8+Idu+IeGGH09Vj9ZzhpSRLSrII9Vn21LSyq7qVHdUtfPbCOSe8/shQnkSaMqjgWUSA/l6wHT1TU6eszLNI/EhP9tLWHaSpPehqkEi8WVCUQZLXsLWqGa/H0BXs46olRaxZNI1PrXsbcNfjeTSLijPx+zz86s3DzMhJ4VBDO8dauvj+R5eO/+AYm5GTiscwaNy3tZZbH9xAT6iPxz//gWg5znnz8qlt6WLb0WZ2HG3hiU2V/NX9b/HTjy/nmjOKAejrs7y4q4aLFxSMONF0abj7yTd+t5Wd1S1cOD+fv7lk7gmvPzfc+WWkzPMXfrmJM0uz+OIl8074+U8GBc8iAkDqgEEKU0HBs0j8SEv20dgepK27d9D47USR7PNSPi2DbVXN1LR0kZWSxKrZufg8hjOmZ7G1qnlSHwr8Pg93XjqPe1/ax9p7XyPJa5hTkMYl5YXjPzjG/D4P03NSONjQ3we7urmLqqZO/nHtkmF17IWZAS7LDHDZwmn81bmz+MzDG/jib97hq5c7mxbr23qoaenm8hFKNgBKc1PICPjYWd3C7RfM5pvXLJxUqV92ShIeMzx4ttby8p46po8xzTNWFDyLCOBkpoAp67ih4FkkfqQHBnbbSMyJn0tLsnh+xzGshTULC6Ntze68bB6f/+UmCjMmt9nsy2vmc+v5ZfzpvWqe2VrNJ1fPwnMCE/NioSwvbVDmeUe4xjnSWm40uWl+fvPZ1XzlsS386IU90eNejxnUEm8gYwzfXbuUJK+HD55ZPOm1ezyGnFQ/9UNGdDe099AZDDFDwbOIxKtU/9Rmnps6FDyLxIt0f//b/dAJgoli6YwsfrvRGUwycAPjlYun8djnVk9JXXFmIImbV83k5lUzJ/1cp1JZXhpPbelvV7f9aAvGuOu9HEjyct8nzmJndStNHT20dAXJS08eswwmMjBmqjgjugfXPFc2OoNnSuOwRl/Bs4gA/TXP7VM0orulM4jf6yGQlBhN70VOZwPHieclYM0zOB03wBlRf1F5fvS4MWbELhTvJ2X5abR29dLY4dS0bz/azOy8tDHHyA9kjIlOD4yFvHT/sLKNykanDGVGbvxlnvWuJiJAf7eNjimaMtjcGSQzJSmmvWFFxJEeGJh5TsyyjYVFGfg8hovKC6JXysRRltffrg5gR3VLTIPhicpPT6a2dXDmueK4k3mOx+4wCp5FBOgfZnJkwKaTyWjuDJ7Scb4iMrqB0wETsdsGOOUF99y8gm9cvTDWS4k7s6Lt6tpp7ghS2diZUMFzWV4alY2ddPf2X/msbOwgJzUpZpMtx6LgWUQA55P/hfPzefD1Q1NS99zcGVS9s0iciFy+T/IaMgPxF4y4de0ZxcwrTB//ju8zpbkpeAwcauhgR3Vks+DERrjH0rzCdEJ9dlDypqKxMy6zzqDgWUQG+OoV5Rxv7+Gh1w9N+rkUPIvEj0g3ndw0v0qpTkPJPi8l2SkcbmiPjs5eXJw4mee5Bc4Hon21bdFjlY0dlMZhvTMoeBaRAVbMzGHNwkL+8+X90VZzJ0rBs0j8SE92/i0maps6Gd/s/DQO1bezo7qFwoxkCjIS5+96ToFTdrK/zgmerbVUKfMsIonib68op6WrlwdePTip51HwLBI/0sKZ50QckCLuzMpLdco2jibWZkFwyopKsgLRzHNdazfdvX1x2eMZFDyLyBBLp2dxzdIi1r16kIrjJ7Z5MNRnae3qjW5CFJHYimy6StTNgjK+srw0mjuD7K5pHXc4SjyaW5jO/jqnW0hFHPd4BgXPIjKCr11ZTp+1XPWTv3D/KwfoDfVN6PEtmi4oElfSFDyf9srCHTeshcXFibNZMGJuQTr769qw1vb3eFbmWUQSxbzCDJ7/ykWcOzuX7/1pJ//jvtfpCrofnqLR3CLxJcnr4bbzy7hm6eTHKUt8Ksvvz9Imaua5oydEdXNXdLrgdAXPIpJISnNTWXfrOXz7g4t4t7KZ9yqbXT82EjxnK3gWiRvf+dASVs3OjfUy5CQpzU3FGKdEZ2ZufJY7jGVeuOPG/ro2Khs7yE/3x+0wHAXPIjIqYwwXlxcAUN3c6fpx0cyzhqSIiJwSyT4vJVkpLCrOwONJvHaEcwudspN9tW1UNnYyPU7rnQHiM6QXkbhRnO1cNjva1OX6MSrbEBE59f7hw0sSNmlRkJ5MRsDH/ro2Ko53sHR6/NZtK3gWkTGlJ/vICPhOLPOs4FlE5JS5fPG0WC/hhBljmFeYzt6aNqqaOrk6juvzVbYhIuMqyUpR5llERE6quQXpbK5oIhiycdtpAxQ8i4gLxdmBCWee/T4PgSTvSVyViIicTuYVptPT67RGLY3jTY8KnkVkXMVZKRxrnkDmuUPTBUVEZGLmhjtuQPz2eAYFzyLiQklWgIb2Hte9nps7g2pTJyIiEzK3IC369fRsBc8iksCKsgIArrPPzZ3KPIuIyMTMzE0lyWsozEiO67I/Bc8iMq6SSLs6l3XPCp5FRGSifF4Ps/PT4rpkA9SqTkRcKA5nnqtddtxo7gyysCjjZC5JREROQ3d/eAlJ3vjO7Sp4FpFxFWc5WQC3HTdaOoNkKvMsIiITdN7c/FgvYVzxHdqLSFxI8XvJSU3iqIua595QH63dvSrbEBGR05KCZxFxpTgrheqm8TPPLV29gAakiIjI6UnBs4i4UpIdoNpF5lnTBUVE5HSm4FlEXCnOSuGoi8xzJHjOTlXwLCIipx8FzyLiSnF2gJauXtq7e8e8nzLPIiJyOlPwLCKulEQ7boxduqHgWURETmcKnkXElWiv53Ha1Sl4FhGR05mCZxFxJTJlcLxBKS3h4Fl9nkVE5HSk4FlEXJmWGcCY8Ud0N3cGSfZ5CCR5T9HKRERETh0FzyLiit/nIT89edzMc1NHj0o2RETktKXgWURcK8kKuMo8q02diIicrnyxXoCIJI7irBT21bUNOhYM9bGvto39dW1UNnayraqFkuxAjFYoIiJycrkKno0xVwM/BbzA/dbaHwy5PRl4BDgbaAA+bq09FL7tm8DtQAj4srX2eTfPKSLxpzg7wF/21vHQawfZUd3C9qMt7K1poyfUF71PdmoSlywojOEqRURETp5xg2djjBe4F7gCqAQ2GGOettbuGHC324FGa+08Y8xNwD8DHzfGLAZuApYAJcCfjTHl4ceM95wiEmdm56fR0RPi7v+3g7w0P4tLMrntgjKWlGQxvzCdGTkpZARUsiEiIqcvN5nnVcA+a+0BAGPMY8BaYGCguxa4O/z1E8B/GGNM+Phj1tpu4KAxZl/4+XDxnCISZ25cWcr8wgzmFKRRmJGM889cRETk/cPNhsHpQMWA7yvDx0a8j7W2F2gG8sZ4rJvnFJE4E0jy8oG5eeG2dQqcRUTk/Sfuu20YYz5njNlojNlYV1cX6+WIiIiIyPuYm+C5Cigd8P2M8LER72OM8QFZOBsHR3usm+cEwFr7c2vtSmvtyoKCAhfLFRERERE5OdwEzxuA+caY2cYYP84GwKeH3Odp4FPhrz8GvGitteHjNxljko0xs4H5wNsun1NEREREJK6Mu2HQWttrjLkTeB6nrdw6a+12Y8w/AhuttU8DDwC/DG8IPI4TDBO+3+M4GwF7gTustSGAkZ5z6n89EREREZGpY5wEcWJYuXKl3bhxY6yXISIiIiKnMWPMJmvtypFui/sNgyIiIiIi8ULBs4iIiIiISwqeRURERERcUvAsIiIiIuKSgmcREREREZcUPIuIiIiIuKTgWURERETEJQXPIiIiIiIuKXgWEREREXFJwbOIiIiIiEsKnkVEREREXFLwLCIiIiLikoJnERERERGXFDyLiIiIiLik4FlERERExCVjrY31GlwzxtQBh2Pwo/OB+hj8XDk96PyRydI5JJOh80cm4/16/syy1haMdENCBc+xYozZaK1dGet1SGLS+SOTpXNIJkPnj0yGzp/hVLYhIiIiIuKSgmcREREREZcUPLvz81gvQBKazh+ZLJ1DMhk6f2QydP4MoZpnERERERGXlHkWEREREXFJwfM4jDFXG2N2G2P2GWP+LtbrkfhnjDlkjNlqjNlijNkYPpZrjHnBGLM3/GdOrNcp8cEYs84YU2uM2Tbg2Ijni3HcE349es8Yc1bsVi7xYpRz6G5jTFX4dWiLMebaAbd9M3wO7TbGXBWbVUs8MMaUGmNeMsbsMMZsN8bcFT6u16AxKHgegzHGC9wLXAMsBm42xiyO7aokQVxqrV0+oL3P3wHrrbXzgfXh70UAHgKuHnJstPPlGmB++L/PAfedojVKfHuI4ecQwL+FX4eWW2ufAQi/h90ELAk/5v+E3+vk/akX+Jq1djGwGrgjfI7oNWgMCp7HtgrYZ609YK3tAR4D1sZ4TZKY1gIPh79+GLg+hmuROGKt/QtwfMjh0c6XtcAj1vEmkG2MKT41K5V4Nco5NJq1wGPW2m5r7UFgH857nbwPWWurrbXvhL9uBXYC09Fr0JgUPI9tOlAx4PvK8DGRsVjgv4wxm4wxnwsfm2atrQ5/fQyYFpulSYIY7XzRa5JMxJ3hS+vrBpSK6RySERljyoAVwFvoNWhMCp5Fpt4F1tqzcC5v3WGMuWjgjdZpcaM2N+KKzhc5QfcBc4HlQDXwo9guR+KZMSYd+B3wFWtty8Db9Bo0nILnsVUBpQO+nxE+JjIqa21V+M9a4EmcS6I1kUtb4T9rY7dCSQCjnS96TRJXrLU11tqQtbYP+AX9pRk6h2QQY0wSTuD8a2vt78OH9Ro0BgXPY9sAzDfGzDbG+HE2WTwd4zVJHDPGpBljMiJfA1cC23DOm0+F7/Yp4A+xWaEkiNHOl6eBvw7veF8NNA+4tCoSNaQO9SM4r0PgnEM3GWOSjTGzcTZ+vX2q1yfxwRhjgAeAndbaHw+4Sa9BY/DFegHxzFrba4y5E3ge8ALrrLXbY7wsiW/TgCed1yN8wG+stc8ZYzYAjxtjbgcOAzfGcI0SR4wxjwKXAPnGmErgO8APGPl8eQa4FmeTVwdw2ylfsMSdUc6hS4wxy3Eutx8CPg9grd1ujHkc2IHTaeEOa20oFuuWuHA+8ElgqzFmS/jYt9Br0Jg0YVBERERExCWVbYiIiIiIuKTgWURERETEJQXPIiIiIiIuKXgWEREREXFJwbOIiIiIiEsKnkVEREREXFLwLCIiIiLikoJnERERERGX/j/uXJ6zQLDdYAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PVx-lksMiY_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}